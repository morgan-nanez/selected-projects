{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Morgan- Neural Machine Translation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6czvz5VKO5M"
      },
      "source": [
        "# Notebook for Programming in Problem 3\n",
        "Welcome to the programming portion of the assignment! Each assignment throughout the semester will have a written portion and a programming portion. We will be using [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb#recent=true), so if you have never used it before, take a quick look through this introduction: [Working with Google Colab](https://docs.google.com/document/d/1LlnXoOblXwW3YX-0yG_5seTXJsb3kRdMMRYqs8Qqum4/edit?usp=sharing).\n",
        "\n",
        "We'll also be programming in Python, which we will assume a basic familiarity with. Python has fantastic community support and we'll be using numerous packages for machine learning (ML) and natural language processing (NLP) tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o8HI5JqTvU5"
      },
      "source": [
        "## Learning Objectives\n",
        "In this problem, we will use [PyTorch](https://pytorch.org/) to implement a sequence-to-sequence (seq2seq) network with attention to build a nerual machine translation (NMT) system (translate from French to English)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObrHyvWvTyGZ"
      },
      "source": [
        "## Writing Code\n",
        "Look for the keyword \"TODO\" and fill in your code in the empty space.\n",
        "Feel free to change function signatures, but be careful that you might need to also change how they are called in other parts of the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnYMKJlKNXYe"
      },
      "source": [
        "## Installing PyTorch\n",
        "\n",
        "Install PyTorch using pip. See [https://pytorch.org/](https://pytorch.org/) if you want to install it on your computer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dRVuiP_JVdT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "642b5725-6737-4c6f-99df-b8f09ff30b39"
      },
      "source": [
        "!pip install torch==1.8.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.8.0\n",
            "  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 735.5 MB 13 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (3.10.0.2)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.8.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.8.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw76yPDhOia1"
      },
      "source": [
        "## Download NMT data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL42TT6Tb0S7"
      },
      "source": [
        "We first download the data for NMT, which contains pairs of parallel sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmD7lPOXOlm2"
      },
      "source": [
        "!wget --quiet https://princeton-nlp.github.io/cos484/assignments/a4/NMT_data.zip\n",
        "!unzip -qo NMT_data.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBbukPd8dguZ"
      },
      "source": [
        "Take a look at the first 10 samples in `train.fr` and `train.en`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3INjAlgO2yJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdf7125f-d700-456b-b638-fcd01b6ff1da"
      },
      "source": [
        "!echo =========== fr sentences ===========\n",
        "!head -n 10 NMT_data/data/train.fr\n",
        "\n",
        "!echo =========== en sentences ===========\n",
        "!head -n 10 NMT_data/data/train.en"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========== fr sentences ===========\n",
            "je suis du@@ re .\n",
            "je ne suis pas aux pi@@ ec@@ es .\n",
            "je ne d@@ or@@ s pas bien .\n",
            "c est mon ass@@ oc@@ ie .\n",
            "tu es idio@@ te .\n",
            "nous sommes engag@@ ees .\n",
            "c est pour vous que je suis ven@@ u .\n",
            "c est une enfant apres tout .\n",
            "je suis a ton service .\n",
            "il a des ennu@@ is .\n",
            "=========== en sentences ===========\n",
            "i m tough .\n",
            "i m not in a r@@ us@@ h .\n",
            "i m not sleep@@ ing well .\n",
            "he s my part@@ ner .\n",
            "you re sil@@ ly .\n",
            "we re comm@@ it@@ ted .\n",
            "you re the re@@ as@@ on i ca@@ me .\n",
            "she is a child af@@ ter all .\n",
            "i m at your service .\n",
            "he is in trouble .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5TS8PG0Os0f"
      },
      "source": [
        "## Data preprocessing\n",
        "\n",
        "In this section we will write code to load data and build the dataset for NMT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgl_RmoiNBko"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "import json\n",
        "import torch\n",
        "import argparse\n",
        "from typing import List"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMcKVgXqPC8v"
      },
      "source": [
        "Write a function to read corpus. When reading target sentences, we insert `<s>` at the beginning of the sentence and `</s>` token at the end."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2TuSJzGPRKY"
      },
      "source": [
        "def read_corpus(file_path, source):\n",
        "    \"\"\" Read file, where each sentence is dilineated by a `\\n`.\n",
        "    @param file_path (str): path to file containing corpus\n",
        "    @param source (str): \"tgt\" or \"src\" indicating whether text\n",
        "        is of the source language or target language\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for line in open(file_path):\n",
        "        sent = line.strip().split(' ')\n",
        "        # only append <s> and </s> to the target sentence\n",
        "        if source == 'tgt':\n",
        "            sent = ['<s>'] + sent + ['</s>']\n",
        "        data.append(sent)\n",
        "    return data"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZRgZ6YrPg_7"
      },
      "source": [
        "Write a function and pad sentences according to the longest sentence in the batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7E0PlENM8so"
      },
      "source": [
        "def pad_sents(sents, pad_token):\n",
        "    \"\"\" Pad list of sentences according to the longest sentence in the batch.\n",
        "    @param sents (list[list[str]]): list of sentences, where each sentence\n",
        "                                    is represented as a list of words\n",
        "    @param pad_token (str): padding token\n",
        "    @returns sents_padded (list[list[str]]): list of sentences where sentences shorter\n",
        "        than the max length sentence are padded out with the pad_token, such that\n",
        "        each sentences in the batch now has equal length.\n",
        "    \"\"\"\n",
        "    sents_padded = []\n",
        "    max_len = max(len(s) for s in sents)\n",
        "    for s in sents:\n",
        "        padded = [pad_token] * max_len\n",
        "        padded[:len(s)] = s\n",
        "        sents_padded.append(padded)\n",
        "    return sents_padded"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmmpSLxqeEia"
      },
      "source": [
        "Write a function to yield batches, i.e., place `batch_size` samples into one batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIwN_7X6d9nX"
      },
      "source": [
        "def batch_iter(data, batch_size, shuffle=False):\n",
        "    \"\"\" Yield batches of source and target sentences reverse sorted by length (largest to smallest).\n",
        "    @param data (list of (src_sent, tgt_sent)): list of tuples containing source and target sentence\n",
        "    @param batch_size (int): batch size\n",
        "    @param shuffle (boolean): whether to randomly shuffle the dataset\n",
        "    \"\"\"\n",
        "    batch_num = math.ceil(len(data) / batch_size)\n",
        "    index_array = list(range(len(data)))\n",
        "\n",
        "    if shuffle:\n",
        "        np.random.shuffle(index_array)\n",
        "\n",
        "    for i in range(batch_num):\n",
        "        indices = index_array[i * batch_size: (i + 1) * batch_size]\n",
        "        examples = [data[idx] for idx in indices]\n",
        "\n",
        "        examples = sorted(examples, key=lambda e: len(e[0]), reverse=True)\n",
        "        src_sents = [e[0] for e in examples]\n",
        "        tgt_sents = [e[1] for e in examples]\n",
        "\n",
        "        yield src_sents, tgt_sents"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eolLr_f5PyDR"
      },
      "source": [
        "## Build vocabulary\n",
        "\n",
        "In this section, we will write code to build vocabulary for the seq2seq model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RzTsjUvNWqF"
      },
      "source": [
        "from collections import Counter\n",
        "from itertools import chain\n",
        "import json\n",
        "import torch\n",
        "import argparse\n",
        "from typing import List"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnfCzW6HNU0c"
      },
      "source": [
        "class VocabEntry(object):\n",
        "    \"\"\" Vocabulary Entry, i.e. structure containing either\n",
        "    src or tgt language terms.\n",
        "    \"\"\"\n",
        "    def __init__(self, word2id=None):\n",
        "        \"\"\" Init VocabEntry Instance.\n",
        "        @param word2id (dict): dictionary mapping words 2 indices\n",
        "        \"\"\"\n",
        "        if word2id:\n",
        "            self.word2id = word2id\n",
        "        else:\n",
        "            self.word2id = dict()\n",
        "            self.word2id['<pad>'] = 0   # Pad Token\n",
        "            self.word2id['<s>'] = 1  # Start Token\n",
        "            self.word2id['</s>'] = 2    # End Token\n",
        "            self.word2id['<unk>'] = 3   # Unknown Token\n",
        "        self.unk_id = self.word2id['<unk>']\n",
        "        self.id2word = {v: k for k, v in self.word2id.items()}\n",
        "\n",
        "    def __getitem__(self, word):\n",
        "        \"\"\" Retrieve word's index. Return the index for the unk\n",
        "        token if the word is out of vocabulary.\n",
        "        @param word (str): word to look up.\n",
        "        @returns index (int): index of word\n",
        "        \"\"\"\n",
        "        return self.word2id.get(word, self.unk_id)\n",
        "\n",
        "    def __contains__(self, word):\n",
        "        \"\"\" Check if word is captured by VocabEntry.\n",
        "        @param word (str): word to look up\n",
        "        @returns contains (bool): whether word is contained\n",
        "        \"\"\"\n",
        "        return word in self.word2id\n",
        "\n",
        "    def __setitem__(self, key, value):\n",
        "        \"\"\" Raise error, if one tries to edit the VocabEntry.\n",
        "        \"\"\"\n",
        "        raise ValueError('vocabulary is readonly')\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\" Compute number of words in VocabEntry.\n",
        "        @returns len (int): number of words in VocabEntry\n",
        "        \"\"\"\n",
        "        return len(self.word2id)\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\" Representation of VocabEntry to be used\n",
        "        when printing the object.\n",
        "        \"\"\"\n",
        "        return 'Vocabulary[size=%d]' % len(self)\n",
        "\n",
        "    def id2word(self, wid):\n",
        "        \"\"\" Return mapping of index to word.\n",
        "        @param wid (int): word index\n",
        "        @returns word (str): word corresponding to index\n",
        "        \"\"\"\n",
        "        return self.id2word[wid]\n",
        "\n",
        "    def add(self, word):\n",
        "        \"\"\" Add word to VocabEntry, if it is previously unseen.\n",
        "        @param word (str): word to add to VocabEntry\n",
        "        @return index (int): index that the word has been assigned\n",
        "        \"\"\"\n",
        "        if word not in self:\n",
        "            wid = self.word2id[word] = len(self)\n",
        "            self.id2word[wid] = word\n",
        "            return wid\n",
        "        else:\n",
        "            return self[word]\n",
        "\n",
        "    def words2indices(self, sents):\n",
        "        \"\"\" Convert list of words or list of sentences of words\n",
        "        into list or list of list of indices.\n",
        "        @param sents (list[str] or list[list[str]]): sentence(s) in words\n",
        "        @return word_ids (list[int] or list[list[int]]): sentence(s) in indices\n",
        "        \"\"\"\n",
        "        if type(sents[0]) == list:\n",
        "            return [[self[w] for w in s] for s in sents]\n",
        "        else:\n",
        "            return [self[w] for w in sents]\n",
        "\n",
        "    def indices2words(self, word_ids):\n",
        "        \"\"\" Convert list of indices into words.\n",
        "        @param word_ids (list[int]): list of word ids\n",
        "        @return sents (list[str]): list of words\n",
        "        \"\"\"\n",
        "        return [self.id2word[w_id] for w_id in word_ids]\n",
        "\n",
        "    def to_input_tensor(self, sents: List[List[str]], device: torch.device) -> torch.Tensor:\n",
        "        \"\"\" Convert list of sentences (words) into tensor with necessary padding for\n",
        "        shorter sentences.\n",
        "\n",
        "        @param sents (List[List[str]]): list of sentences (words)\n",
        "        @param device: device on which to load the tesnor, i.e. CPU or GPU\n",
        "\n",
        "        @returns sents_var: tensor of (max_sentence_length, batch_size)\n",
        "        \"\"\"\n",
        "        word_ids = self.words2indices(sents)\n",
        "        sents_t = pad_sents(word_ids, self['<pad>'])\n",
        "        sents_var = torch.tensor(sents_t, dtype=torch.long, device=device)\n",
        "        return torch.t(sents_var)\n",
        "\n",
        "    @staticmethod\n",
        "    def from_corpus(corpus, size, freq_cutoff=2):\n",
        "        \"\"\" Given a corpus construct a Vocab Entry.\n",
        "        @param corpus (list[str]): corpus of text produced by read_corpus function\n",
        "        @param size (int): # of words in vocabulary\n",
        "        @param freq_cutoff (int): if word occurs n < freq_cutoff times, drop the word\n",
        "        @returns vocab_entry (VocabEntry): VocabEntry instance produced from provided corpus\n",
        "        \"\"\"\n",
        "        vocab_entry = VocabEntry()\n",
        "        word_freq = Counter(chain(*corpus))\n",
        "        valid_words = [w for w, v in word_freq.items() if v >= freq_cutoff]\n",
        "        print('number of word types: {}, number of word types w/ frequency >= {}: {}'\n",
        "              .format(len(word_freq), freq_cutoff, len(valid_words)))\n",
        "        top_k_words = sorted(valid_words, key=lambda w: word_freq[w], reverse=True)[:size]\n",
        "        for word in top_k_words:\n",
        "            vocab_entry.add(word)\n",
        "        return vocab_entry\n",
        "\n",
        "\n",
        "class Vocab(object):\n",
        "    \"\"\" Vocab encapsulating src and target langauges.\n",
        "    \"\"\"\n",
        "    def __init__(self, src_vocab: VocabEntry, tgt_vocab: VocabEntry):\n",
        "        \"\"\" Init Vocab.\n",
        "        @param src_vocab (VocabEntry): VocabEntry for source language\n",
        "        @param tgt_vocab (VocabEntry): VocabEntry for target language\n",
        "        \"\"\"\n",
        "        self.src = src_vocab\n",
        "        self.tgt = tgt_vocab\n",
        "\n",
        "    @staticmethod\n",
        "    def build(src_sents, tgt_sents, vocab_size, freq_cutoff) -> 'Vocab':\n",
        "        \"\"\" Build Vocabulary.\n",
        "        @param src_sents (list[str]): Source sentences provided by read_corpus() function\n",
        "        @param tgt_sents (list[str]): Target sentences provided by read_corpus() function\n",
        "        @param vocab_size (int): Size of vocabulary for both source and target languages\n",
        "        @param freq_cutoff (int): if word occurs n < freq_cutoff times, drop the word.\n",
        "        \"\"\"\n",
        "        assert len(src_sents) == len(tgt_sents)\n",
        "\n",
        "        print('initialize source vocabulary ..')\n",
        "        src = VocabEntry.from_corpus(src_sents, vocab_size, freq_cutoff)\n",
        "\n",
        "        print('initialize target vocabulary ..')\n",
        "        tgt = VocabEntry.from_corpus(tgt_sents, vocab_size, freq_cutoff)\n",
        "\n",
        "        return Vocab(src, tgt)\n",
        "\n",
        "    def save(self, file_path):\n",
        "        \"\"\" Save Vocab to file as JSON dump.\n",
        "        @param file_path (str): file path to vocab file\n",
        "        \"\"\"\n",
        "        json.dump(dict(src_word2id=self.src.word2id, tgt_word2id=self.tgt.word2id), open(file_path, 'w'), indent=2)\n",
        "\n",
        "    @staticmethod\n",
        "    def load(file_path):\n",
        "        \"\"\" Load vocabulary from JSON dump.\n",
        "        @param file_path (str): file path to vocab file\n",
        "        @returns Vocab object loaded from JSON dump\n",
        "        \"\"\"\n",
        "        entry = json.load(open(file_path, 'r'))\n",
        "        src_word2id = entry['src_word2id']\n",
        "        tgt_word2id = entry['tgt_word2id']\n",
        "\n",
        "        return Vocab(VocabEntry(src_word2id), VocabEntry(tgt_word2id))\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\" Representation of Vocab to be used\n",
        "        when printing the object.\n",
        "        \"\"\"\n",
        "        return 'Vocab(source %d words, target %d words)' % (len(self.src), len(self.tgt))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5W-qY92P8ck"
      },
      "source": [
        "## Seq2seq model for NMT\n",
        "\n",
        "In this section, we implement the seq2seq model class for NMT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqobG2OmNl-I"
      },
      "source": [
        "from collections import namedtuple\n",
        "from typing import List, Tuple\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
        "\n",
        "Hypothesis = namedtuple('Hypothesis', ['value', 'score'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMRIArSnfSiw"
      },
      "source": [
        "First, we define a pytorch module `ModelEmbeddings` to convert inputs words to their embedding vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNBwgdgyiGe6"
      },
      "source": [
        "class ModelEmbeddings(nn.Module):\n",
        "    \"\"\"\n",
        "    Class that converts input words to their embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_size, vocab):\n",
        "        \"\"\"\n",
        "        Init the Embedding layers.\n",
        "\n",
        "        @param embed_size (int): Embedding size (dimensionality)\n",
        "        @param vocab (Vocab): Vocabulary object containing src and tgt languages\n",
        "                              See vocab.py for documentation.\n",
        "        \"\"\"\n",
        "        super(ModelEmbeddings, self).__init__()\n",
        "        self.embed_size = embed_size\n",
        "\n",
        "        # default values\n",
        "        self.source = None\n",
        "        self.target = None\n",
        "\n",
        "        src_pad_token_idx = vocab.src['<pad>']\n",
        "        tgt_pad_token_idx = vocab.tgt['<pad>']\n",
        "\n",
        "        self.source = nn.Embedding(len(vocab.src), embed_size, padding_idx=src_pad_token_idx)\n",
        "        self.target = nn.Embedding(len(vocab.tgt), embed_size, padding_idx=tgt_pad_token_idx)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tDPqxKciJyl"
      },
      "source": [
        "Then, we implement the seq2seq model for the NMT task. (All TODOs are in the class `NMT`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WppD_0QNpQc"
      },
      "source": [
        "class NMT(nn.Module):\n",
        "    \"\"\" Simple Neural Machine Translation Model:\n",
        "        - Bidrectional LSTM Encoder\n",
        "        - Unidirection LSTM Decoder\n",
        "        - Global Attention Model (Luong, et al. 2015)\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_size, hidden_size, vocab, dropout_rate=0.2):\n",
        "        \"\"\" Init NMT Model.\n",
        "\n",
        "        @param embed_size (int): Embedding size (dimensionality)\n",
        "        @param hidden_size (int): Hidden Size (dimensionality)\n",
        "        @param vocab (Vocab): Vocabulary object containing src and tgt languages\n",
        "                              See vocab.py for documentation.\n",
        "        @param dropout_rate (float): Dropout probability, for attention\n",
        "        \"\"\"\n",
        "        super(NMT, self).__init__()\n",
        "        self.model_embeddings = ModelEmbeddings(embed_size, vocab)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.vocab = vocab\n",
        "\n",
        "        # default values\n",
        "        self.encoder = None\n",
        "        self.decoder = None\n",
        "        self.h_projection = None\n",
        "        self.c_projection = None\n",
        "        self.att_projection = None\n",
        "        self.combined_output_projection = None\n",
        "        self.target_vocab_projection = None\n",
        "        self.dropout = None\n",
        "\n",
        "        # Bidirectional LSTM with bias\n",
        "        self.encoder = nn.LSTM(embed_size, hidden_size, bidirectional=True)\n",
        "        # LSTM Cell with bias\n",
        "        self.decoder = nn.LSTMCell(embed_size + hidden_size, hidden_size)\n",
        "\n",
        "        # Linear Layer with no bias), called W_{h} in the PDF.\n",
        "        self.h_projection = nn.Linear(hidden_size * 2, hidden_size, bias=False)\n",
        "        # Linear Layer with no bias), called W_{c} in the PDF.\n",
        "        self.c_projection = nn.Linear(hidden_size * 2, hidden_size, bias=False)\n",
        "        # Linear Layer with no bias), called W_{attProj} in the PDF.\n",
        "        self.att_projection = nn.Linear(hidden_size * 2, hidden_size, bias=False)\n",
        "        # Linear Layer with no bias), called W_{u} in the PDF.\n",
        "        self.combined_output_projection = nn.Linear(hidden_size * 2 + hidden_size, hidden_size, bias=False)\n",
        "        # Linear Layer with no bias), called W_{vocab} in the PDF.\n",
        "        self.target_vocab_projection = nn.Linear(hidden_size, len(vocab.tgt), bias=False)\n",
        "        # Dropout Layer\n",
        "        self.dropout = nn.Dropout(self.dropout_rate)\n",
        "\n",
        "    def forward(self, source: List[List[str]], target: List[List[str]]) -> torch.Tensor:\n",
        "        \"\"\" Take a mini-batch of source and target sentences, compute the log-likelihood of\n",
        "        target sentences under the language models learned by the NMT system.\n",
        "\n",
        "        @param source (List[List[str]]): list of source sentence tokens\n",
        "        @param target (List[List[str]]): list of target sentence tokens, wrapped by `<s>` and `</s>`\n",
        "\n",
        "        @returns scores (Tensor): a variable/tensor of shape (b, ) representing the\n",
        "                                    log-likelihood of generating the gold-standard target sentence for\n",
        "                                    each example in the input batch. Here b = batch size.\n",
        "        \"\"\"\n",
        "        # Compute sentence lengths\n",
        "        source_lengths = [len(s) for s in source]\n",
        "\n",
        "        # Convert list of lists into tensors\n",
        "        source_padded = self.vocab.src.to_input_tensor(source, device=self.device)   # Tensor: (src_len, b)\n",
        "        target_padded = self.vocab.tgt.to_input_tensor(target, device=self.device)   # Tensor: (tgt_len, b)\n",
        "\n",
        "        #     Run the network forward:\n",
        "        #     1. Apply the encoder to `source_padded` by calling `self.encode()`\n",
        "\n",
        "        x_enc, dec_init = self.encode(source_padded, source_lengths)\n",
        "        #     2. Generate sentence masks for `source_padded` by calling `self.generate_sent_masks()`\n",
        "        sent_masks = self.generate_sent_masks(x_enc, source_lengths)\n",
        "        #     3. Apply the decoder to compute combined-output by calling `self.decode()`\n",
        "        combined_outputs  = self.decode(x_enc, sent_masks, dec_init, target_padded)\n",
        "        #     4. Compute log probability distribution over the target vocabulary using the\n",
        "        #        combined_outputs returned by the `self.decode()` function.\n",
        "        P = F.log_softmax(self.target_vocab_projection(combined_outputs), dim=-1)\n",
        "\n",
        "\n",
        "        # Zero out, probabilities for which we have nothing in the target text\n",
        "        target_masks = (target_padded != self.vocab.tgt['<pad>']).float()\n",
        "\n",
        "        # Compute log probability of generating true target words\n",
        "        target_gold_words_log_prob = \\\n",
        "            torch.gather(P, index=target_padded[1:].unsqueeze(-1), dim=-1).squeeze(-1) * target_masks[1:]\n",
        "        scores = target_gold_words_log_prob.sum(dim=0)\n",
        "        return scores\n",
        "\n",
        "    def encode(self, source_padded: torch.Tensor,\n",
        "               source_lengths: List[int]) -> Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
        "        \"\"\" Apply the encoder to source sentences to obtain encoder hidden states.\n",
        "            Additionally, take the final states of the encoder and project them to obtain initial states for decoder.\n",
        "\n",
        "        @param source_padded (Tensor): Tensor of padded source sentences with shape (src_len, b), where\n",
        "                                        b = batch_size, src_len = maximum source sentence length. Note that\n",
        "                                       these have already been sorted in order of longest to shortest sentence.\n",
        "        @param source_lengths (List[int]): List of actual lengths for each of the source sentences in the batch\n",
        "        @returns enc_hiddens (Tensor): Tensor of hidden units with shape (b, src_len, h*2), where\n",
        "                                        b = batch size, src_len = maximum source sentence length, h = hidden size.\n",
        "        @returns dec_init_state (tuple(Tensor, Tensor)): Tuple of tensors representing the decoder's initial\n",
        "                                                hidden state and cell.\n",
        "        \"\"\"\n",
        "        enc_hiddens, dec_init_state = None, None\n",
        "\n",
        "        # YOUR CODE HERE (~ 8 Lines)\n",
        "        # TODO:\n",
        "        #     1. Construct Tensor `X` of source sentences with shape (src_len, b, e) using the source model embeddings.\n",
        "        #         src_len = maximum source sentence length, b = batch size, e = embedding size. \n",
        "\n",
        "        X = self.model_embeddings.source(source_padded)\n",
        "        #     2. Compute `enc_hiddens`, `last_hidden`, `last_cell` by applying the encoder to `X`.\n",
        "        #         - Before you can apply the encoder, you need to apply the `pack_padded_sequence` function to X.\n",
        "        #         - After you apply the encoder, you need to apply the `pad_packed_sequence` function to enc_hiddens.\n",
        "        #         - Note that the shape of the tensor returned by the encoder is (src_len, b, h*2) and we want to\n",
        "        #           return a tensor of shape (b, src_len, h*2) as `enc_hiddens`.\n",
        "        padded_X = pack_padded_sequence(X, source_lengths)\n",
        "        enc_hiddens, (last_hidden,last_cell) = self.encoder(padded_X)\n",
        "        enc_hiddens,_ = pad_packed_sequence(enc_hiddens)\n",
        "        enc_hiddens = enc_hiddens.permute(1,0,2)\n",
        "        #     3. Compute `dec_init_state` = (init_decoder_hidden, init_decoder_cell):\n",
        "        #         - `init_decoder_hidden`:\n",
        "        #             `last_hidden` is a tensor shape (2, b, h).\n",
        "        #             The first dimension corresponds to forwards and backwards.\n",
        "        #             Concatenate the forwards and backwards tensors to obtain a tensor shape (b, 2*h).\n",
        "        #             Apply the h_projection layer to this in order to compute init_decoder_hidden.\n",
        "        #             This is h_0^{dec} in the PDF. Here b = batch size, h = hidden size\n",
        "        #         - `init_decoder_cell`:\n",
        "        #             `last_cell` is a tensor shape (2, b, h).\n",
        "        #             The first dimension corresponds to forwards and backwards.\n",
        "        #             Concatenate the forwards and backwards tensors to obtain a tensor shape (b, 2*h).\n",
        "        #             Apply the c_projection layer to this in order to compute init_decoder_cell.\n",
        "        #             This is c_0^{dec} in the PDF. Here b = batch size, h = hidden size\n",
        "        #\n",
        "        last_fowards = last_hidden[0]\n",
        "        last_backwards = last_hidden[1]\n",
        "        last_concat =torch.cat((last_fowards,last_backwards), dim=-1)\n",
        "        init_decoder_hidden = self.h_projection(last_concat)\n",
        "\n",
        "        cell_fowards = last_cell[0]\n",
        "        cell_backwards = last_cell[1]\n",
        "        cell_concat =torch.cat((cell_fowards,cell_backwards), dim=-1)\n",
        "        init_decoder_cell = self.c_projection(cell_concat)\n",
        "\n",
        "        dec_init_state = (init_decoder_hidden, init_decoder_cell)\n",
        "   \n",
        "        # See the following docs, as you may need to use some of the following functions in your implementation:\n",
        "        #     Pack the padded sequence X before passing to the encoder:\n",
        "        #         https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pack_padded_sequence\n",
        "        #     Pad the packed sequence, enc_hiddens, returned by the encoder:\n",
        "        #         https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pad_packed_sequence\n",
        "        #     Tensor Concatenation:\n",
        "        #         https://pytorch.org/docs/stable/torch.html#torch.cat\n",
        "        #     Tensor Permute:\n",
        "        #         https://pytorch.org/docs/stable/tensors.html#torch.Tensor.permute\n",
        "\n",
        "\n",
        "        # END YOUR CODE\n",
        "\n",
        "        return enc_hiddens, dec_init_state\n",
        "\n",
        "    def decode(self, enc_hiddens: torch.Tensor, enc_masks: torch.Tensor,\n",
        "               dec_init_state: Tuple[torch.Tensor, torch.Tensor],\n",
        "               target_padded: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Compute combined output vectors for a batch.\n",
        "\n",
        "        @param enc_hiddens (Tensor): Hidden states (b, src_len, h*2), where\n",
        "                                     b = batch size, src_len = maximum source sentence length, h = hidden size.\n",
        "        @param enc_masks (Tensor): Tensor of sentence masks (b, src_len), where\n",
        "                                     b = batch size, src_len = maximum source sentence length.\n",
        "        @param dec_init_state (tuple(Tensor, Tensor)): Initial state and cell for decoder\n",
        "        @param target_padded (Tensor): Gold-standard padded target sentences (tgt_len, b), where\n",
        "                                       tgt_len = maximum target sentence length, b = batch size.\n",
        "\n",
        "        @returns combined_outputs (Tensor): combined output tensor  (tgt_len, b,  h), where\n",
        "                                        tgt_len = maximum target sentence length, b = batch_size,  h = hidden size\n",
        "        \"\"\"\n",
        "        # Chop of the <END> token for max length sentences.\n",
        "        target_padded = target_padded[:-1]\n",
        "\n",
        "        # Initialize the decoder state (hidden and cell)\n",
        "        dec_state = dec_init_state\n",
        "\n",
        "        # Initialize previous combined output vector o_{t-1} as zero\n",
        "        batch_size = enc_hiddens.size(0)\n",
        "        o_prev = torch.zeros(batch_size, self.hidden_size, device=self.device)\n",
        "\n",
        "        # Initialize a list we will use to collect the combined output o_t on each step\n",
        "        combined_outputs = []\n",
        "\n",
        "        # YOUR CODE HERE (~9 Lines)\n",
        "        # TODO:\n",
        "        #     1. Apply the attention projection layer to `enc_hiddens` to obtain `enc_hiddens_proj`,\n",
        "        #         which should be shape (b, src_len, h),\n",
        "        #         where b = batch size, src_len = maximum source length, h = hidden size.\n",
        "        #         This is applying W_{attProj} to h^enc, as described in the PDF.\n",
        "        enc_hiddens_proj  = self.att_projection(enc_hiddens)\n",
        "\n",
        "        #     2. Construct tensor `Y` of target sentences with shape (tgt_len, b, e) using the target model embeddings.\n",
        "        #         where tgt_len = maximum target sentence length, b = batch size, e = embedding size.\n",
        "\n",
        "        Y = self.model_embeddings.target(target_padded)\n",
        "        #     3. Use the torch.split function to iterate over the time dimension of Y.\n",
        "        #         Within the loop, this will give you Y_t of shape (1, b, e) where b = batch size, e = embedding size.\n",
        "        #             - Squeeze Y_t into a tensor of dimension (b, e).\n",
        "        #             - Construct Ybar_t by concatenating Y_t with o_prev.\n",
        "        #             - Use the step function to compute the the Decoder's next (cell, state) values\n",
        "        #               as well as the new combined output o_t.\n",
        "        #             - Append o_t to combined_outputs\n",
        "        #             - Update o_prev to the new o_t.\n",
        "\n",
        "        for yi in torch.split(Y, 1, dim = 0):\n",
        "          y_sqz = torch.squeeze(yi, dim = 0)\n",
        "          Ybar_t = torch.cat((y_sqz, o_prev), dim = 1)\n",
        "          d_state, com_out, e_t = self.step(Ybar_t, dec_state, enc_hiddens, enc_hiddens_proj,enc_masks)\n",
        "          combined_outputs.append(com_out)\n",
        "          o_prev = com_out\n",
        "\n",
        "\n",
        "        #     4. Use torch.stack to convert combined_outputs from a list length tgt_len of\n",
        "        #         tensors shape (b, h), to a single tensor shape (tgt_len, b, h)\n",
        "        #         where tgt_len = maximum target sentence length, b = batch size, h = hidden size.\n",
        "        #\n",
        "        combined_outputs = torch.stack(combined_outputs, dim = 0)\n",
        "        # Note:\n",
        "        #    - When using the squeeze() function make sure to specify the dimension you want to squeeze\n",
        "        #      over. Otherwise, you will remove the batch dimension accidentally, if batch_size = 1.\n",
        "        #\n",
        "        # Use the following docs to implement this functionality:\n",
        "        #     Zeros Tensor:\n",
        "        #         https://pytorch.org/docs/stable/torch.html#torch.zeros\n",
        "        #     Tensor Splitting (iteration):\n",
        "        #         https://pytorch.org/docs/stable/torch.html#torch.split\n",
        "        #     Tensor Dimension Squeezing:\n",
        "        #         https://pytorch.org/docs/stable/torch.html#torch.squeeze\n",
        "        #     Tensor Concatenation:\n",
        "        #         https://pytorch.org/docs/stable/torch.html#torch.cat\n",
        "        #     Tensor Stacking:\n",
        "        #         https://pytorch.org/docs/stable/torch.html#torch.stack\n",
        "\n",
        "  \n",
        "\n",
        "        # END YOUR CODE\n",
        "\n",
        "        return combined_outputs\n",
        "\n",
        "    def step(self, Ybar_t: torch.Tensor,\n",
        "             dec_state: Tuple[torch.Tensor, torch.Tensor],\n",
        "             enc_hiddens: torch.Tensor,\n",
        "             enc_hiddens_proj: torch.Tensor,\n",
        "             enc_masks: torch.Tensor) -> Tuple[Tuple, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\" Compute one forward step of the LSTM decoder, including the attention computation.\n",
        "\n",
        "        @param Ybar_t (Tensor): Concatenated Tensor of [Y_t o_prev], with shape (b, e + h). The input for the decoder,\n",
        "                                where b = batch size, e = embedding size, h = hidden size.\n",
        "        @param dec_state (tuple(Tensor, Tensor)): Tuple of tensors both with shape (b, h),\n",
        "                where b = batch size, h = hidden size.\n",
        "                First tensor is decoder's prev hidden state, second tensor is decoder's prev cell.\n",
        "        @param enc_hiddens (Tensor): Encoder hidden states Tensor, with shape (b, src_len, h * 2), where b = batch size,\n",
        "                                    src_len = maximum source length, h = hidden size.\n",
        "        @param enc_hiddens_proj (Tensor): Encoder hidden states Tensor, projected from (h * 2) to h.\n",
        "                Tensor is with shape (b, src_len, h),\n",
        "                where b = batch size, src_len = maximum source length, h = hidden size.\n",
        "        @param enc_masks (Tensor): Tensor of sentence masks shape (b, src_len),\n",
        "                                    where b = batch size, src_len is maximum source length.\n",
        "\n",
        "        @returns dec_state (tuple (Tensor, Tensor)): Tuple of tensors both shape (b, h),\n",
        "                where b = batch size, h = hidden size.\n",
        "                First tensor is decoder's new hidden state, second tensor is decoder's new cell.\n",
        "        @returns combined_output (Tensor): Combined output Tensor at timestep t, shape (b, h),\n",
        "                where b = batch size, h = hidden size.\n",
        "        @returns e_t (Tensor): Tensor of shape (b, src_len). It is attention scores distribution.\n",
        "                                Note: You will not use this outside of this function.\n",
        "                                      We are simply returning this value so that we can sanity check\n",
        "                                      your implementation.\n",
        "        \"\"\"\n",
        "\n",
        "        combined_output = None\n",
        "\n",
        "        # YOUR CODE HERE (~3 Lines)\n",
        "        # TODO:\n",
        "        #     1. Apply the decoder to `Ybar_t` and `dec_state`to obtain the new dec_state.\n",
        "        dec_state = self.decoder(Ybar_t, dec_state)\n",
        "        #     2. Split dec_state into its two parts (dec_hidden, dec_cell)\n",
        "        dec_hidden, dec_cell = dec_state\n",
        "        #     3. Compute the attention scores e_t, a Tensor shape (b, src_len).\n",
        "        #        Note: b = batch_size, src_len = maximum source length, h = hidden size.\n",
        "        #\n",
        "        e_t =  torch.squeeze(torch.bmm(enc_hiddens_proj, torch.unsqueeze(dec_hidden, dim=2)), dim=2)\n",
        "        #       Hints:\n",
        "        #         - dec_hidden is shape (b, h) and corresponds to h^dec_t in the PDF (batched)\n",
        "        #         - enc_hiddens_proj is shape (b, src_len, h) and corresponds to W_{attProj} h^enc (batched).\n",
        "        #         - Use batched matrix multiplication (torch.bmm) to compute e_t.\n",
        "        #         - To get the tensors into the right shapes for bmm, you'll need to do some squeezing and unsqueezing.\n",
        "        #         - When using the squeeze() function make sure to specify the dimension you want to squeeze\n",
        "        #             over. Otherwise, you will remove the batch dimension accidentally, if batch_size = 1.\n",
        "        #\n",
        "        # Use the following docs to implement this functionality:\n",
        "        #     Batch Multiplication:\n",
        "        #        https://pytorch.org/docs/stable/torch.html#torch.bmm\n",
        "        #     Tensor Unsqueeze:\n",
        "        #         https://pytorch.org/docs/stable/torch.html#torch.unsqueeze\n",
        "        #     Tensor Squeeze:\n",
        "        #         https://pytorch.org/docs/stable/torch.html#torch.squeeze\n",
        "\n",
        "\n",
        "\n",
        "        # END YOUR CODE\n",
        "\n",
        "        # Set e_t to -inf where enc_masks has 1\n",
        "        if enc_masks is not None:\n",
        "            e_t.data.masked_fill_(enc_masks.bool(), -float('inf'))\n",
        "\n",
        "        # YOUR CODE HERE (~6 Lines)\n",
        "        # TODO:\n",
        "        #     1. Apply softmax to e_t to yield alpha_t\n",
        "\n",
        "        alpha_t = nn.functional.softmax(e_t)\n",
        "        #     2. Use batched matrix multiplication between alpha_t and enc_hiddens to obtain the\n",
        "        #         attention output vector, a_t.\n",
        "        #     Hints:\n",
        "        #           - alpha_t is shape (b, src_len)\n",
        "        #           - enc_hiddens is shape (b, src_len, 2h)\n",
        "        #           - a_t should be shape (b, 2h)\n",
        "        #           - You will need to do some squeezing and unsqueezing.\n",
        "        #     Note: b = batch size, src_len = maximum source length, h = hidden size.\n",
        "        #\n",
        "        a_t = torch.squeeze(torch.bmm(torch.unsqueeze(alpha_t, dim=1), enc_hiddens), dim=1)\n",
        "        #     3. Concatenate dec_hidden with a_t to compute tensor U_t\n",
        "        U_t = torch.cat((a_t, dec_hidden), dim=1)\n",
        "        #     4. Apply the combined output projection layer to U_t to compute tensor V_t\n",
        "        V_t = self.combined_output_projection(U_t)\n",
        "        #     5. Compute tensor O_t by first applying the Tanh function and then the dropout layer.\n",
        "        #\n",
        "        O_t = self.dropout(torch.tanh(V_t))\n",
        "        # Use the following docs to implement this functionality:\n",
        "        #     Softmax:\n",
        "        #         https://pytorch.org/docs/stable/nn.html#torch.nn.functional.softmax\n",
        "        #     Batch Multiplication:\n",
        "        #        https://pytorch.org/docs/stable/torch.html#torch.bmm\n",
        "        #     Tensor View:\n",
        "        #         https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view\n",
        "        #     Tensor Concatenation:\n",
        "        #         https://pytorch.org/docs/stable/torch.html#torch.cat\n",
        "        #     Tanh:\n",
        "        #         https://pytorch.org/docs/stable/torch.html#torch.tanh\n",
        "\n",
        "\n",
        "        # END YOUR CODE\n",
        "\n",
        "        combined_output = O_t\n",
        "        return dec_state, combined_output, e_t\n",
        "\n",
        "    def generate_sent_masks(self, enc_hiddens: torch.Tensor, source_lengths: List[int]) -> torch.Tensor:\n",
        "        \"\"\" Generate sentence masks for encoder hidden states.\n",
        "\n",
        "        @param enc_hiddens (Tensor): encodings of shape (b, src_len, 2*h), where b = batch size,\n",
        "                                     src_len = max source length, h = hidden size.\n",
        "        @param source_lengths (List[int]): List of actual lengths for each of the sentences in the batch.\n",
        "\n",
        "        @returns enc_masks (Tensor): Tensor of sentence masks of shape (b, src_len),\n",
        "                                    where src_len = max source length, h = hidden size.\n",
        "        \"\"\"\n",
        "        enc_masks = torch.zeros(enc_hiddens.size(0), enc_hiddens.size(1), dtype=torch.float)\n",
        "        for e_id, src_len in enumerate(source_lengths):\n",
        "            enc_masks[e_id, src_len:] = 1\n",
        "        return enc_masks.to(self.device)\n",
        "\n",
        "    def beam_search(self, src_sent: List[str],\n",
        "                    beam_size: int = 5, max_decoding_time_step: int = 70) -> List[Hypothesis]:\n",
        "        \"\"\" Given a single source sentence, perform beam search, yielding translations in the target language.\n",
        "        @param src_sent (List[str]): a single source sentence (words)\n",
        "        @param beam_size (int): beam size\n",
        "        @param max_decoding_time_step (int): maximum number of time steps to unroll the decoding RNN\n",
        "        @returns hypotheses (List[Hypothesis]): a list of hypothesis, each hypothesis has two fields:\n",
        "                value: List[str]: the decoded target sentence, represented as a list of words\n",
        "                score: float: the log-likelihood of the target sentence\n",
        "        \"\"\"\n",
        "        src_sents_var = self.vocab.src.to_input_tensor([src_sent], self.device)\n",
        "\n",
        "        src_encodings, dec_init_vec = self.encode(src_sents_var, [len(src_sent)])\n",
        "        src_encodings_att_linear = self.att_projection(src_encodings)\n",
        "\n",
        "        h_tm1 = dec_init_vec\n",
        "        att_tm1 = torch.zeros(1, self.hidden_size, device=self.device)\n",
        "\n",
        "        hypotheses = [['<s>']]\n",
        "        hyp_scores = torch.zeros(len(hypotheses), dtype=torch.float, device=self.device)\n",
        "        completed_hypotheses = []\n",
        "\n",
        "        t = 0\n",
        "        while len(completed_hypotheses) < beam_size and t < max_decoding_time_step:\n",
        "            t += 1\n",
        "            hyp_num = len(hypotheses)\n",
        "\n",
        "            exp_src_encodings = src_encodings.expand(hyp_num,\n",
        "                                                     src_encodings.size(1),\n",
        "                                                     src_encodings.size(2))\n",
        "\n",
        "            exp_src_encodings_att_linear = src_encodings_att_linear.expand(hyp_num,\n",
        "                                                                           src_encodings_att_linear.size(1),\n",
        "                                                                           src_encodings_att_linear.size(2))\n",
        "\n",
        "            y_tm1 = torch.tensor([self.vocab.tgt[hyp[-1]] for hyp in hypotheses], dtype=torch.long, device=self.device)\n",
        "            y_t_embed = self.model_embeddings.target(y_tm1)\n",
        "\n",
        "            x = torch.cat([y_t_embed, att_tm1], dim=-1)\n",
        "\n",
        "            (h_t, cell_t), att_t, _ = self.step(x, h_tm1, exp_src_encodings,\n",
        "                                                exp_src_encodings_att_linear, enc_masks=None)\n",
        "\n",
        "            # log probabilities over target words\n",
        "            log_p_t = F.log_softmax(self.target_vocab_projection(att_t), dim=-1)\n",
        "\n",
        "            live_hyp_num = beam_size - len(completed_hypotheses)\n",
        "            contiuating_hyp_scores = (hyp_scores.unsqueeze(1).expand_as(log_p_t) + log_p_t).view(-1)\n",
        "            top_cand_hyp_scores, top_cand_hyp_pos = torch.topk(contiuating_hyp_scores, k=live_hyp_num)\n",
        "\n",
        "            prev_hyp_ids = top_cand_hyp_pos // len(self.vocab.tgt)\n",
        "            hyp_word_ids = top_cand_hyp_pos % len(self.vocab.tgt)\n",
        "\n",
        "            new_hypotheses = []\n",
        "            live_hyp_ids = []\n",
        "            new_hyp_scores = []\n",
        "\n",
        "            for prev_hyp_id, hyp_word_id, cand_new_hyp_score in zip(prev_hyp_ids, hyp_word_ids, top_cand_hyp_scores):\n",
        "                prev_hyp_id = prev_hyp_id.item()\n",
        "                hyp_word_id = hyp_word_id.item()\n",
        "                cand_new_hyp_score = cand_new_hyp_score.item()\n",
        "\n",
        "                hyp_word = self.vocab.tgt.id2word[hyp_word_id]\n",
        "                new_hyp_sent = hypotheses[prev_hyp_id] + [hyp_word]\n",
        "                if hyp_word == '</s>':\n",
        "                    completed_hypotheses.append(Hypothesis(value=new_hyp_sent[1:-1],\n",
        "                                                           score=cand_new_hyp_score))\n",
        "                else:\n",
        "                    new_hypotheses.append(new_hyp_sent)\n",
        "                    live_hyp_ids.append(prev_hyp_id)\n",
        "                    new_hyp_scores.append(cand_new_hyp_score)\n",
        "\n",
        "            if len(completed_hypotheses) == beam_size:\n",
        "                break\n",
        "\n",
        "            live_hyp_ids = torch.tensor(live_hyp_ids, dtype=torch.long, device=self.device)\n",
        "            h_tm1 = (h_t[live_hyp_ids], cell_t[live_hyp_ids])\n",
        "            att_tm1 = att_t[live_hyp_ids]\n",
        "\n",
        "            hypotheses = new_hypotheses\n",
        "            hyp_scores = torch.tensor(new_hyp_scores, dtype=torch.float, device=self.device)\n",
        "\n",
        "        if len(completed_hypotheses) == 0:\n",
        "            completed_hypotheses.append(Hypothesis(value=hypotheses[0][1:],\n",
        "                                                   score=hyp_scores[0].item()))\n",
        "\n",
        "        completed_hypotheses.sort(key=lambda hyp: hyp.score, reverse=True)\n",
        "\n",
        "        return completed_hypotheses\n",
        "\n",
        "    @property\n",
        "    def device(self) -> torch.device:\n",
        "        \"\"\" Determine which device to place the Tensors upon, CPU or GPU.\n",
        "        \"\"\"\n",
        "        return self.model_embeddings.source.weight.device\n",
        "\n",
        "    @staticmethod\n",
        "    def load(model_path: str):\n",
        "        \"\"\" Load the model from a file.\n",
        "        @param model_path (str): path to model\n",
        "        \"\"\"\n",
        "        params = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
        "        args = params['args']\n",
        "        model = NMT(vocab=params['vocab'], **args)\n",
        "        model.load_state_dict(params['state_dict'])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def save(self, path: str):\n",
        "        \"\"\" Save the odel to a file.\n",
        "        @param path (str): path to the model\n",
        "        \"\"\"\n",
        "\n",
        "        params = {\n",
        "            'args': dict(embed_size=self.model_embeddings.embed_size,\n",
        "                         hidden_size=self.hidden_size,\n",
        "                         dropout_rate=self.dropout_rate),\n",
        "            'vocab': self.vocab,\n",
        "            'state_dict': self.state_dict()\n",
        "        }\n",
        "\n",
        "        torch.save(params, path)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_VjclKMjS5"
      },
      "source": [
        "## Pass sanity checks before training the model\n",
        "\n",
        "Please follow the instructions to complete some functions in the class `NMT` and pass sanity checks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggh7s0EZRl7-"
      },
      "source": [
        "Define some constants and the reinitalization function used for sanity checks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqd87eiqRuml"
      },
      "source": [
        "BATCH_SIZE = 5\n",
        "EMBED_SIZE = 3\n",
        "HIDDEN_SIZE = 3\n",
        "DROPOUT_RATE = 0.0\n",
        "\n",
        "def reinitialize_layers(model):\n",
        "    \"\"\" Reinitialize the Layer Weights for Sanity Checks.\n",
        "    \"\"\"\n",
        "    def init_weights(m):\n",
        "        if type(m) == nn.Linear:\n",
        "            m.weight.data.fill_(0.3)\n",
        "            if m.bias is not None:\n",
        "                m.bias.data.fill_(0.1)\n",
        "        elif type(m) == nn.Embedding:\n",
        "            m.weight.data.fill_(0.15)\n",
        "        elif type(m) == nn.Dropout:\n",
        "            nn.Dropout(DROPOUT_RATE)\n",
        "    with torch.no_grad():\n",
        "        model.apply(init_weights)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDP2WNMMQwVP"
      },
      "source": [
        "### Implement the `encode` function in the class `NMT`.\n",
        "\n",
        "Complete the `encode` function in the class `NMT`. This function applies the encoder to source sentences to obtain encoder hidden states.\n",
        "\n",
        "Run the following code to check if your implementation is correct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTx_ERH6RZ6N"
      },
      "source": [
        "def encode_sanity_check(model, src_sents, tgt_sents, vocab):\n",
        "    \"\"\"\n",
        "        Compares student output to that of model with dummy data.\n",
        "    \"\"\"\n",
        "    print(\"Running Sanity Check: Encode\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    # Configure for Testing\n",
        "    reinitialize_layers(model)\n",
        "    source_lengths = [len(s) for s in src_sents]\n",
        "    source_padded = model.vocab.src.to_input_tensor(src_sents, device=model.device)\n",
        "\n",
        "    print(source_padded.shape)\n",
        "\n",
        "    # Load Outputs\n",
        "    enc_hiddens_target = torch.load('NMT_data/sanity_check/enc_hiddens.pkl')\n",
        "    dec_init_state_target = torch.load('NMT_data/sanity_check/dec_init_state.pkl')\n",
        "\n",
        "    # Test\n",
        "    with torch.no_grad():\n",
        "        enc_hiddens_pred, dec_init_state_pred = model.encode(source_padded, source_lengths)\n",
        "    assert(np.allclose(enc_hiddens_target.numpy(), enc_hiddens_pred.numpy())), \\\n",
        "        \"enc_hiddens is incorrect: it should be:\\n {} but is:\\n{}\".format(enc_hiddens_target, enc_hiddens_pred)\n",
        "    print(\"enc_hiddens Sanity Checks Passed!\")\n",
        "    assert(np.allclose(dec_init_state_target[0].numpy(), dec_init_state_pred[0].numpy())), \\\n",
        "        \"dec_init_state[0] is incorrect: it should be:\\n \" \\\n",
        "        \"{} but is:\\n{}\".format(dec_init_state_target[0], dec_init_state_pred[0])\n",
        "    print(\"dec_init_state[0] Sanity Checks Passed!\")\n",
        "    assert(np.allclose(dec_init_state_target[1].numpy(), dec_init_state_pred[1].numpy())), \\\n",
        "        \"dec_init_state[1] is incorrect: it should be:\\n \" \\\n",
        "        \"{} but is:\\n{}\".format(dec_init_state_target[1], dec_init_state_pred[1])\n",
        "    print(\"dec_init_state[1] Sanity Checks Passed!\")\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Encode: All Sanity Checks Passed!\")\n",
        "    print(\"-\" * 80)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz_sHkwVT2dU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1f99f3b-1f89-441c-e84f-96586158230d"
      },
      "source": [
        "seed = 1234\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "np.random.seed(seed * 13 // 7)\n",
        "\n",
        "train_data_src = read_corpus('NMT_data/sanity_check/train_sanity_check.es', 'src')\n",
        "train_data_tgt = read_corpus('NMT_data/sanity_check/train_sanity_check.en', 'tgt')\n",
        "train_data = list(zip(train_data_src, train_data_tgt))\n",
        "\n",
        "for src_sents, tgt_sents in batch_iter(train_data, batch_size=BATCH_SIZE, shuffle=True):\n",
        "        src_sents = src_sents\n",
        "        tgt_sents = tgt_sents\n",
        "        break\n",
        "vocab = Vocab.load('NMT_data/sanity_check/vocab_sanity_check.json')\n",
        "\n",
        "model = NMT(\n",
        "        embed_size=EMBED_SIZE,\n",
        "        hidden_size=HIDDEN_SIZE,\n",
        "        dropout_rate=DROPOUT_RATE,\n",
        "        vocab=vocab)\n",
        "\n",
        "encode_sanity_check(model, src_sents, tgt_sents, vocab)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Sanity Check: Encode\n",
            "--------------------------------------------------------------------------------\n",
            "torch.Size([20, 5])\n",
            "enc_hiddens Sanity Checks Passed!\n",
            "dec_init_state[0] Sanity Checks Passed!\n",
            "dec_init_state[1] Sanity Checks Passed!\n",
            "--------------------------------------------------------------------------------\n",
            "Encode: All Sanity Checks Passed!\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kflLEkMcXA02"
      },
      "source": [
        "### Implement `decode` function in the class `NMT`\n",
        "\n",
        "Complete the `decode` function in the class `NMT`. This function computes combined outputvectors for a batch.\n",
        "\n",
        "Run the following code to check if your implementation is correct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7v6_F9fXRwb"
      },
      "source": [
        "def decode_sanity_check(model, src_sents, tgt_sents, vocab):\n",
        "    \"\"\"\n",
        "        Compares student output to that of model with dummy data.\n",
        "    \"\"\"\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Running Sanity Check: Decode\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    # Load Inputs\n",
        "    dec_init_state = torch.load('NMT_data/sanity_check/dec_init_state.pkl')\n",
        "    enc_hiddens = torch.load('NMT_data/sanity_check/enc_hiddens.pkl')\n",
        "    enc_masks = torch.load('NMT_data/sanity_check/enc_masks.pkl')\n",
        "    target_padded = torch.load('NMT_data/sanity_check/target_padded.pkl')\n",
        "\n",
        "    # Load Outputs\n",
        "    combined_outputs_target = torch.load('NMT_data/sanity_check/combined_outputs.pkl')\n",
        "\n",
        "    # Configure for Testing\n",
        "    reinitialize_layers(model)\n",
        "    COUNTER = [0]\n",
        "\n",
        "    def stepFunction(Ybar_t, dec_state, enc_hiddens, enc_hiddens_proj, enc_masks):\n",
        "        dec_state = torch.load('NMT_data/sanity_check/step_dec_state_{}.pkl'.format(COUNTER[0]))\n",
        "        o_t = torch.load('NMT_data/sanity_check/step_o_t_{}.pkl'.format(COUNTER[0]))\n",
        "        COUNTER[0] += 1\n",
        "        return dec_state, o_t, None\n",
        "    model.step = stepFunction\n",
        "\n",
        "    # Run Tests\n",
        "    with torch.no_grad():\n",
        "        combined_outputs_pred = model.decode(enc_hiddens, enc_masks, dec_init_state, target_padded)\n",
        "    assert(np.allclose(combined_outputs_pred.numpy(), combined_outputs_target.numpy())), \\\n",
        "        \"combined_outputs is incorrect: \" \\\n",
        "        \"it should be:\\n {} but is:\\n{}\".format(combined_outputs_target, combined_outputs_pred)\n",
        "    print(\"combined_outputs Sanity Checks Passed!\")\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Decode: All Sanity Checks Passed!\")\n",
        "    print(\"-\" * 80)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej3EhDkhXXNA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9845a52c-d6ca-41f3-b924-f1f62137d766"
      },
      "source": [
        "seed = 1234\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "np.random.seed(seed * 13 // 7)\n",
        "\n",
        "train_data_src = read_corpus('NMT_data/sanity_check/train_sanity_check.es', 'src')\n",
        "train_data_tgt = read_corpus('NMT_data/sanity_check/train_sanity_check.en', 'tgt')\n",
        "train_data = list(zip(train_data_src, train_data_tgt))\n",
        "\n",
        "for src_sents, tgt_sents in batch_iter(train_data, batch_size=BATCH_SIZE, shuffle=True):\n",
        "        src_sents = src_sents\n",
        "        tgt_sents = tgt_sents\n",
        "        break\n",
        "vocab = Vocab.load('NMT_data/sanity_check/vocab_sanity_check.json')\n",
        "\n",
        "model = NMT(\n",
        "        embed_size=EMBED_SIZE,\n",
        "        hidden_size=HIDDEN_SIZE,\n",
        "        dropout_rate=DROPOUT_RATE,\n",
        "        vocab=vocab)\n",
        "\n",
        "decode_sanity_check(model, src_sents, tgt_sents, vocab)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Running Sanity Check: Decode\n",
            "--------------------------------------------------------------------------------\n",
            "combined_outputs Sanity Checks Passed!\n",
            "--------------------------------------------------------------------------------\n",
            "Decode: All Sanity Checks Passed!\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_s_IW6-X1Xx"
      },
      "source": [
        "### Implement `step` function in the class `NMT`\n",
        "\n",
        "\n",
        "Complete the `step` function in the class `NMT`. This function is a forward step of the LSTM decoder, including the attention computation.\n",
        "\n",
        "Run the following code to check if your implementation is correct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dUFcc85aETE"
      },
      "source": [
        "def step_sanity_check(model, src_sents, tgt_sents, vocab):\n",
        "    \"\"\"\n",
        "        Compares student output to that of model with dummy data.\n",
        "    \"\"\"\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Running Sanity Check: Step\")\n",
        "    print(\"-\" * 80)\n",
        "    reinitialize_layers(model)\n",
        "\n",
        "    # Inputs\n",
        "    Ybar_t = torch.load('NMT_data/sanity_check/Ybar_t.pkl')\n",
        "    dec_init_state = torch.load('NMT_data/sanity_check/dec_init_state.pkl')\n",
        "    enc_hiddens = torch.load('NMT_data/sanity_check/enc_hiddens.pkl')\n",
        "    enc_masks = torch.load('NMT_data/sanity_check/enc_masks.pkl')\n",
        "    enc_hiddens_proj = torch.load('NMT_data/sanity_check/enc_hiddens_proj.pkl')\n",
        "\n",
        "    # Output\n",
        "    dec_state_target = torch.load('NMT_data/sanity_check/dec_state.pkl')\n",
        "    o_t_target = torch.load('NMT_data/sanity_check/o_t.pkl')\n",
        "    e_t_target = torch.load('NMT_data/sanity_check/e_t.pkl')\n",
        "\n",
        "    # Run Tests\n",
        "    with torch.no_grad():\n",
        "        dec_state_pred, o_t_pred, e_t_pred = \\\n",
        "            model.step(Ybar_t, dec_init_state, enc_hiddens, enc_hiddens_proj, enc_masks)\n",
        "    assert(np.allclose(dec_state_target[0].numpy(), dec_state_pred[0].numpy())), \\\n",
        "        \"decoder_state[0] is incorrect: it should be:\\n {} but is:\\n{}\".format(dec_state_target[0], dec_state_pred[0])\n",
        "    print(\"dec_state[0] Sanity Checks Passed!\")\n",
        "    assert(np.allclose(dec_state_target[1].numpy(), dec_state_pred[1].numpy())), \\\n",
        "        \"decoder_state[1] is incorrect: it should be:\\n {} but is:\\n{}\".format(dec_state_target[1], dec_state_pred[1])\n",
        "    print(\"dec_state[1] Sanity Checks Passed!\")\n",
        "    assert(np.allclose(o_t_target.numpy(), o_t_pred.numpy())), \\\n",
        "        \"combined_output is incorrect: it should be:\\n {} but is:\\n{}\".format(o_t_target, o_t_pred)\n",
        "    print(\"combined_output  Sanity Checks Passed!\")\n",
        "    assert(np.allclose(e_t_target.numpy(), e_t_pred.numpy())), \\\n",
        "        \"e_t is incorrect: it should be:\\n {} but is:\\n{}\".format(e_t_target, e_t_pred)\n",
        "    print(\"e_t Sanity Checks Passed!\")\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Step: All Sanity Checks Passed!\")\n",
        "    print(\"-\" * 80)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYITmk2DaJ3k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "256c27e8-faca-4ffd-d90d-135d6d7d2403"
      },
      "source": [
        "seed = 1234\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "np.random.seed(seed * 13 // 7)\n",
        "\n",
        "train_data_src = read_corpus('NMT_data/sanity_check/train_sanity_check.es', 'src')\n",
        "train_data_tgt = read_corpus('NMT_data/sanity_check/train_sanity_check.en', 'tgt')\n",
        "train_data = list(zip(train_data_src, train_data_tgt))\n",
        "\n",
        "for src_sents, tgt_sents in batch_iter(train_data, batch_size=BATCH_SIZE, shuffle=True):\n",
        "        src_sents = src_sents\n",
        "        tgt_sents = tgt_sents\n",
        "        break\n",
        "vocab = Vocab.load('NMT_data/sanity_check/vocab_sanity_check.json')\n",
        "\n",
        "model = NMT(\n",
        "        embed_size=EMBED_SIZE,\n",
        "        hidden_size=HIDDEN_SIZE,\n",
        "        dropout_rate=DROPOUT_RATE,\n",
        "        vocab=vocab)\n",
        "\n",
        "step_sanity_check(model, src_sents, tgt_sents, vocab)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Running Sanity Check: Step\n",
            "--------------------------------------------------------------------------------\n",
            "dec_state[0] Sanity Checks Passed!\n",
            "dec_state[1] Sanity Checks Passed!\n",
            "combined_output  Sanity Checks Passed!\n",
            "e_t Sanity Checks Passed!\n",
            "--------------------------------------------------------------------------------\n",
            "Step: All Sanity Checks Passed!\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:317: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mbf1FkZteHIW"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "In this section, we define the trianing process and train the seq2seq model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2mK-v0Hyow7"
      },
      "source": [
        "import math\n",
        "import time\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_qQJrGLmxy-"
      },
      "source": [
        "Write the function `evaluate_ppl` to evaluate perpleixty on dev sentences. \n",
        "\n",
        "This function is used to evaluate the model during training, i.e., we pick the model with the best perplexity on the dev set as our final model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_n978SMkAfL"
      },
      "source": [
        "def evaluate_ppl(model, dev_data, batch_size=32):\n",
        "    \"\"\" Evaluate perplexity on dev sentences\n",
        "    @param model (NMT): NMT Model\n",
        "    @param dev_data (list of (src_sent, tgt_sent)): list of tuples containing source and target sentence\n",
        "    @param batch_size (batch size)\n",
        "    @returns ppl (perplixty on dev sentences)\n",
        "    \"\"\"\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "\n",
        "    cum_loss = 0.\n",
        "    cum_tgt_words = 0.\n",
        "\n",
        "    # no_grad() signals backend to throw away all gradients\n",
        "    with torch.no_grad():\n",
        "        for src_sents, tgt_sents in batch_iter(dev_data, batch_size):\n",
        "            loss = -model(src_sents, tgt_sents).sum()\n",
        "\n",
        "            cum_loss += loss.item()\n",
        "            tgt_word_num_to_predict = sum(len(s[1:]) for s in tgt_sents)  # omitting leading `<s>`\n",
        "            cum_tgt_words += tgt_word_num_to_predict\n",
        "\n",
        "        ppl = np.exp(cum_loss / cum_tgt_words)\n",
        "\n",
        "    if was_training:\n",
        "        model.train()\n",
        "\n",
        "    return ppl"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGASi8VMnZnW"
      },
      "source": [
        "Define constants (hyper-parameters) used during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1IIx6-32qcI"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "EMBED_SIZE = 64\n",
        "HIDDEN_SIZE = 64\n",
        "DROPOUT_RATE = 0.3\n",
        "\n",
        "LOG_EVERY = 10\n",
        "VALID_NITER = 100\n",
        "PATIENCE = 5\n",
        "LR = 0.001\n",
        "LR_DECAY = 0.5\n",
        "MAX_EPOCH = 50\n",
        "MAX_NUM_TRIAL = 5\n",
        "\n",
        "MODEL_PATH = \"model.bin\""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfIbsy0qnm4v"
      },
      "source": [
        "Write the `train` function, which takes training set, dev set, and vocabulary and performs Maximum Likelihood training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeZgvg2VkRQd"
      },
      "source": [
        "def train(train_src, train_tgt, dev_src, dev_tgt, vocab):\n",
        "    train_data_src = read_corpus(train_src, source='src')\n",
        "    train_data_tgt = read_corpus(train_tgt, source='tgt')\n",
        "    dev_data_src = read_corpus(dev_src, source='src')\n",
        "    dev_data_tgt = read_corpus(dev_tgt, source='tgt')\n",
        "\n",
        "    train_data = list(zip(train_data_src, train_data_tgt))\n",
        "    dev_data = list(zip(dev_data_src, dev_data_tgt))\n",
        "\n",
        "    model = NMT(embed_size=EMBED_SIZE,\n",
        "                hidden_size=HIDDEN_SIZE,\n",
        "                dropout_rate=DROPOUT_RATE,\n",
        "                vocab=vocab)\n",
        "    model.train()\n",
        "\n",
        "    # initialize model parameters\n",
        "    for p in model.parameters():\n",
        "        p.data.uniform_(-0.1, 0.1)\n",
        "\n",
        "    vocab_mask = torch.ones(len(vocab.tgt))\n",
        "    vocab_mask[vocab.tgt['<pad>']] = 0\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print('use device: %s' % device)\n",
        "\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "    num_trial = 0\n",
        "    train_iter = patience = cum_loss = report_loss = cum_tgt_words = report_tgt_words = 0\n",
        "    cum_examples = report_examples = epoch = valid_num = 0\n",
        "    hist_valid_scores = []\n",
        "    train_time = begin_time = time.time()\n",
        "    print('begin Maximum Likelihood training')\n",
        "\n",
        "    while True:\n",
        "        epoch += 1\n",
        "        batch_num = math.ceil(len(train_data) / BATCH_SIZE)\n",
        "        current_iter = 0\n",
        "        for src_sents, tgt_sents in batch_iter(train_data, batch_size=BATCH_SIZE, shuffle=True):\n",
        "            current_iter += 1\n",
        "            train_iter += 1\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            batch_size = len(src_sents)\n",
        "            example_losses = -model(src_sents, tgt_sents)\n",
        "            batch_loss = example_losses.sum()\n",
        "            loss = batch_loss / batch_size\n",
        "            loss.backward()\n",
        "\n",
        "            # clip gradient\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            batch_losses_val = batch_loss.item()\n",
        "            report_loss += batch_losses_val\n",
        "            cum_loss += batch_losses_val\n",
        "\n",
        "            # omitting leading `<s>`\n",
        "            tgt_words_num_to_predict = sum(len(s[1:]) for s in tgt_sents)\n",
        "            report_tgt_words += tgt_words_num_to_predict\n",
        "            cum_tgt_words += tgt_words_num_to_predict\n",
        "            report_examples += batch_size\n",
        "            cum_examples += batch_size\n",
        "\n",
        "            if train_iter % LOG_EVERY == 0:\n",
        "                print('epoch %d (%d / %d), iter %d, avg. loss %.2f, avg. ppl %.2f '\n",
        "                      'cum. examples %d, speed %.2f words/sec, time elapsed %.2f sec' %\n",
        "                      (epoch, current_iter, batch_num, train_iter,\n",
        "                       report_loss / report_examples,\n",
        "                       math.exp(report_loss / report_tgt_words),\n",
        "                       cum_examples,\n",
        "                       report_tgt_words / (time.time() - train_time),\n",
        "                       time.time() - begin_time))\n",
        "\n",
        "                train_time = time.time()\n",
        "                report_loss = report_tgt_words = report_examples = 0.\n",
        "\n",
        "            # perform validation\n",
        "            if train_iter % VALID_NITER == 0:\n",
        "                print('epoch %d, iter %d, cum. loss %.2f, cum. ppl %.2f cum. examples %d' % (epoch, train_iter,\n",
        "                      cum_loss / cum_examples,\n",
        "                      np.exp(cum_loss / cum_tgt_words),\n",
        "                      cum_examples))\n",
        "\n",
        "                cum_loss = cum_examples = cum_tgt_words = 0.\n",
        "                valid_num += 1\n",
        "\n",
        "                print('begin validation ...')\n",
        "\n",
        "                # compute dev. ppl and bleu\n",
        "                dev_ppl = evaluate_ppl(model, dev_data, batch_size=128)   # dev batch size can be a bit larger\n",
        "                valid_metric = -dev_ppl\n",
        "\n",
        "                print('validation: iter %d, dev. ppl %f' % (train_iter, dev_ppl))\n",
        "\n",
        "                is_better = len(hist_valid_scores) == 0 or valid_metric > max(hist_valid_scores)\n",
        "                hist_valid_scores.append(valid_metric)\n",
        "\n",
        "                if is_better:\n",
        "                    patience = 0\n",
        "                    print('epoch %d, iter %d: save currently the best model to [%s]' %\n",
        "                          (epoch, train_iter, MODEL_PATH))\n",
        "                    model.save(MODEL_PATH)\n",
        "                    torch.save(optimizer.state_dict(), MODEL_PATH + '.optim')\n",
        "                elif patience < PATIENCE:\n",
        "                    patience += 1\n",
        "                    print('hit patience %d' % patience)\n",
        "\n",
        "                    if patience == PATIENCE:\n",
        "                        num_trial += 1\n",
        "                        print('hit #%d trial' % num_trial)\n",
        "                        if num_trial == MAX_NUM_TRIAL:\n",
        "                            print('early stop!')\n",
        "                            exit(0)\n",
        "\n",
        "                        # decay lr, and restore from previously best checkpoint\n",
        "                        lr = optimizer.param_groups[0]['lr'] * LR_DECAY\n",
        "                        print('load previously best model and decay learning rate to %f' % lr)\n",
        "\n",
        "                        # load model\n",
        "                        params = torch.load(MODEL_PATH, map_location=lambda storage, loc: storage)\n",
        "                        model.load_state_dict(params['state_dict'])\n",
        "                        model = model.to(device)\n",
        "\n",
        "                        print('restore parameters of the optimizers')\n",
        "                        optimizer.load_state_dict(torch.load(MODEL_PATH + '.optim'))\n",
        "\n",
        "                        # set new lr\n",
        "                        for param_group in optimizer.param_groups:\n",
        "                            param_group['lr'] = lr\n",
        "\n",
        "                        # reset patience\n",
        "                        patience = 0\n",
        "\n",
        "        if epoch == MAX_EPOCH:\n",
        "            print('reached maximum number of epochs!')\n",
        "            break"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9DM-b2ApfVk"
      },
      "source": [
        "First, build model vocabulary using training corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJkfbFmmpmNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0d59c63-1f71-4b5a-87d3-1288c35d36ad"
      },
      "source": [
        "VOCAB_SIZE = 5000\n",
        "FREQ_CUTOFF = 2\n",
        "\n",
        "src_sents = read_corpus('NMT_data/data/train.fr', source='src')\n",
        "tgt_sents = read_corpus('NMT_data/data/train.en', source='tgt')\n",
        "vocab = Vocab.build(src_sents, tgt_sents, VOCAB_SIZE, FREQ_CUTOFF)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize source vocabulary ..\n",
            "number of word types: 1379, number of word types w/ frequency >= 2: 1305\n",
            "initialize target vocabulary ..\n",
            "number of word types: 1361, number of word types w/ frequency >= 2: 1278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7IsImbEpn2P"
      },
      "source": [
        "Train the model! (**NOTE**: Training should take around 9 min on CPU and 6 min on GPU)\n",
        "\n",
        "The following code will load the training and development sets and start the training process using the model that you just completed.\n",
        "\n",
        "The best model will be saved in `model.bin`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVps-0x63iw0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f91e02c-6e7b-44a3-f24a-cbc7fa8450dc"
      },
      "source": [
        "train(train_src='NMT_data/data/train.fr', train_tgt='NMT_data/data/train.en', dev_src='NMT_data/data/dev.fr', dev_tgt='NMT_data/data/dev.en', vocab=vocab)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use device: cpu\n",
            "begin Maximum Likelihood training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:317: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 (10 / 272), iter 10, avg. loss 56.99, avg. ppl 1227.62 cum. examples 320, speed 5693.85 words/sec, time elapsed 0.45 sec\n",
            "epoch 1 (20 / 272), iter 20, avg. loss 53.52, avg. ppl 840.95 cum. examples 640, speed 5492.60 words/sec, time elapsed 0.91 sec\n",
            "epoch 1 (30 / 272), iter 30, avg. loss 46.45, avg. ppl 295.58 cum. examples 960, speed 6776.80 words/sec, time elapsed 1.30 sec\n",
            "epoch 1 (40 / 272), iter 40, avg. loss 41.65, avg. ppl 170.44 cum. examples 1280, speed 6574.08 words/sec, time elapsed 1.69 sec\n",
            "epoch 1 (50 / 272), iter 50, avg. loss 41.68, avg. ppl 157.59 cum. examples 1600, speed 6256.02 words/sec, time elapsed 2.12 sec\n",
            "epoch 1 (60 / 272), iter 60, avg. loss 39.18, avg. ppl 141.48 cum. examples 1920, speed 5574.75 words/sec, time elapsed 2.57 sec\n",
            "epoch 1 (70 / 272), iter 70, avg. loss 40.94, avg. ppl 150.51 cum. examples 2240, speed 5330.69 words/sec, time elapsed 3.06 sec\n",
            "epoch 1 (80 / 272), iter 80, avg. loss 40.56, avg. ppl 149.47 cum. examples 2560, speed 5027.51 words/sec, time elapsed 3.58 sec\n",
            "epoch 1 (90 / 272), iter 90, avg. loss 39.80, avg. ppl 142.87 cum. examples 2880, speed 5535.74 words/sec, time elapsed 4.04 sec\n",
            "epoch 1 (100 / 272), iter 100, avg. loss 41.55, avg. ppl 159.66 cum. examples 3200, speed 5760.64 words/sec, time elapsed 4.50 sec\n",
            "epoch 1, iter 100, cum. loss 44.23, cum. ppl 237.57 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 100, dev. ppl 133.769947\n",
            "epoch 1, iter 100: save currently the best model to [model.bin]\n",
            "epoch 1 (110 / 272), iter 110, avg. loss 40.53, avg. ppl 147.00 cum. examples 320, speed 4148.90 words/sec, time elapsed 5.12 sec\n",
            "epoch 1 (120 / 272), iter 120, avg. loss 40.20, avg. ppl 147.83 cum. examples 640, speed 5941.95 words/sec, time elapsed 5.56 sec\n",
            "epoch 1 (130 / 272), iter 130, avg. loss 39.66, avg. ppl 143.14 cum. examples 960, speed 5250.14 words/sec, time elapsed 6.04 sec\n",
            "epoch 1 (140 / 272), iter 140, avg. loss 40.44, avg. ppl 144.86 cum. examples 1280, speed 5928.36 words/sec, time elapsed 6.48 sec\n",
            "epoch 1 (150 / 272), iter 150, avg. loss 41.41, avg. ppl 152.51 cum. examples 1600, speed 5738.47 words/sec, time elapsed 6.94 sec\n",
            "epoch 1 (160 / 272), iter 160, avg. loss 40.84, avg. ppl 150.58 cum. examples 1920, speed 6096.88 words/sec, time elapsed 7.37 sec\n",
            "epoch 1 (170 / 272), iter 170, avg. loss 40.76, avg. ppl 144.70 cum. examples 2240, speed 5770.88 words/sec, time elapsed 7.83 sec\n",
            "epoch 1 (180 / 272), iter 180, avg. loss 39.73, avg. ppl 144.10 cum. examples 2560, speed 5864.06 words/sec, time elapsed 8.26 sec\n",
            "epoch 1 (190 / 272), iter 190, avg. loss 38.51, avg. ppl 131.77 cum. examples 2880, speed 5985.30 words/sec, time elapsed 8.68 sec\n",
            "epoch 1 (200 / 272), iter 200, avg. loss 40.85, avg. ppl 150.57 cum. examples 3200, speed 5802.49 words/sec, time elapsed 9.13 sec\n",
            "epoch 1, iter 200, cum. loss 40.30, cum. ppl 145.66 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 200, dev. ppl 129.893202\n",
            "epoch 1, iter 200: save currently the best model to [model.bin]\n",
            "epoch 1 (210 / 272), iter 210, avg. loss 39.39, avg. ppl 135.99 cum. examples 320, speed 4339.36 words/sec, time elapsed 9.73 sec\n",
            "epoch 1 (220 / 272), iter 220, avg. loss 38.99, avg. ppl 135.11 cum. examples 640, speed 5777.26 words/sec, time elapsed 10.17 sec\n",
            "epoch 1 (230 / 272), iter 230, avg. loss 39.46, avg. ppl 140.82 cum. examples 960, speed 5655.89 words/sec, time elapsed 10.62 sec\n",
            "epoch 1 (240 / 272), iter 240, avg. loss 38.83, avg. ppl 132.21 cum. examples 1280, speed 5187.01 words/sec, time elapsed 11.11 sec\n",
            "epoch 1 (250 / 272), iter 250, avg. loss 40.46, avg. ppl 141.42 cum. examples 1600, speed 5065.96 words/sec, time elapsed 11.62 sec\n",
            "epoch 1 (260 / 272), iter 260, avg. loss 41.00, avg. ppl 137.73 cum. examples 1920, speed 5682.45 words/sec, time elapsed 12.09 sec\n",
            "epoch 1 (270 / 272), iter 270, avg. loss 38.07, avg. ppl 117.90 cum. examples 2240, speed 5919.29 words/sec, time elapsed 12.53 sec\n",
            "epoch 2 (8 / 272), iter 280, avg. loss 37.78, avg. ppl 113.33 cum. examples 2557, speed 5631.66 words/sec, time elapsed 12.98 sec\n",
            "epoch 2 (18 / 272), iter 290, avg. loss 38.99, avg. ppl 119.11 cum. examples 2877, speed 5665.12 words/sec, time elapsed 13.44 sec\n",
            "epoch 2 (28 / 272), iter 300, avg. loss 36.92, avg. ppl 104.54 cum. examples 3197, speed 6074.98 words/sec, time elapsed 13.86 sec\n",
            "epoch 2, iter 300, cum. loss 38.99, cum. ppl 127.28 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 300, dev. ppl 99.443969\n",
            "epoch 2, iter 300: save currently the best model to [model.bin]\n",
            "epoch 2 (38 / 272), iter 310, avg. loss 37.32, avg. ppl 101.06 cum. examples 320, speed 4772.13 words/sec, time elapsed 14.40 sec\n",
            "epoch 2 (48 / 272), iter 320, avg. loss 36.94, avg. ppl 97.99 cum. examples 640, speed 6727.32 words/sec, time elapsed 14.78 sec\n",
            "epoch 2 (58 / 272), iter 330, avg. loss 36.22, avg. ppl 92.56 cum. examples 960, speed 6427.82 words/sec, time elapsed 15.18 sec\n",
            "epoch 2 (68 / 272), iter 340, avg. loss 37.02, avg. ppl 90.82 cum. examples 1280, speed 6467.95 words/sec, time elapsed 15.59 sec\n",
            "epoch 2 (78 / 272), iter 350, avg. loss 35.61, avg. ppl 84.02 cum. examples 1600, speed 7312.47 words/sec, time elapsed 15.94 sec\n",
            "epoch 2 (88 / 272), iter 360, avg. loss 35.85, avg. ppl 81.06 cum. examples 1920, speed 6837.19 words/sec, time elapsed 16.32 sec\n",
            "epoch 2 (98 / 272), iter 370, avg. loss 34.85, avg. ppl 79.32 cum. examples 2240, speed 6862.32 words/sec, time elapsed 16.69 sec\n",
            "epoch 2 (108 / 272), iter 380, avg. loss 35.28, avg. ppl 78.40 cum. examples 2560, speed 6928.50 words/sec, time elapsed 17.07 sec\n",
            "epoch 2 (118 / 272), iter 390, avg. loss 34.92, avg. ppl 77.28 cum. examples 2880, speed 6641.28 words/sec, time elapsed 17.45 sec\n",
            "epoch 2 (128 / 272), iter 400, avg. loss 33.93, avg. ppl 66.57 cum. examples 3200, speed 7049.34 words/sec, time elapsed 17.82 sec\n",
            "epoch 2, iter 400, cum. loss 35.79, cum. ppl 84.31 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 400, dev. ppl 61.363022\n",
            "epoch 2, iter 400: save currently the best model to [model.bin]\n",
            "epoch 2 (138 / 272), iter 410, avg. loss 34.13, avg. ppl 67.13 cum. examples 320, speed 5052.86 words/sec, time elapsed 18.33 sec\n",
            "epoch 2 (148 / 272), iter 420, avg. loss 35.02, avg. ppl 68.78 cum. examples 640, speed 7025.12 words/sec, time elapsed 18.71 sec\n",
            "epoch 2 (158 / 272), iter 430, avg. loss 34.20, avg. ppl 64.64 cum. examples 960, speed 7025.76 words/sec, time elapsed 19.09 sec\n",
            "epoch 2 (168 / 272), iter 440, avg. loss 32.40, avg. ppl 56.23 cum. examples 1280, speed 7089.10 words/sec, time elapsed 19.45 sec\n",
            "epoch 2 (178 / 272), iter 450, avg. loss 32.85, avg. ppl 58.06 cum. examples 1600, speed 6877.03 words/sec, time elapsed 19.83 sec\n",
            "epoch 2 (188 / 272), iter 460, avg. loss 32.59, avg. ppl 54.58 cum. examples 1920, speed 6877.77 words/sec, time elapsed 20.20 sec\n",
            "epoch 2 (198 / 272), iter 470, avg. loss 32.12, avg. ppl 52.40 cum. examples 2240, speed 6902.79 words/sec, time elapsed 20.58 sec\n",
            "epoch 2 (208 / 272), iter 480, avg. loss 31.31, avg. ppl 49.10 cum. examples 2560, speed 6768.82 words/sec, time elapsed 20.96 sec\n",
            "epoch 2 (218 / 272), iter 490, avg. loss 31.21, avg. ppl 46.80 cum. examples 2880, speed 5747.92 words/sec, time elapsed 21.41 sec\n",
            "epoch 2 (228 / 272), iter 500, avg. loss 31.32, avg. ppl 47.71 cum. examples 3200, speed 6395.02 words/sec, time elapsed 21.82 sec\n",
            "epoch 2, iter 500, cum. loss 32.71, cum. ppl 56.08 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 500, dev. ppl 39.737372\n",
            "epoch 2, iter 500: save currently the best model to [model.bin]\n",
            "epoch 2 (238 / 272), iter 510, avg. loss 31.20, avg. ppl 45.77 cum. examples 320, speed 5153.46 words/sec, time elapsed 22.33 sec\n",
            "epoch 2 (248 / 272), iter 520, avg. loss 29.10, avg. ppl 39.72 cum. examples 640, speed 7247.10 words/sec, time elapsed 22.68 sec\n",
            "epoch 2 (258 / 272), iter 530, avg. loss 29.96, avg. ppl 41.57 cum. examples 960, speed 7131.65 words/sec, time elapsed 23.04 sec\n",
            "epoch 2 (268 / 272), iter 540, avg. loss 28.28, avg. ppl 35.85 cum. examples 1280, speed 7040.87 words/sec, time elapsed 23.40 sec\n",
            "epoch 3 (6 / 272), iter 550, avg. loss 29.78, avg. ppl 38.17 cum. examples 1597, speed 7058.46 words/sec, time elapsed 23.76 sec\n",
            "epoch 3 (16 / 272), iter 560, avg. loss 28.57, avg. ppl 35.47 cum. examples 1917, speed 7027.57 words/sec, time elapsed 24.13 sec\n",
            "epoch 3 (26 / 272), iter 570, avg. loss 28.87, avg. ppl 35.49 cum. examples 2237, speed 6841.90 words/sec, time elapsed 24.51 sec\n",
            "epoch 3 (36 / 272), iter 580, avg. loss 28.70, avg. ppl 34.94 cum. examples 2557, speed 7035.59 words/sec, time elapsed 24.87 sec\n",
            "epoch 3 (46 / 272), iter 590, avg. loss 27.08, avg. ppl 31.13 cum. examples 2877, speed 5887.61 words/sec, time elapsed 25.30 sec\n",
            "epoch 3 (56 / 272), iter 600, avg. loss 28.94, avg. ppl 34.83 cum. examples 3197, speed 7347.74 words/sec, time elapsed 25.66 sec\n",
            "epoch 3, iter 600, cum. loss 29.04, cum. ppl 37.11 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 600, dev. ppl 30.355185\n",
            "epoch 3, iter 600: save currently the best model to [model.bin]\n",
            "epoch 3 (66 / 272), iter 610, avg. loss 29.20, avg. ppl 34.92 cum. examples 320, speed 5166.10 words/sec, time elapsed 26.17 sec\n",
            "epoch 3 (76 / 272), iter 620, avg. loss 28.30, avg. ppl 32.97 cum. examples 640, speed 6533.96 words/sec, time elapsed 26.56 sec\n",
            "epoch 3 (86 / 272), iter 630, avg. loss 27.80, avg. ppl 31.66 cum. examples 960, speed 6976.15 words/sec, time elapsed 26.93 sec\n",
            "epoch 3 (96 / 272), iter 640, avg. loss 28.16, avg. ppl 31.37 cum. examples 1280, speed 7305.07 words/sec, time elapsed 27.29 sec\n",
            "epoch 3 (106 / 272), iter 650, avg. loss 28.33, avg. ppl 32.24 cum. examples 1600, speed 6665.92 words/sec, time elapsed 27.68 sec\n",
            "epoch 3 (116 / 272), iter 660, avg. loss 27.69, avg. ppl 30.69 cum. examples 1920, speed 6708.91 words/sec, time elapsed 28.07 sec\n",
            "epoch 3 (126 / 272), iter 670, avg. loss 27.06, avg. ppl 29.84 cum. examples 2240, speed 6706.53 words/sec, time elapsed 28.45 sec\n",
            "epoch 3 (136 / 272), iter 680, avg. loss 27.29, avg. ppl 29.45 cum. examples 2560, speed 7111.28 words/sec, time elapsed 28.81 sec\n",
            "epoch 3 (146 / 272), iter 690, avg. loss 27.55, avg. ppl 30.26 cum. examples 2880, speed 7059.95 words/sec, time elapsed 29.18 sec\n",
            "epoch 3 (156 / 272), iter 700, avg. loss 27.61, avg. ppl 29.79 cum. examples 3200, speed 6887.66 words/sec, time elapsed 29.56 sec\n",
            "epoch 3, iter 700, cum. loss 27.90, cum. ppl 31.29 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 700, dev. ppl 26.294146\n",
            "epoch 3, iter 700: save currently the best model to [model.bin]\n",
            "epoch 3 (166 / 272), iter 710, avg. loss 27.95, avg. ppl 29.64 cum. examples 320, speed 4739.00 words/sec, time elapsed 30.11 sec\n",
            "epoch 3 (176 / 272), iter 720, avg. loss 27.20, avg. ppl 29.45 cum. examples 640, speed 7023.60 words/sec, time elapsed 30.48 sec\n",
            "epoch 3 (186 / 272), iter 730, avg. loss 25.96, avg. ppl 25.90 cum. examples 960, speed 6376.18 words/sec, time elapsed 30.88 sec\n",
            "epoch 3 (196 / 272), iter 740, avg. loss 25.48, avg. ppl 25.39 cum. examples 1280, speed 7037.70 words/sec, time elapsed 31.24 sec\n",
            "epoch 3 (206 / 272), iter 750, avg. loss 25.32, avg. ppl 24.49 cum. examples 1600, speed 6696.56 words/sec, time elapsed 31.62 sec\n",
            "epoch 3 (216 / 272), iter 760, avg. loss 26.81, avg. ppl 27.81 cum. examples 1920, speed 6552.81 words/sec, time elapsed 32.01 sec\n",
            "epoch 3 (226 / 272), iter 770, avg. loss 27.87, avg. ppl 30.16 cum. examples 2240, speed 6298.40 words/sec, time elapsed 32.43 sec\n",
            "epoch 3 (236 / 272), iter 780, avg. loss 26.49, avg. ppl 27.08 cum. examples 2560, speed 7016.54 words/sec, time elapsed 32.79 sec\n",
            "epoch 3 (246 / 272), iter 790, avg. loss 26.31, avg. ppl 26.29 cum. examples 2880, speed 6887.76 words/sec, time elapsed 33.17 sec\n",
            "epoch 3 (256 / 272), iter 800, avg. loss 27.15, avg. ppl 27.67 cum. examples 3200, speed 6911.95 words/sec, time elapsed 33.55 sec\n",
            "epoch 3, iter 800, cum. loss 26.65, cum. ppl 27.35 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 800, dev. ppl 23.528068\n",
            "epoch 3, iter 800: save currently the best model to [model.bin]\n",
            "epoch 3 (266 / 272), iter 810, avg. loss 27.20, avg. ppl 27.82 cum. examples 320, speed 4636.97 words/sec, time elapsed 34.11 sec\n",
            "epoch 4 (4 / 272), iter 820, avg. loss 26.84, avg. ppl 27.04 cum. examples 637, speed 6671.94 words/sec, time elapsed 34.50 sec\n",
            "epoch 4 (14 / 272), iter 830, avg. loss 24.90, avg. ppl 23.46 cum. examples 957, speed 6878.95 words/sec, time elapsed 34.87 sec\n",
            "epoch 4 (24 / 272), iter 840, avg. loss 26.29, avg. ppl 25.65 cum. examples 1277, speed 7268.94 words/sec, time elapsed 35.22 sec\n",
            "epoch 4 (34 / 272), iter 850, avg. loss 24.91, avg. ppl 22.87 cum. examples 1597, speed 6661.64 words/sec, time elapsed 35.61 sec\n",
            "epoch 4 (44 / 272), iter 860, avg. loss 25.67, avg. ppl 24.23 cum. examples 1917, speed 6424.55 words/sec, time elapsed 36.01 sec\n",
            "epoch 4 (54 / 272), iter 870, avg. loss 25.37, avg. ppl 24.08 cum. examples 2237, speed 6326.54 words/sec, time elapsed 36.41 sec\n",
            "epoch 4 (64 / 272), iter 880, avg. loss 25.23, avg. ppl 23.41 cum. examples 2557, speed 6649.78 words/sec, time elapsed 36.79 sec\n",
            "epoch 4 (74 / 272), iter 890, avg. loss 25.55, avg. ppl 23.72 cum. examples 2877, speed 5799.72 words/sec, time elapsed 37.24 sec\n",
            "epoch 4 (84 / 272), iter 900, avg. loss 25.08, avg. ppl 22.54 cum. examples 3197, speed 6673.62 words/sec, time elapsed 37.63 sec\n",
            "epoch 4, iter 900, cum. loss 25.70, cum. ppl 24.44 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 900, dev. ppl 21.953858\n",
            "epoch 4, iter 900: save currently the best model to [model.bin]\n",
            "epoch 4 (94 / 272), iter 910, avg. loss 24.82, avg. ppl 21.96 cum. examples 320, speed 5066.38 words/sec, time elapsed 38.13 sec\n",
            "epoch 4 (104 / 272), iter 920, avg. loss 25.32, avg. ppl 23.65 cum. examples 640, speed 6799.49 words/sec, time elapsed 38.51 sec\n",
            "epoch 4 (114 / 272), iter 930, avg. loss 25.45, avg. ppl 23.57 cum. examples 960, speed 6392.05 words/sec, time elapsed 38.91 sec\n",
            "epoch 4 (124 / 272), iter 940, avg. loss 26.10, avg. ppl 24.19 cum. examples 1280, speed 7149.41 words/sec, time elapsed 39.28 sec\n",
            "epoch 4 (134 / 272), iter 950, avg. loss 25.20, avg. ppl 22.53 cum. examples 1600, speed 6629.24 words/sec, time elapsed 39.67 sec\n",
            "epoch 4 (144 / 272), iter 960, avg. loss 25.79, avg. ppl 23.13 cum. examples 1920, speed 5966.17 words/sec, time elapsed 40.11 sec\n",
            "epoch 4 (154 / 272), iter 970, avg. loss 26.17, avg. ppl 24.16 cum. examples 2240, speed 6289.46 words/sec, time elapsed 40.53 sec\n",
            "epoch 4 (164 / 272), iter 980, avg. loss 26.64, avg. ppl 25.21 cum. examples 2560, speed 6792.18 words/sec, time elapsed 40.92 sec\n",
            "epoch 4 (174 / 272), iter 990, avg. loss 25.46, avg. ppl 22.97 cum. examples 2880, speed 7009.14 words/sec, time elapsed 41.29 sec\n",
            "epoch 4 (184 / 272), iter 1000, avg. loss 24.59, avg. ppl 21.52 cum. examples 3200, speed 6709.24 words/sec, time elapsed 41.67 sec\n",
            "epoch 4, iter 1000, cum. loss 25.55, cum. ppl 23.27 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 1000, dev. ppl 20.311588\n",
            "epoch 4, iter 1000: save currently the best model to [model.bin]\n",
            "epoch 4 (194 / 272), iter 1010, avg. loss 24.55, avg. ppl 20.91 cum. examples 320, speed 5093.71 words/sec, time elapsed 42.18 sec\n",
            "epoch 4 (204 / 272), iter 1020, avg. loss 24.72, avg. ppl 21.28 cum. examples 640, speed 6930.10 words/sec, time elapsed 42.55 sec\n",
            "epoch 4 (214 / 272), iter 1030, avg. loss 24.93, avg. ppl 21.45 cum. examples 960, speed 6698.51 words/sec, time elapsed 42.94 sec\n",
            "epoch 4 (224 / 272), iter 1040, avg. loss 24.32, avg. ppl 21.06 cum. examples 1280, speed 6617.46 words/sec, time elapsed 43.33 sec\n",
            "epoch 4 (234 / 272), iter 1050, avg. loss 25.62, avg. ppl 22.68 cum. examples 1600, speed 6395.89 words/sec, time elapsed 43.74 sec\n",
            "epoch 4 (244 / 272), iter 1060, avg. loss 25.34, avg. ppl 21.95 cum. examples 1920, speed 5465.52 words/sec, time elapsed 44.22 sec\n",
            "epoch 4 (254 / 272), iter 1070, avg. loss 24.66, avg. ppl 21.47 cum. examples 2240, speed 6204.61 words/sec, time elapsed 44.64 sec\n",
            "epoch 4 (264 / 272), iter 1080, avg. loss 24.54, avg. ppl 21.29 cum. examples 2560, speed 6522.56 words/sec, time elapsed 45.03 sec\n",
            "epoch 5 (2 / 272), iter 1090, avg. loss 23.73, avg. ppl 19.71 cum. examples 2877, speed 6726.27 words/sec, time elapsed 45.40 sec\n",
            "epoch 5 (12 / 272), iter 1100, avg. loss 23.88, avg. ppl 19.39 cum. examples 3197, speed 6451.83 words/sec, time elapsed 45.80 sec\n",
            "epoch 5, iter 1100, cum. loss 24.63, cum. ppl 21.11 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 1100, dev. ppl 18.994665\n",
            "epoch 5, iter 1100: save currently the best model to [model.bin]\n",
            "epoch 5 (22 / 272), iter 1110, avg. loss 24.57, avg. ppl 20.65 cum. examples 320, speed 4967.39 words/sec, time elapsed 46.33 sec\n",
            "epoch 5 (32 / 272), iter 1120, avg. loss 23.95, avg. ppl 19.84 cum. examples 640, speed 4378.30 words/sec, time elapsed 46.91 sec\n",
            "epoch 5 (42 / 272), iter 1130, avg. loss 23.74, avg. ppl 19.61 cum. examples 960, speed 6498.63 words/sec, time elapsed 47.31 sec\n",
            "epoch 5 (52 / 272), iter 1140, avg. loss 23.36, avg. ppl 18.51 cum. examples 1280, speed 4961.68 words/sec, time elapsed 47.82 sec\n",
            "epoch 5 (62 / 272), iter 1150, avg. loss 24.23, avg. ppl 20.12 cum. examples 1600, speed 6986.15 words/sec, time elapsed 48.19 sec\n",
            "epoch 5 (72 / 272), iter 1160, avg. loss 22.63, avg. ppl 17.16 cum. examples 1920, speed 7005.67 words/sec, time elapsed 48.56 sec\n",
            "epoch 5 (82 / 272), iter 1170, avg. loss 22.96, avg. ppl 17.55 cum. examples 2240, speed 6794.21 words/sec, time elapsed 48.94 sec\n",
            "epoch 5 (92 / 272), iter 1180, avg. loss 23.44, avg. ppl 18.11 cum. examples 2560, speed 7215.30 words/sec, time elapsed 49.30 sec\n",
            "epoch 5 (102 / 272), iter 1190, avg. loss 25.02, avg. ppl 21.09 cum. examples 2880, speed 6556.70 words/sec, time elapsed 49.70 sec\n",
            "epoch 5 (112 / 272), iter 1200, avg. loss 24.66, avg. ppl 20.08 cum. examples 3200, speed 6801.43 words/sec, time elapsed 50.08 sec\n",
            "epoch 5, iter 1200, cum. loss 23.86, cum. ppl 19.24 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 1200, dev. ppl 17.791834\n",
            "epoch 5, iter 1200: save currently the best model to [model.bin]\n",
            "epoch 5 (122 / 272), iter 1210, avg. loss 23.42, avg. ppl 18.17 cum. examples 320, speed 4967.36 words/sec, time elapsed 50.60 sec\n",
            "epoch 5 (132 / 272), iter 1220, avg. loss 23.01, avg. ppl 17.69 cum. examples 640, speed 6896.67 words/sec, time elapsed 50.98 sec\n",
            "epoch 5 (142 / 272), iter 1230, avg. loss 24.16, avg. ppl 18.88 cum. examples 960, speed 7294.51 words/sec, time elapsed 51.34 sec\n",
            "epoch 5 (152 / 272), iter 1240, avg. loss 23.69, avg. ppl 19.67 cum. examples 1280, speed 6853.92 words/sec, time elapsed 51.71 sec\n",
            "epoch 5 (162 / 272), iter 1250, avg. loss 23.27, avg. ppl 18.28 cum. examples 1600, speed 6657.14 words/sec, time elapsed 52.09 sec\n",
            "epoch 5 (172 / 272), iter 1260, avg. loss 22.96, avg. ppl 17.50 cum. examples 1920, speed 7124.73 words/sec, time elapsed 52.45 sec\n",
            "epoch 5 (182 / 272), iter 1270, avg. loss 24.52, avg. ppl 19.84 cum. examples 2240, speed 6906.43 words/sec, time elapsed 52.83 sec\n",
            "epoch 5 (192 / 272), iter 1280, avg. loss 24.10, avg. ppl 19.03 cum. examples 2560, speed 7165.72 words/sec, time elapsed 53.20 sec\n",
            "epoch 5 (202 / 272), iter 1290, avg. loss 23.29, avg. ppl 17.33 cum. examples 2880, speed 7233.00 words/sec, time elapsed 53.56 sec\n",
            "epoch 5 (212 / 272), iter 1300, avg. loss 23.90, avg. ppl 19.09 cum. examples 3200, speed 6796.86 words/sec, time elapsed 53.94 sec\n",
            "epoch 5, iter 1300, cum. loss 23.63, cum. ppl 18.53 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 1300, dev. ppl 16.895553\n",
            "epoch 5, iter 1300: save currently the best model to [model.bin]\n",
            "epoch 5 (222 / 272), iter 1310, avg. loss 23.69, avg. ppl 18.53 cum. examples 320, speed 4617.02 words/sec, time elapsed 54.51 sec\n",
            "epoch 5 (232 / 272), iter 1320, avg. loss 23.03, avg. ppl 17.68 cum. examples 640, speed 6374.72 words/sec, time elapsed 54.91 sec\n",
            "epoch 5 (242 / 272), iter 1330, avg. loss 23.39, avg. ppl 17.82 cum. examples 960, speed 6904.10 words/sec, time elapsed 55.28 sec\n",
            "epoch 5 (252 / 272), iter 1340, avg. loss 24.07, avg. ppl 18.62 cum. examples 1280, speed 7121.76 words/sec, time elapsed 55.65 sec\n",
            "epoch 5 (262 / 272), iter 1350, avg. loss 22.32, avg. ppl 16.10 cum. examples 1600, speed 6556.05 words/sec, time elapsed 56.05 sec\n",
            "epoch 5 (272 / 272), iter 1360, avg. loss 23.03, avg. ppl 18.01 cum. examples 1917, speed 6946.64 words/sec, time elapsed 56.41 sec\n",
            "epoch 6 (10 / 272), iter 1370, avg. loss 23.04, avg. ppl 16.69 cum. examples 2237, speed 6997.80 words/sec, time elapsed 56.78 sec\n",
            "epoch 6 (20 / 272), iter 1380, avg. loss 22.35, avg. ppl 16.12 cum. examples 2557, speed 5490.09 words/sec, time elapsed 57.25 sec\n",
            "epoch 6 (30 / 272), iter 1390, avg. loss 22.72, avg. ppl 16.98 cum. examples 2877, speed 6293.70 words/sec, time elapsed 57.66 sec\n",
            "epoch 6 (40 / 272), iter 1400, avg. loss 21.43, avg. ppl 15.20 cum. examples 3197, speed 6578.89 words/sec, time elapsed 58.05 sec\n",
            "epoch 6, iter 1400, cum. loss 22.91, cum. ppl 17.15 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 1400, dev. ppl 16.015815\n",
            "epoch 6, iter 1400: save currently the best model to [model.bin]\n",
            "epoch 6 (50 / 272), iter 1410, avg. loss 21.68, avg. ppl 15.60 cum. examples 320, speed 5063.81 words/sec, time elapsed 58.54 sec\n",
            "epoch 6 (60 / 272), iter 1420, avg. loss 22.34, avg. ppl 16.20 cum. examples 640, speed 6934.62 words/sec, time elapsed 58.91 sec\n",
            "epoch 6 (70 / 272), iter 1430, avg. loss 21.89, avg. ppl 15.39 cum. examples 960, speed 6648.98 words/sec, time elapsed 59.30 sec\n",
            "epoch 6 (80 / 272), iter 1440, avg. loss 23.31, avg. ppl 17.18 cum. examples 1280, speed 7024.70 words/sec, time elapsed 59.67 sec\n",
            "epoch 6 (90 / 272), iter 1450, avg. loss 22.64, avg. ppl 16.20 cum. examples 1600, speed 6959.51 words/sec, time elapsed 60.05 sec\n",
            "epoch 6 (100 / 272), iter 1460, avg. loss 23.45, avg. ppl 17.57 cum. examples 1920, speed 6928.28 words/sec, time elapsed 60.43 sec\n",
            "epoch 6 (110 / 272), iter 1470, avg. loss 22.54, avg. ppl 15.93 cum. examples 2240, speed 5006.48 words/sec, time elapsed 60.95 sec\n",
            "epoch 6 (120 / 272), iter 1480, avg. loss 24.01, avg. ppl 18.19 cum. examples 2560, speed 5318.76 words/sec, time elapsed 61.44 sec\n",
            "epoch 6 (130 / 272), iter 1490, avg. loss 21.40, avg. ppl 14.83 cum. examples 2880, speed 6875.55 words/sec, time elapsed 61.81 sec\n",
            "epoch 6 (140 / 272), iter 1500, avg. loss 22.55, avg. ppl 16.77 cum. examples 3200, speed 6628.98 words/sec, time elapsed 62.20 sec\n",
            "epoch 6, iter 1500, cum. loss 22.58, cum. ppl 16.37 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 1500, dev. ppl 15.385937\n",
            "epoch 6, iter 1500: save currently the best model to [model.bin]\n",
            "epoch 6 (150 / 272), iter 1510, avg. loss 22.54, avg. ppl 16.34 cum. examples 320, speed 4766.88 words/sec, time elapsed 62.74 sec\n",
            "epoch 6 (160 / 272), iter 1520, avg. loss 23.06, avg. ppl 17.05 cum. examples 640, speed 6534.67 words/sec, time elapsed 63.14 sec\n",
            "epoch 6 (170 / 272), iter 1530, avg. loss 22.42, avg. ppl 15.95 cum. examples 960, speed 6529.18 words/sec, time elapsed 63.54 sec\n",
            "epoch 6 (180 / 272), iter 1540, avg. loss 21.35, avg. ppl 14.52 cum. examples 1280, speed 6039.37 words/sec, time elapsed 63.96 sec\n",
            "epoch 6 (190 / 272), iter 1550, avg. loss 23.99, avg. ppl 17.62 cum. examples 1600, speed 6500.65 words/sec, time elapsed 64.37 sec\n",
            "epoch 6 (200 / 272), iter 1560, avg. loss 21.74, avg. ppl 15.58 cum. examples 1920, speed 6657.06 words/sec, time elapsed 64.75 sec\n",
            "epoch 6 (210 / 272), iter 1570, avg. loss 22.90, avg. ppl 16.49 cum. examples 2240, speed 6553.34 words/sec, time elapsed 65.15 sec\n",
            "epoch 6 (220 / 272), iter 1580, avg. loss 22.62, avg. ppl 16.04 cum. examples 2560, speed 7056.49 words/sec, time elapsed 65.52 sec\n",
            "epoch 6 (230 / 272), iter 1590, avg. loss 23.10, avg. ppl 16.60 cum. examples 2880, speed 5933.60 words/sec, time elapsed 65.96 sec\n",
            "epoch 6 (240 / 272), iter 1600, avg. loss 22.10, avg. ppl 15.70 cum. examples 3200, speed 6584.93 words/sec, time elapsed 66.36 sec\n",
            "epoch 6, iter 1600, cum. loss 22.58, cum. ppl 16.18 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 1600, dev. ppl 14.807874\n",
            "epoch 6, iter 1600: save currently the best model to [model.bin]\n",
            "epoch 6 (250 / 272), iter 1610, avg. loss 21.40, avg. ppl 14.57 cum. examples 320, speed 4745.46 words/sec, time elapsed 66.89 sec\n",
            "epoch 6 (260 / 272), iter 1620, avg. loss 22.09, avg. ppl 15.44 cum. examples 640, speed 6222.87 words/sec, time elapsed 67.31 sec\n",
            "epoch 6 (270 / 272), iter 1630, avg. loss 21.34, avg. ppl 14.31 cum. examples 960, speed 6702.91 words/sec, time elapsed 67.69 sec\n",
            "epoch 7 (8 / 272), iter 1640, avg. loss 21.94, avg. ppl 15.00 cum. examples 1277, speed 6798.46 words/sec, time elapsed 68.07 sec\n",
            "epoch 7 (18 / 272), iter 1650, avg. loss 22.51, avg. ppl 15.55 cum. examples 1597, speed 6656.89 words/sec, time elapsed 68.46 sec\n",
            "epoch 7 (28 / 272), iter 1660, avg. loss 21.59, avg. ppl 14.87 cum. examples 1917, speed 6735.82 words/sec, time elapsed 68.84 sec\n",
            "epoch 7 (38 / 272), iter 1670, avg. loss 21.89, avg. ppl 15.32 cum. examples 2237, speed 6248.21 words/sec, time elapsed 69.26 sec\n",
            "epoch 7 (48 / 272), iter 1680, avg. loss 22.77, avg. ppl 15.76 cum. examples 2557, speed 6625.77 words/sec, time elapsed 69.65 sec\n",
            "epoch 7 (58 / 272), iter 1690, avg. loss 20.93, avg. ppl 13.68 cum. examples 2877, speed 6303.46 words/sec, time elapsed 70.06 sec\n",
            "epoch 7 (68 / 272), iter 1700, avg. loss 21.17, avg. ppl 14.08 cum. examples 3197, speed 6346.19 words/sec, time elapsed 70.46 sec\n",
            "epoch 7, iter 1700, cum. loss 21.76, cum. ppl 14.85 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 1700, dev. ppl 14.336814\n",
            "epoch 7, iter 1700: save currently the best model to [model.bin]\n",
            "epoch 7 (78 / 272), iter 1710, avg. loss 21.80, avg. ppl 14.65 cum. examples 320, speed 4919.55 words/sec, time elapsed 70.99 sec\n",
            "epoch 7 (88 / 272), iter 1720, avg. loss 21.12, avg. ppl 13.78 cum. examples 640, speed 6595.10 words/sec, time elapsed 71.38 sec\n",
            "epoch 7 (98 / 272), iter 1730, avg. loss 21.60, avg. ppl 14.84 cum. examples 960, speed 6724.06 words/sec, time elapsed 71.76 sec\n",
            "epoch 7 (108 / 272), iter 1740, avg. loss 21.25, avg. ppl 13.60 cum. examples 1280, speed 6861.19 words/sec, time elapsed 72.14 sec\n",
            "epoch 7 (118 / 272), iter 1750, avg. loss 22.41, avg. ppl 15.14 cum. examples 1600, speed 6363.30 words/sec, time elapsed 72.56 sec\n",
            "epoch 7 (128 / 272), iter 1760, avg. loss 21.83, avg. ppl 14.63 cum. examples 1920, speed 6302.90 words/sec, time elapsed 72.97 sec\n",
            "epoch 7 (138 / 272), iter 1770, avg. loss 20.47, avg. ppl 13.30 cum. examples 2240, speed 6475.62 words/sec, time elapsed 73.36 sec\n",
            "epoch 7 (148 / 272), iter 1780, avg. loss 21.80, avg. ppl 14.46 cum. examples 2560, speed 6726.36 words/sec, time elapsed 73.75 sec\n",
            "epoch 7 (158 / 272), iter 1790, avg. loss 21.79, avg. ppl 14.41 cum. examples 2880, speed 6245.92 words/sec, time elapsed 74.17 sec\n",
            "epoch 7 (168 / 272), iter 1800, avg. loss 21.00, avg. ppl 13.34 cum. examples 3200, speed 6726.59 words/sec, time elapsed 74.56 sec\n",
            "epoch 7, iter 1800, cum. loss 21.51, cum. ppl 14.21 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 1800, dev. ppl 13.857173\n",
            "epoch 7, iter 1800: save currently the best model to [model.bin]\n",
            "epoch 7 (178 / 272), iter 1810, avg. loss 21.48, avg. ppl 14.59 cum. examples 320, speed 4982.33 words/sec, time elapsed 75.07 sec\n",
            "epoch 7 (188 / 272), iter 1820, avg. loss 22.13, avg. ppl 14.96 cum. examples 640, speed 6707.71 words/sec, time elapsed 75.46 sec\n",
            "epoch 7 (198 / 272), iter 1830, avg. loss 22.15, avg. ppl 14.64 cum. examples 960, speed 6409.97 words/sec, time elapsed 75.87 sec\n",
            "epoch 7 (208 / 272), iter 1840, avg. loss 21.38, avg. ppl 14.12 cum. examples 1280, speed 6693.78 words/sec, time elapsed 76.26 sec\n",
            "epoch 7 (218 / 272), iter 1850, avg. loss 20.92, avg. ppl 13.80 cum. examples 1600, speed 6394.67 words/sec, time elapsed 76.66 sec\n",
            "epoch 7 (228 / 272), iter 1860, avg. loss 20.36, avg. ppl 12.84 cum. examples 1920, speed 6636.05 words/sec, time elapsed 77.04 sec\n",
            "epoch 7 (238 / 272), iter 1870, avg. loss 20.93, avg. ppl 13.40 cum. examples 2240, speed 6361.96 words/sec, time elapsed 77.45 sec\n",
            "epoch 7 (248 / 272), iter 1880, avg. loss 20.80, avg. ppl 13.11 cum. examples 2560, speed 6338.43 words/sec, time elapsed 77.86 sec\n",
            "epoch 7 (258 / 272), iter 1890, avg. loss 20.49, avg. ppl 13.49 cum. examples 2880, speed 6496.60 words/sec, time elapsed 78.25 sec\n",
            "epoch 7 (268 / 272), iter 1900, avg. loss 20.85, avg. ppl 13.51 cum. examples 3200, speed 6534.41 words/sec, time elapsed 78.64 sec\n",
            "epoch 7, iter 1900, cum. loss 21.15, cum. ppl 13.84 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 1900, dev. ppl 13.383316\n",
            "epoch 7, iter 1900: save currently the best model to [model.bin]\n",
            "epoch 8 (6 / 272), iter 1910, avg. loss 20.64, avg. ppl 12.90 cum. examples 317, speed 4683.11 words/sec, time elapsed 79.19 sec\n",
            "epoch 8 (16 / 272), iter 1920, avg. loss 21.28, avg. ppl 13.47 cum. examples 637, speed 6544.61 words/sec, time elapsed 79.59 sec\n",
            "epoch 8 (26 / 272), iter 1930, avg. loss 20.75, avg. ppl 13.24 cum. examples 957, speed 6288.44 words/sec, time elapsed 80.00 sec\n",
            "epoch 8 (36 / 272), iter 1940, avg. loss 21.73, avg. ppl 14.16 cum. examples 1277, speed 4644.00 words/sec, time elapsed 80.56 sec\n",
            "epoch 8 (46 / 272), iter 1950, avg. loss 20.68, avg. ppl 12.98 cum. examples 1597, speed 6877.09 words/sec, time elapsed 80.94 sec\n",
            "epoch 8 (56 / 272), iter 1960, avg. loss 21.74, avg. ppl 14.34 cum. examples 1917, speed 6835.07 words/sec, time elapsed 81.32 sec\n",
            "epoch 8 (66 / 272), iter 1970, avg. loss 20.97, avg. ppl 13.14 cum. examples 2237, speed 6012.92 words/sec, time elapsed 81.75 sec\n",
            "epoch 8 (76 / 272), iter 1980, avg. loss 19.67, avg. ppl 12.11 cum. examples 2557, speed 6744.61 words/sec, time elapsed 82.13 sec\n",
            "epoch 8 (86 / 272), iter 1990, avg. loss 21.41, avg. ppl 13.08 cum. examples 2877, speed 6704.23 words/sec, time elapsed 82.52 sec\n",
            "epoch 8 (96 / 272), iter 2000, avg. loss 21.27, avg. ppl 13.44 cum. examples 3197, speed 6641.97 words/sec, time elapsed 82.92 sec\n",
            "epoch 8, iter 2000, cum. loss 21.01, cum. ppl 13.28 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 2000, dev. ppl 13.096291\n",
            "epoch 8, iter 2000: save currently the best model to [model.bin]\n",
            "epoch 8 (106 / 272), iter 2010, avg. loss 19.18, avg. ppl 11.35 cum. examples 320, speed 4966.38 words/sec, time elapsed 83.43 sec\n",
            "epoch 8 (116 / 272), iter 2020, avg. loss 20.98, avg. ppl 13.18 cum. examples 640, speed 6089.38 words/sec, time elapsed 83.86 sec\n",
            "epoch 8 (126 / 272), iter 2030, avg. loss 19.68, avg. ppl 11.80 cum. examples 960, speed 6694.71 words/sec, time elapsed 84.24 sec\n",
            "epoch 8 (136 / 272), iter 2040, avg. loss 20.11, avg. ppl 12.37 cum. examples 1280, speed 6571.49 words/sec, time elapsed 84.63 sec\n",
            "epoch 8 (146 / 272), iter 2050, avg. loss 20.17, avg. ppl 12.64 cum. examples 1600, speed 6680.09 words/sec, time elapsed 85.01 sec\n",
            "epoch 8 (156 / 272), iter 2060, avg. loss 19.72, avg. ppl 12.04 cum. examples 1920, speed 6434.51 words/sec, time elapsed 85.40 sec\n",
            "epoch 8 (166 / 272), iter 2070, avg. loss 19.07, avg. ppl 11.46 cum. examples 2240, speed 6524.16 words/sec, time elapsed 85.79 sec\n",
            "epoch 8 (176 / 272), iter 2080, avg. loss 20.48, avg. ppl 12.60 cum. examples 2560, speed 6666.90 words/sec, time elapsed 86.17 sec\n",
            "epoch 8 (186 / 272), iter 2090, avg. loss 21.53, avg. ppl 13.48 cum. examples 2880, speed 6498.46 words/sec, time elapsed 86.58 sec\n",
            "epoch 8 (196 / 272), iter 2100, avg. loss 19.79, avg. ppl 12.14 cum. examples 3200, speed 6733.15 words/sec, time elapsed 86.96 sec\n",
            "epoch 8, iter 2100, cum. loss 20.07, cum. ppl 12.30 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 2100, dev. ppl 12.691390\n",
            "epoch 8, iter 2100: save currently the best model to [model.bin]\n",
            "epoch 8 (206 / 272), iter 2110, avg. loss 20.12, avg. ppl 12.12 cum. examples 320, speed 4774.19 words/sec, time elapsed 87.50 sec\n",
            "epoch 8 (216 / 272), iter 2120, avg. loss 21.80, avg. ppl 14.03 cum. examples 640, speed 6243.53 words/sec, time elapsed 87.92 sec\n",
            "epoch 8 (226 / 272), iter 2130, avg. loss 20.34, avg. ppl 12.59 cum. examples 960, speed 6893.51 words/sec, time elapsed 88.30 sec\n",
            "epoch 8 (236 / 272), iter 2140, avg. loss 20.43, avg. ppl 12.53 cum. examples 1280, speed 6516.27 words/sec, time elapsed 88.69 sec\n",
            "epoch 8 (246 / 272), iter 2150, avg. loss 20.10, avg. ppl 12.21 cum. examples 1600, speed 7033.16 words/sec, time elapsed 89.06 sec\n",
            "epoch 8 (256 / 272), iter 2160, avg. loss 21.82, avg. ppl 14.76 cum. examples 1920, speed 7197.47 words/sec, time elapsed 89.42 sec\n",
            "epoch 8 (266 / 272), iter 2170, avg. loss 20.22, avg. ppl 12.61 cum. examples 2240, speed 6689.00 words/sec, time elapsed 89.80 sec\n",
            "epoch 9 (4 / 272), iter 2180, avg. loss 21.13, avg. ppl 12.95 cum. examples 2557, speed 7146.90 words/sec, time elapsed 90.17 sec\n",
            "epoch 9 (14 / 272), iter 2190, avg. loss 21.23, avg. ppl 13.04 cum. examples 2877, speed 7237.49 words/sec, time elapsed 90.53 sec\n",
            "epoch 9 (24 / 272), iter 2200, avg. loss 20.08, avg. ppl 12.00 cum. examples 3197, speed 6969.38 words/sec, time elapsed 90.90 sec\n",
            "epoch 9, iter 2200, cum. loss 20.73, cum. ppl 12.86 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 2200, dev. ppl 12.334323\n",
            "epoch 9, iter 2200: save currently the best model to [model.bin]\n",
            "epoch 9 (34 / 272), iter 2210, avg. loss 19.33, avg. ppl 11.27 cum. examples 320, speed 5072.41 words/sec, time elapsed 91.41 sec\n",
            "epoch 9 (44 / 272), iter 2220, avg. loss 19.61, avg. ppl 11.56 cum. examples 640, speed 7101.41 words/sec, time elapsed 91.77 sec\n",
            "epoch 9 (54 / 272), iter 2230, avg. loss 19.90, avg. ppl 11.64 cum. examples 960, speed 7147.64 words/sec, time elapsed 92.13 sec\n",
            "epoch 9 (64 / 272), iter 2240, avg. loss 19.46, avg. ppl 11.21 cum. examples 1280, speed 7157.89 words/sec, time elapsed 92.49 sec\n",
            "epoch 9 (74 / 272), iter 2250, avg. loss 20.35, avg. ppl 12.10 cum. examples 1600, speed 7104.83 words/sec, time elapsed 92.86 sec\n",
            "epoch 9 (84 / 272), iter 2260, avg. loss 20.45, avg. ppl 12.37 cum. examples 1920, speed 6021.91 words/sec, time elapsed 93.29 sec\n",
            "epoch 9 (94 / 272), iter 2270, avg. loss 19.16, avg. ppl 11.28 cum. examples 2240, speed 6041.46 words/sec, time elapsed 93.71 sec\n",
            "epoch 9 (104 / 272), iter 2280, avg. loss 18.90, avg. ppl 10.90 cum. examples 2560, speed 7101.74 words/sec, time elapsed 94.07 sec\n",
            "epoch 9 (114 / 272), iter 2290, avg. loss 20.81, avg. ppl 12.51 cum. examples 2880, speed 6069.55 words/sec, time elapsed 94.50 sec\n",
            "epoch 9 (124 / 272), iter 2300, avg. loss 19.98, avg. ppl 11.84 cum. examples 3200, speed 6394.79 words/sec, time elapsed 94.91 sec\n",
            "epoch 9, iter 2300, cum. loss 19.80, cum. ppl 11.66 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 2300, dev. ppl 11.963862\n",
            "epoch 9, iter 2300: save currently the best model to [model.bin]\n",
            "epoch 9 (134 / 272), iter 2310, avg. loss 19.27, avg. ppl 11.25 cum. examples 320, speed 5215.46 words/sec, time elapsed 95.40 sec\n",
            "epoch 9 (144 / 272), iter 2320, avg. loss 20.20, avg. ppl 12.06 cum. examples 640, speed 6989.00 words/sec, time elapsed 95.77 sec\n",
            "epoch 9 (154 / 272), iter 2330, avg. loss 20.12, avg. ppl 12.07 cum. examples 960, speed 6850.16 words/sec, time elapsed 96.15 sec\n",
            "epoch 9 (164 / 272), iter 2340, avg. loss 20.31, avg. ppl 12.25 cum. examples 1280, speed 6820.16 words/sec, time elapsed 96.53 sec\n",
            "epoch 9 (174 / 272), iter 2350, avg. loss 19.44, avg. ppl 10.99 cum. examples 1600, speed 6714.50 words/sec, time elapsed 96.91 sec\n",
            "epoch 9 (184 / 272), iter 2360, avg. loss 20.70, avg. ppl 12.19 cum. examples 1920, speed 7251.71 words/sec, time elapsed 97.28 sec\n",
            "epoch 9 (194 / 272), iter 2370, avg. loss 20.28, avg. ppl 12.34 cum. examples 2240, speed 6685.18 words/sec, time elapsed 97.66 sec\n",
            "epoch 9 (204 / 272), iter 2380, avg. loss 19.89, avg. ppl 11.75 cum. examples 2560, speed 6427.35 words/sec, time elapsed 98.07 sec\n",
            "epoch 9 (214 / 272), iter 2390, avg. loss 19.69, avg. ppl 11.58 cum. examples 2880, speed 7192.83 words/sec, time elapsed 98.42 sec\n",
            "epoch 9 (224 / 272), iter 2400, avg. loss 20.71, avg. ppl 12.67 cum. examples 3200, speed 6671.89 words/sec, time elapsed 98.82 sec\n",
            "epoch 9, iter 2400, cum. loss 20.06, cum. ppl 11.91 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 2400, dev. ppl 11.699678\n",
            "epoch 9, iter 2400: save currently the best model to [model.bin]\n",
            "epoch 9 (234 / 272), iter 2410, avg. loss 19.47, avg. ppl 11.26 cum. examples 320, speed 5194.85 words/sec, time elapsed 99.31 sec\n",
            "epoch 9 (244 / 272), iter 2420, avg. loss 19.38, avg. ppl 11.25 cum. examples 640, speed 7162.40 words/sec, time elapsed 99.67 sec\n",
            "epoch 9 (254 / 272), iter 2430, avg. loss 20.61, avg. ppl 12.50 cum. examples 960, speed 6597.71 words/sec, time elapsed 100.06 sec\n",
            "epoch 9 (264 / 272), iter 2440, avg. loss 20.27, avg. ppl 12.02 cum. examples 1280, speed 6938.01 words/sec, time elapsed 100.44 sec\n",
            "epoch 10 (2 / 272), iter 2450, avg. loss 19.70, avg. ppl 11.42 cum. examples 1597, speed 7041.46 words/sec, time elapsed 100.81 sec\n",
            "epoch 10 (12 / 272), iter 2460, avg. loss 19.30, avg. ppl 10.99 cum. examples 1917, speed 6817.82 words/sec, time elapsed 101.18 sec\n",
            "epoch 10 (22 / 272), iter 2470, avg. loss 19.04, avg. ppl 10.55 cum. examples 2237, speed 6770.10 words/sec, time elapsed 101.57 sec\n",
            "epoch 10 (32 / 272), iter 2480, avg. loss 19.00, avg. ppl 10.48 cum. examples 2557, speed 6570.42 words/sec, time elapsed 101.96 sec\n",
            "epoch 10 (42 / 272), iter 2490, avg. loss 19.00, avg. ppl 10.59 cum. examples 2877, speed 7273.36 words/sec, time elapsed 102.31 sec\n",
            "epoch 10 (52 / 272), iter 2500, avg. loss 19.23, avg. ppl 10.73 cum. examples 3197, speed 6753.40 words/sec, time elapsed 102.70 sec\n",
            "epoch 10, iter 2500, cum. loss 19.50, cum. ppl 11.16 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 2500, dev. ppl 11.456561\n",
            "epoch 10, iter 2500: save currently the best model to [model.bin]\n",
            "epoch 10 (62 / 272), iter 2510, avg. loss 19.46, avg. ppl 10.87 cum. examples 320, speed 5033.54 words/sec, time elapsed 103.22 sec\n",
            "epoch 10 (72 / 272), iter 2520, avg. loss 19.40, avg. ppl 10.79 cum. examples 640, speed 6299.28 words/sec, time elapsed 103.63 sec\n",
            "epoch 10 (82 / 272), iter 2530, avg. loss 19.45, avg. ppl 10.96 cum. examples 960, speed 6743.20 words/sec, time elapsed 104.02 sec\n",
            "epoch 10 (92 / 272), iter 2540, avg. loss 19.77, avg. ppl 11.42 cum. examples 1280, speed 6496.48 words/sec, time elapsed 104.42 sec\n",
            "epoch 10 (102 / 272), iter 2550, avg. loss 18.51, avg. ppl 10.18 cum. examples 1600, speed 7150.80 words/sec, time elapsed 104.77 sec\n",
            "epoch 10 (112 / 272), iter 2560, avg. loss 19.72, avg. ppl 11.30 cum. examples 1920, speed 6952.45 words/sec, time elapsed 105.15 sec\n",
            "epoch 10 (122 / 272), iter 2570, avg. loss 20.37, avg. ppl 12.12 cum. examples 2240, speed 6829.05 words/sec, time elapsed 105.53 sec\n",
            "epoch 10 (132 / 272), iter 2580, avg. loss 18.86, avg. ppl 10.46 cum. examples 2560, speed 6429.82 words/sec, time elapsed 105.93 sec\n",
            "epoch 10 (142 / 272), iter 2590, avg. loss 18.91, avg. ppl 10.84 cum. examples 2880, speed 7146.38 words/sec, time elapsed 106.29 sec\n",
            "epoch 10 (152 / 272), iter 2600, avg. loss 18.91, avg. ppl 10.73 cum. examples 3200, speed 7144.12 words/sec, time elapsed 106.64 sec\n",
            "epoch 10, iter 2600, cum. loss 19.34, cum. ppl 10.96 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 2600, dev. ppl 11.102968\n",
            "epoch 10, iter 2600: save currently the best model to [model.bin]\n",
            "epoch 10 (162 / 272), iter 2610, avg. loss 19.88, avg. ppl 11.63 cum. examples 320, speed 4871.17 words/sec, time elapsed 107.18 sec\n",
            "epoch 10 (172 / 272), iter 2620, avg. loss 20.53, avg. ppl 11.94 cum. examples 640, speed 6954.18 words/sec, time elapsed 107.56 sec\n",
            "epoch 10 (182 / 272), iter 2630, avg. loss 19.03, avg. ppl 10.94 cum. examples 960, speed 6795.35 words/sec, time elapsed 107.93 sec\n",
            "epoch 10 (192 / 272), iter 2640, avg. loss 19.20, avg. ppl 10.69 cum. examples 1280, speed 6430.17 words/sec, time elapsed 108.33 sec\n",
            "epoch 10 (202 / 272), iter 2650, avg. loss 18.35, avg. ppl 10.16 cum. examples 1600, speed 6749.15 words/sec, time elapsed 108.71 sec\n",
            "epoch 10 (212 / 272), iter 2660, avg. loss 19.71, avg. ppl 11.38 cum. examples 1920, speed 6237.69 words/sec, time elapsed 109.13 sec\n",
            "epoch 10 (222 / 272), iter 2670, avg. loss 19.39, avg. ppl 11.02 cum. examples 2240, speed 6719.60 words/sec, time elapsed 109.51 sec\n",
            "epoch 10 (232 / 272), iter 2680, avg. loss 19.17, avg. ppl 10.50 cum. examples 2560, speed 6432.88 words/sec, time elapsed 109.92 sec\n",
            "epoch 10 (242 / 272), iter 2690, avg. loss 19.17, avg. ppl 10.77 cum. examples 2880, speed 6740.42 words/sec, time elapsed 110.30 sec\n",
            "epoch 10 (252 / 272), iter 2700, avg. loss 19.53, avg. ppl 10.80 cum. examples 3200, speed 6682.70 words/sec, time elapsed 110.69 sec\n",
            "epoch 10, iter 2700, cum. loss 19.39, cum. ppl 10.98 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 2700, dev. ppl 10.856850\n",
            "epoch 10, iter 2700: save currently the best model to [model.bin]\n",
            "epoch 10 (262 / 272), iter 2710, avg. loss 18.80, avg. ppl 10.39 cum. examples 320, speed 4964.65 words/sec, time elapsed 111.21 sec\n",
            "epoch 10 (272 / 272), iter 2720, avg. loss 18.17, avg. ppl 10.12 cum. examples 637, speed 6481.68 words/sec, time elapsed 111.60 sec\n",
            "epoch 11 (10 / 272), iter 2730, avg. loss 19.19, avg. ppl 10.20 cum. examples 957, speed 6686.48 words/sec, time elapsed 111.99 sec\n",
            "epoch 11 (20 / 272), iter 2740, avg. loss 18.48, avg. ppl 9.88 cum. examples 1277, speed 6703.98 words/sec, time elapsed 112.38 sec\n",
            "epoch 11 (30 / 272), iter 2750, avg. loss 18.03, avg. ppl 9.53 cum. examples 1597, speed 6480.14 words/sec, time elapsed 112.77 sec\n",
            "epoch 11 (40 / 272), iter 2760, avg. loss 18.21, avg. ppl 9.76 cum. examples 1917, speed 6296.89 words/sec, time elapsed 113.18 sec\n",
            "epoch 11 (50 / 272), iter 2770, avg. loss 18.58, avg. ppl 9.96 cum. examples 2237, speed 6238.70 words/sec, time elapsed 113.59 sec\n",
            "epoch 11 (60 / 272), iter 2780, avg. loss 20.02, avg. ppl 11.21 cum. examples 2557, speed 6636.53 words/sec, time elapsed 113.99 sec\n",
            "epoch 11 (70 / 272), iter 2790, avg. loss 18.70, avg. ppl 10.09 cum. examples 2877, speed 6636.65 words/sec, time elapsed 114.38 sec\n",
            "epoch 11 (80 / 272), iter 2800, avg. loss 18.84, avg. ppl 10.34 cum. examples 3197, speed 6608.26 words/sec, time elapsed 114.77 sec\n",
            "epoch 11, iter 2800, cum. loss 18.70, cum. ppl 10.14 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 2800, dev. ppl 10.695994\n",
            "epoch 11, iter 2800: save currently the best model to [model.bin]\n",
            "epoch 11 (90 / 272), iter 2810, avg. loss 19.39, avg. ppl 10.56 cum. examples 320, speed 4757.36 words/sec, time elapsed 115.33 sec\n",
            "epoch 11 (100 / 272), iter 2820, avg. loss 19.24, avg. ppl 10.53 cum. examples 640, speed 6405.60 words/sec, time elapsed 115.74 sec\n",
            "epoch 11 (110 / 272), iter 2830, avg. loss 18.35, avg. ppl 9.86 cum. examples 960, speed 6401.23 words/sec, time elapsed 116.14 sec\n",
            "epoch 11 (120 / 272), iter 2840, avg. loss 16.71, avg. ppl 8.39 cum. examples 1280, speed 6520.78 words/sec, time elapsed 116.52 sec\n",
            "epoch 11 (130 / 272), iter 2850, avg. loss 18.57, avg. ppl 10.21 cum. examples 1600, speed 6393.60 words/sec, time elapsed 116.92 sec\n",
            "epoch 11 (140 / 272), iter 2860, avg. loss 18.09, avg. ppl 9.67 cum. examples 1920, speed 6512.35 words/sec, time elapsed 117.31 sec\n",
            "epoch 11 (150 / 272), iter 2870, avg. loss 18.97, avg. ppl 10.34 cum. examples 2240, speed 6470.77 words/sec, time elapsed 117.72 sec\n",
            "epoch 11 (160 / 272), iter 2880, avg. loss 19.09, avg. ppl 10.40 cum. examples 2560, speed 6623.50 words/sec, time elapsed 118.11 sec\n",
            "epoch 11 (170 / 272), iter 2890, avg. loss 18.22, avg. ppl 9.78 cum. examples 2880, speed 6217.64 words/sec, time elapsed 118.52 sec\n",
            "epoch 11 (180 / 272), iter 2900, avg. loss 19.69, avg. ppl 11.23 cum. examples 3200, speed 6472.73 words/sec, time elapsed 118.92 sec\n",
            "epoch 11, iter 2900, cum. loss 18.63, cum. ppl 10.08 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 2900, dev. ppl 10.514306\n",
            "epoch 11, iter 2900: save currently the best model to [model.bin]\n",
            "epoch 11 (190 / 272), iter 2910, avg. loss 18.59, avg. ppl 10.19 cum. examples 320, speed 4848.10 words/sec, time elapsed 119.45 sec\n",
            "epoch 11 (200 / 272), iter 2920, avg. loss 18.18, avg. ppl 9.64 cum. examples 640, speed 6383.46 words/sec, time elapsed 119.86 sec\n",
            "epoch 11 (210 / 272), iter 2930, avg. loss 18.40, avg. ppl 9.99 cum. examples 960, speed 5754.35 words/sec, time elapsed 120.30 sec\n",
            "epoch 11 (220 / 272), iter 2940, avg. loss 18.64, avg. ppl 10.06 cum. examples 1280, speed 5930.34 words/sec, time elapsed 120.74 sec\n",
            "epoch 11 (230 / 272), iter 2950, avg. loss 19.40, avg. ppl 10.98 cum. examples 1600, speed 6333.60 words/sec, time elapsed 121.15 sec\n",
            "epoch 11 (240 / 272), iter 2960, avg. loss 18.88, avg. ppl 10.19 cum. examples 1920, speed 6357.33 words/sec, time elapsed 121.55 sec\n",
            "epoch 11 (250 / 272), iter 2970, avg. loss 17.40, avg. ppl 8.84 cum. examples 2240, speed 6503.25 words/sec, time elapsed 121.95 sec\n",
            "epoch 11 (260 / 272), iter 2980, avg. loss 18.93, avg. ppl 10.21 cum. examples 2560, speed 6616.59 words/sec, time elapsed 122.34 sec\n",
            "epoch 11 (270 / 272), iter 2990, avg. loss 19.45, avg. ppl 10.73 cum. examples 2880, speed 6681.74 words/sec, time elapsed 122.73 sec\n",
            "epoch 12 (8 / 272), iter 3000, avg. loss 17.66, avg. ppl 9.29 cum. examples 3197, speed 6552.47 words/sec, time elapsed 123.12 sec\n",
            "epoch 12, iter 3000, cum. loss 18.55, cum. ppl 10.00 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 3000, dev. ppl 10.250954\n",
            "epoch 12, iter 3000: save currently the best model to [model.bin]\n",
            "epoch 12 (18 / 272), iter 3010, avg. loss 18.11, avg. ppl 9.30 cum. examples 320, speed 4729.87 words/sec, time elapsed 123.67 sec\n",
            "epoch 12 (28 / 272), iter 3020, avg. loss 17.61, avg. ppl 8.97 cum. examples 640, speed 6718.12 words/sec, time elapsed 124.05 sec\n",
            "epoch 12 (38 / 272), iter 3030, avg. loss 18.55, avg. ppl 9.48 cum. examples 960, speed 6644.50 words/sec, time elapsed 124.45 sec\n",
            "epoch 12 (48 / 272), iter 3040, avg. loss 19.11, avg. ppl 10.57 cum. examples 1280, speed 6477.00 words/sec, time elapsed 124.85 sec\n",
            "epoch 12 (58 / 272), iter 3050, avg. loss 17.82, avg. ppl 9.01 cum. examples 1600, speed 6749.75 words/sec, time elapsed 125.23 sec\n",
            "epoch 12 (68 / 272), iter 3060, avg. loss 16.94, avg. ppl 8.56 cum. examples 1920, speed 6436.38 words/sec, time elapsed 125.63 sec\n",
            "epoch 12 (78 / 272), iter 3070, avg. loss 18.30, avg. ppl 9.53 cum. examples 2240, speed 6560.40 words/sec, time elapsed 126.02 sec\n",
            "epoch 12 (88 / 272), iter 3080, avg. loss 18.65, avg. ppl 9.86 cum. examples 2560, speed 6695.82 words/sec, time elapsed 126.41 sec\n",
            "epoch 12 (98 / 272), iter 3090, avg. loss 18.77, avg. ppl 10.04 cum. examples 2880, speed 6678.24 words/sec, time elapsed 126.80 sec\n",
            "epoch 12 (108 / 272), iter 3100, avg. loss 18.86, avg. ppl 9.93 cum. examples 3200, speed 6518.08 words/sec, time elapsed 127.20 sec\n",
            "epoch 12, iter 3100, cum. loss 18.27, cum. ppl 9.51 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 3100, dev. ppl 10.148228\n",
            "epoch 12, iter 3100: save currently the best model to [model.bin]\n",
            "epoch 12 (118 / 272), iter 3110, avg. loss 17.56, avg. ppl 9.02 cum. examples 320, speed 4628.11 words/sec, time elapsed 127.76 sec\n",
            "epoch 12 (128 / 272), iter 3120, avg. loss 18.08, avg. ppl 9.56 cum. examples 640, speed 7029.48 words/sec, time elapsed 128.12 sec\n",
            "epoch 12 (138 / 272), iter 3130, avg. loss 17.75, avg. ppl 9.16 cum. examples 960, speed 6273.15 words/sec, time elapsed 128.53 sec\n",
            "epoch 12 (148 / 272), iter 3140, avg. loss 18.60, avg. ppl 9.79 cum. examples 1280, speed 6090.66 words/sec, time elapsed 128.96 sec\n",
            "epoch 12 (158 / 272), iter 3150, avg. loss 17.82, avg. ppl 9.28 cum. examples 1600, speed 6602.77 words/sec, time elapsed 129.35 sec\n",
            "epoch 12 (168 / 272), iter 3160, avg. loss 17.13, avg. ppl 8.66 cum. examples 1920, speed 6446.67 words/sec, time elapsed 129.74 sec\n",
            "epoch 12 (178 / 272), iter 3170, avg. loss 19.14, avg. ppl 10.19 cum. examples 2240, speed 6630.17 words/sec, time elapsed 130.14 sec\n",
            "epoch 12 (188 / 272), iter 3180, avg. loss 17.41, avg. ppl 8.91 cum. examples 2560, speed 6547.77 words/sec, time elapsed 130.53 sec\n",
            "epoch 12 (198 / 272), iter 3190, avg. loss 18.22, avg. ppl 9.40 cum. examples 2880, speed 6543.73 words/sec, time elapsed 130.93 sec\n",
            "epoch 12 (208 / 272), iter 3200, avg. loss 18.30, avg. ppl 9.73 cum. examples 3200, speed 6894.15 words/sec, time elapsed 131.30 sec\n",
            "epoch 12, iter 3200, cum. loss 18.00, cum. ppl 9.36 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 3200, dev. ppl 9.896704\n",
            "epoch 12, iter 3200: save currently the best model to [model.bin]\n",
            "epoch 12 (218 / 272), iter 3210, avg. loss 19.51, avg. ppl 10.65 cum. examples 320, speed 4784.48 words/sec, time elapsed 131.85 sec\n",
            "epoch 12 (228 / 272), iter 3220, avg. loss 18.82, avg. ppl 9.93 cum. examples 640, speed 5464.59 words/sec, time elapsed 132.33 sec\n",
            "epoch 12 (238 / 272), iter 3230, avg. loss 18.04, avg. ppl 9.26 cum. examples 960, speed 6321.38 words/sec, time elapsed 132.74 sec\n",
            "epoch 12 (248 / 272), iter 3240, avg. loss 17.58, avg. ppl 8.82 cum. examples 1280, speed 6543.42 words/sec, time elapsed 133.14 sec\n",
            "epoch 12 (258 / 272), iter 3250, avg. loss 18.26, avg. ppl 9.81 cum. examples 1600, speed 6438.61 words/sec, time elapsed 133.53 sec\n",
            "epoch 12 (268 / 272), iter 3260, avg. loss 17.69, avg. ppl 9.18 cum. examples 1920, speed 6375.80 words/sec, time elapsed 133.94 sec\n",
            "epoch 13 (6 / 272), iter 3270, avg. loss 17.18, avg. ppl 8.81 cum. examples 2237, speed 7053.23 words/sec, time elapsed 134.29 sec\n",
            "epoch 13 (16 / 272), iter 3280, avg. loss 17.41, avg. ppl 8.86 cum. examples 2557, speed 6844.15 words/sec, time elapsed 134.66 sec\n",
            "epoch 13 (26 / 272), iter 3290, avg. loss 18.04, avg. ppl 9.24 cum. examples 2877, speed 7191.37 words/sec, time elapsed 135.02 sec\n",
            "epoch 13 (36 / 272), iter 3300, avg. loss 17.26, avg. ppl 8.61 cum. examples 3197, speed 7015.08 words/sec, time elapsed 135.39 sec\n",
            "epoch 13, iter 3300, cum. loss 17.98, cum. ppl 9.30 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 3300, dev. ppl 9.692521\n",
            "epoch 13, iter 3300: save currently the best model to [model.bin]\n",
            "epoch 13 (46 / 272), iter 3310, avg. loss 16.88, avg. ppl 8.39 cum. examples 320, speed 4729.10 words/sec, time elapsed 135.93 sec\n",
            "epoch 13 (56 / 272), iter 3320, avg. loss 18.64, avg. ppl 9.70 cum. examples 640, speed 7010.13 words/sec, time elapsed 136.30 sec\n",
            "epoch 13 (66 / 272), iter 3330, avg. loss 17.22, avg. ppl 8.58 cum. examples 960, speed 6302.04 words/sec, time elapsed 136.71 sec\n",
            "epoch 13 (76 / 272), iter 3340, avg. loss 18.48, avg. ppl 9.56 cum. examples 1280, speed 6943.22 words/sec, time elapsed 137.09 sec\n",
            "epoch 13 (86 / 272), iter 3350, avg. loss 17.23, avg. ppl 8.73 cum. examples 1600, speed 6699.83 words/sec, time elapsed 137.47 sec\n",
            "epoch 13 (96 / 272), iter 3360, avg. loss 17.23, avg. ppl 8.60 cum. examples 1920, speed 6268.14 words/sec, time elapsed 137.88 sec\n",
            "epoch 13 (106 / 272), iter 3370, avg. loss 18.27, avg. ppl 9.32 cum. examples 2240, speed 6525.54 words/sec, time elapsed 138.28 sec\n",
            "epoch 13 (116 / 272), iter 3380, avg. loss 17.29, avg. ppl 8.66 cum. examples 2560, speed 6599.87 words/sec, time elapsed 138.67 sec\n",
            "epoch 13 (126 / 272), iter 3390, avg. loss 17.90, avg. ppl 9.32 cum. examples 2880, speed 6385.38 words/sec, time elapsed 139.07 sec\n",
            "epoch 13 (136 / 272), iter 3400, avg. loss 18.03, avg. ppl 9.04 cum. examples 3200, speed 6594.81 words/sec, time elapsed 139.47 sec\n",
            "epoch 13, iter 3400, cum. loss 17.72, cum. ppl 8.98 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 3400, dev. ppl 9.602156\n",
            "epoch 13, iter 3400: save currently the best model to [model.bin]\n",
            "epoch 13 (146 / 272), iter 3410, avg. loss 17.16, avg. ppl 8.53 cum. examples 320, speed 4753.77 words/sec, time elapsed 140.00 sec\n",
            "epoch 13 (156 / 272), iter 3420, avg. loss 16.82, avg. ppl 8.36 cum. examples 640, speed 6994.46 words/sec, time elapsed 140.37 sec\n",
            "epoch 13 (166 / 272), iter 3430, avg. loss 18.25, avg. ppl 9.37 cum. examples 960, speed 6619.34 words/sec, time elapsed 140.76 sec\n",
            "epoch 13 (176 / 272), iter 3440, avg. loss 16.37, avg. ppl 7.83 cum. examples 1280, speed 5798.41 words/sec, time elapsed 141.20 sec\n",
            "epoch 13 (186 / 272), iter 3450, avg. loss 16.93, avg. ppl 8.41 cum. examples 1600, speed 5853.99 words/sec, time elapsed 141.64 sec\n",
            "epoch 13 (196 / 272), iter 3460, avg. loss 18.66, avg. ppl 9.58 cum. examples 1920, speed 6798.09 words/sec, time elapsed 142.02 sec\n",
            "epoch 13 (206 / 272), iter 3470, avg. loss 18.31, avg. ppl 9.37 cum. examples 2240, speed 6951.79 words/sec, time elapsed 142.40 sec\n",
            "epoch 13 (216 / 272), iter 3480, avg. loss 18.02, avg. ppl 9.02 cum. examples 2560, speed 6588.03 words/sec, time elapsed 142.80 sec\n",
            "epoch 13 (226 / 272), iter 3490, avg. loss 17.49, avg. ppl 8.74 cum. examples 2880, speed 7134.78 words/sec, time elapsed 143.16 sec\n",
            "epoch 13 (236 / 272), iter 3500, avg. loss 17.81, avg. ppl 9.01 cum. examples 3200, speed 7004.61 words/sec, time elapsed 143.53 sec\n",
            "epoch 13, iter 3500, cum. loss 17.58, cum. ppl 8.81 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 3500, dev. ppl 9.404655\n",
            "epoch 13, iter 3500: save currently the best model to [model.bin]\n",
            "epoch 13 (246 / 272), iter 3510, avg. loss 17.66, avg. ppl 8.57 cum. examples 320, speed 4994.73 words/sec, time elapsed 144.06 sec\n",
            "epoch 13 (256 / 272), iter 3520, avg. loss 17.69, avg. ppl 8.92 cum. examples 640, speed 7175.83 words/sec, time elapsed 144.42 sec\n",
            "epoch 13 (266 / 272), iter 3530, avg. loss 18.12, avg. ppl 9.20 cum. examples 960, speed 6364.15 words/sec, time elapsed 144.83 sec\n",
            "epoch 14 (4 / 272), iter 3540, avg. loss 18.04, avg. ppl 8.92 cum. examples 1277, speed 6846.52 words/sec, time elapsed 145.21 sec\n",
            "epoch 14 (14 / 272), iter 3550, avg. loss 16.84, avg. ppl 8.21 cum. examples 1597, speed 6715.32 words/sec, time elapsed 145.59 sec\n",
            "epoch 14 (24 / 272), iter 3560, avg. loss 17.00, avg. ppl 8.45 cum. examples 1917, speed 6408.86 words/sec, time elapsed 145.99 sec\n",
            "epoch 14 (34 / 272), iter 3570, avg. loss 17.49, avg. ppl 8.53 cum. examples 2237, speed 7030.87 words/sec, time elapsed 146.36 sec\n",
            "epoch 14 (44 / 272), iter 3580, avg. loss 17.08, avg. ppl 8.25 cum. examples 2557, speed 6296.26 words/sec, time elapsed 146.77 sec\n",
            "epoch 14 (54 / 272), iter 3590, avg. loss 15.88, avg. ppl 7.50 cum. examples 2877, speed 6706.00 words/sec, time elapsed 147.15 sec\n",
            "epoch 14 (64 / 272), iter 3600, avg. loss 17.98, avg. ppl 9.00 cum. examples 3197, speed 6937.09 words/sec, time elapsed 147.53 sec\n",
            "epoch 14, iter 3600, cum. loss 17.38, cum. ppl 8.55 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 3600, dev. ppl 9.259082\n",
            "epoch 14, iter 3600: save currently the best model to [model.bin]\n",
            "epoch 14 (74 / 272), iter 3610, avg. loss 17.35, avg. ppl 8.42 cum. examples 320, speed 4577.20 words/sec, time elapsed 148.10 sec\n",
            "epoch 14 (84 / 272), iter 3620, avg. loss 18.12, avg. ppl 9.03 cum. examples 640, speed 7219.36 words/sec, time elapsed 148.46 sec\n",
            "epoch 14 (94 / 272), iter 3630, avg. loss 18.03, avg. ppl 9.04 cum. examples 960, speed 6805.22 words/sec, time elapsed 148.85 sec\n",
            "epoch 14 (104 / 272), iter 3640, avg. loss 16.61, avg. ppl 8.07 cum. examples 1280, speed 6638.78 words/sec, time elapsed 149.23 sec\n",
            "epoch 14 (114 / 272), iter 3650, avg. loss 17.51, avg. ppl 8.60 cum. examples 1600, speed 6957.27 words/sec, time elapsed 149.61 sec\n",
            "epoch 14 (124 / 272), iter 3660, avg. loss 16.28, avg. ppl 7.82 cum. examples 1920, speed 6521.71 words/sec, time elapsed 149.99 sec\n",
            "epoch 14 (134 / 272), iter 3670, avg. loss 17.46, avg. ppl 8.58 cum. examples 2240, speed 7165.21 words/sec, time elapsed 150.36 sec\n",
            "epoch 14 (144 / 272), iter 3680, avg. loss 16.75, avg. ppl 8.09 cum. examples 2560, speed 6700.77 words/sec, time elapsed 150.74 sec\n",
            "epoch 14 (154 / 272), iter 3690, avg. loss 18.17, avg. ppl 9.34 cum. examples 2880, speed 6697.19 words/sec, time elapsed 151.13 sec\n",
            "epoch 14 (164 / 272), iter 3700, avg. loss 15.75, avg. ppl 7.34 cum. examples 3200, speed 6718.84 words/sec, time elapsed 151.51 sec\n",
            "epoch 14, iter 3700, cum. loss 17.20, cum. ppl 8.42 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 3700, dev. ppl 9.169148\n",
            "epoch 14, iter 3700: save currently the best model to [model.bin]\n",
            "epoch 14 (174 / 272), iter 3710, avg. loss 17.71, avg. ppl 8.49 cum. examples 320, speed 5080.07 words/sec, time elapsed 152.03 sec\n",
            "epoch 14 (184 / 272), iter 3720, avg. loss 16.93, avg. ppl 8.25 cum. examples 640, speed 5658.37 words/sec, time elapsed 152.48 sec\n",
            "epoch 14 (194 / 272), iter 3730, avg. loss 16.88, avg. ppl 8.02 cum. examples 960, speed 6958.94 words/sec, time elapsed 152.85 sec\n",
            "epoch 14 (204 / 272), iter 3740, avg. loss 16.30, avg. ppl 7.80 cum. examples 1280, speed 6936.55 words/sec, time elapsed 153.22 sec\n",
            "epoch 14 (214 / 272), iter 3750, avg. loss 17.54, avg. ppl 8.48 cum. examples 1600, speed 7199.75 words/sec, time elapsed 153.59 sec\n",
            "epoch 14 (224 / 272), iter 3760, avg. loss 17.80, avg. ppl 9.03 cum. examples 1920, speed 6678.56 words/sec, time elapsed 153.97 sec\n",
            "epoch 14 (234 / 272), iter 3770, avg. loss 16.88, avg. ppl 8.09 cum. examples 2240, speed 7000.48 words/sec, time elapsed 154.34 sec\n",
            "epoch 14 (244 / 272), iter 3780, avg. loss 17.02, avg. ppl 8.48 cum. examples 2560, speed 7043.00 words/sec, time elapsed 154.70 sec\n",
            "epoch 14 (254 / 272), iter 3790, avg. loss 17.60, avg. ppl 8.88 cum. examples 2880, speed 6029.72 words/sec, time elapsed 155.13 sec\n",
            "epoch 14 (264 / 272), iter 3800, avg. loss 17.68, avg. ppl 8.63 cum. examples 3200, speed 7030.67 words/sec, time elapsed 155.51 sec\n",
            "epoch 14, iter 3800, cum. loss 17.23, cum. ppl 8.41 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 3800, dev. ppl 8.973254\n",
            "epoch 14, iter 3800: save currently the best model to [model.bin]\n",
            "epoch 15 (2 / 272), iter 3810, avg. loss 16.90, avg. ppl 8.24 cum. examples 317, speed 4920.53 words/sec, time elapsed 156.02 sec\n",
            "epoch 15 (12 / 272), iter 3820, avg. loss 16.18, avg. ppl 7.47 cum. examples 637, speed 7034.92 words/sec, time elapsed 156.39 sec\n",
            "epoch 15 (22 / 272), iter 3830, avg. loss 16.57, avg. ppl 8.06 cum. examples 957, speed 6640.94 words/sec, time elapsed 156.77 sec\n",
            "epoch 15 (32 / 272), iter 3840, avg. loss 16.37, avg. ppl 7.71 cum. examples 1277, speed 6828.87 words/sec, time elapsed 157.15 sec\n",
            "epoch 15 (42 / 272), iter 3850, avg. loss 17.17, avg. ppl 8.16 cum. examples 1597, speed 7239.22 words/sec, time elapsed 157.51 sec\n",
            "epoch 15 (52 / 272), iter 3860, avg. loss 17.42, avg. ppl 8.58 cum. examples 1917, speed 6254.33 words/sec, time elapsed 157.92 sec\n",
            "epoch 15 (62 / 272), iter 3870, avg. loss 16.69, avg. ppl 7.74 cum. examples 2237, speed 6346.80 words/sec, time elapsed 158.33 sec\n",
            "epoch 15 (72 / 272), iter 3880, avg. loss 16.86, avg. ppl 8.20 cum. examples 2557, speed 6764.01 words/sec, time elapsed 158.71 sec\n",
            "epoch 15 (82 / 272), iter 3890, avg. loss 15.76, avg. ppl 7.42 cum. examples 2877, speed 6678.87 words/sec, time elapsed 159.09 sec\n",
            "epoch 15 (92 / 272), iter 3900, avg. loss 16.41, avg. ppl 7.62 cum. examples 3197, speed 6550.54 words/sec, time elapsed 159.49 sec\n",
            "epoch 15, iter 3900, cum. loss 16.63, cum. ppl 7.91 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 3900, dev. ppl 8.835736\n",
            "epoch 15, iter 3900: save currently the best model to [model.bin]\n",
            "epoch 15 (102 / 272), iter 3910, avg. loss 17.04, avg. ppl 8.03 cum. examples 320, speed 5012.39 words/sec, time elapsed 160.01 sec\n",
            "epoch 15 (112 / 272), iter 3920, avg. loss 18.25, avg. ppl 8.84 cum. examples 640, speed 6669.11 words/sec, time elapsed 160.41 sec\n",
            "epoch 15 (122 / 272), iter 3930, avg. loss 16.80, avg. ppl 8.19 cum. examples 960, speed 6704.07 words/sec, time elapsed 160.79 sec\n",
            "epoch 15 (132 / 272), iter 3940, avg. loss 16.61, avg. ppl 7.64 cum. examples 1280, speed 6995.76 words/sec, time elapsed 161.17 sec\n",
            "epoch 15 (142 / 272), iter 3950, avg. loss 16.29, avg. ppl 7.72 cum. examples 1600, speed 6815.04 words/sec, time elapsed 161.54 sec\n",
            "epoch 15 (152 / 272), iter 3960, avg. loss 17.43, avg. ppl 8.57 cum. examples 1920, speed 6936.87 words/sec, time elapsed 161.91 sec\n",
            "epoch 15 (162 / 272), iter 3970, avg. loss 15.71, avg. ppl 7.12 cum. examples 2240, speed 6733.16 words/sec, time elapsed 162.30 sec\n",
            "epoch 15 (172 / 272), iter 3980, avg. loss 16.11, avg. ppl 7.46 cum. examples 2560, speed 7034.05 words/sec, time elapsed 162.66 sec\n",
            "epoch 15 (182 / 272), iter 3990, avg. loss 16.02, avg. ppl 7.55 cum. examples 2880, speed 5715.82 words/sec, time elapsed 163.10 sec\n",
            "epoch 15 (192 / 272), iter 4000, avg. loss 16.91, avg. ppl 8.17 cum. examples 3200, speed 5666.32 words/sec, time elapsed 163.56 sec\n",
            "epoch 15, iter 4000, cum. loss 16.72, cum. ppl 7.92 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 4000, dev. ppl 8.826938\n",
            "epoch 15, iter 4000: save currently the best model to [model.bin]\n",
            "epoch 15 (202 / 272), iter 4010, avg. loss 15.65, avg. ppl 7.21 cum. examples 320, speed 4956.40 words/sec, time elapsed 164.07 sec\n",
            "epoch 15 (212 / 272), iter 4020, avg. loss 17.54, avg. ppl 8.69 cum. examples 640, speed 6851.47 words/sec, time elapsed 164.45 sec\n",
            "epoch 15 (222 / 272), iter 4030, avg. loss 17.31, avg. ppl 8.37 cum. examples 960, speed 6918.67 words/sec, time elapsed 164.83 sec\n",
            "epoch 15 (232 / 272), iter 4040, avg. loss 17.93, avg. ppl 8.70 cum. examples 1280, speed 6911.27 words/sec, time elapsed 165.21 sec\n",
            "epoch 15 (242 / 272), iter 4050, avg. loss 16.57, avg. ppl 7.77 cum. examples 1600, speed 7275.09 words/sec, time elapsed 165.57 sec\n",
            "epoch 15 (252 / 272), iter 4060, avg. loss 17.98, avg. ppl 8.81 cum. examples 1920, speed 6974.98 words/sec, time elapsed 165.94 sec\n",
            "epoch 15 (262 / 272), iter 4070, avg. loss 16.77, avg. ppl 7.80 cum. examples 2240, speed 6974.23 words/sec, time elapsed 166.32 sec\n",
            "epoch 15 (272 / 272), iter 4080, avg. loss 16.31, avg. ppl 7.73 cum. examples 2557, speed 6801.93 words/sec, time elapsed 166.69 sec\n",
            "epoch 16 (10 / 272), iter 4090, avg. loss 17.05, avg. ppl 7.85 cum. examples 2877, speed 6791.16 words/sec, time elapsed 167.08 sec\n",
            "epoch 16 (20 / 272), iter 4100, avg. loss 16.14, avg. ppl 7.49 cum. examples 3197, speed 6939.67 words/sec, time elapsed 167.45 sec\n",
            "epoch 16, iter 4100, cum. loss 16.93, cum. ppl 8.03 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 4100, dev. ppl 8.619056\n",
            "epoch 16, iter 4100: save currently the best model to [model.bin]\n",
            "epoch 16 (30 / 272), iter 4110, avg. loss 17.31, avg. ppl 7.91 cum. examples 320, speed 5037.77 words/sec, time elapsed 167.98 sec\n",
            "epoch 16 (40 / 272), iter 4120, avg. loss 17.05, avg. ppl 7.93 cum. examples 640, speed 6890.44 words/sec, time elapsed 168.37 sec\n",
            "epoch 16 (50 / 272), iter 4130, avg. loss 17.48, avg. ppl 8.33 cum. examples 960, speed 6925.22 words/sec, time elapsed 168.75 sec\n",
            "epoch 16 (60 / 272), iter 4140, avg. loss 15.79, avg. ppl 7.06 cum. examples 1280, speed 5892.38 words/sec, time elapsed 169.19 sec\n",
            "epoch 16 (70 / 272), iter 4150, avg. loss 15.61, avg. ppl 7.20 cum. examples 1600, speed 6093.26 words/sec, time elapsed 169.60 sec\n",
            "epoch 16 (80 / 272), iter 4160, avg. loss 16.61, avg. ppl 7.82 cum. examples 1920, speed 5832.51 words/sec, time elapsed 170.04 sec\n",
            "epoch 16 (90 / 272), iter 4170, avg. loss 15.72, avg. ppl 7.33 cum. examples 2240, speed 5763.95 words/sec, time elapsed 170.48 sec\n",
            "epoch 16 (100 / 272), iter 4180, avg. loss 15.41, avg. ppl 6.99 cum. examples 2560, speed 6852.78 words/sec, time elapsed 170.85 sec\n",
            "epoch 16 (110 / 272), iter 4190, avg. loss 16.13, avg. ppl 7.45 cum. examples 2880, speed 7013.71 words/sec, time elapsed 171.22 sec\n",
            "epoch 16 (120 / 272), iter 4200, avg. loss 15.56, avg. ppl 6.98 cum. examples 3200, speed 6836.50 words/sec, time elapsed 171.59 sec\n",
            "epoch 16, iter 4200, cum. loss 16.27, cum. ppl 7.49 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 4200, dev. ppl 8.566842\n",
            "epoch 16, iter 4200: save currently the best model to [model.bin]\n",
            "epoch 16 (130 / 272), iter 4210, avg. loss 17.12, avg. ppl 8.13 cum. examples 320, speed 4424.37 words/sec, time elapsed 172.19 sec\n",
            "epoch 16 (140 / 272), iter 4220, avg. loss 17.52, avg. ppl 8.70 cum. examples 640, speed 6088.12 words/sec, time elapsed 172.61 sec\n",
            "epoch 16 (150 / 272), iter 4230, avg. loss 15.60, avg. ppl 7.26 cum. examples 960, speed 6801.89 words/sec, time elapsed 172.98 sec\n",
            "epoch 16 (160 / 272), iter 4240, avg. loss 17.08, avg. ppl 8.28 cum. examples 1280, speed 6787.61 words/sec, time elapsed 173.36 sec\n",
            "epoch 16 (170 / 272), iter 4250, avg. loss 16.59, avg. ppl 7.78 cum. examples 1600, speed 6883.06 words/sec, time elapsed 173.74 sec\n",
            "epoch 16 (180 / 272), iter 4260, avg. loss 17.19, avg. ppl 8.02 cum. examples 1920, speed 6925.44 words/sec, time elapsed 174.12 sec\n",
            "epoch 16 (190 / 272), iter 4270, avg. loss 17.10, avg. ppl 8.14 cum. examples 2240, speed 6839.35 words/sec, time elapsed 174.50 sec\n",
            "epoch 16 (200 / 272), iter 4280, avg. loss 15.26, avg. ppl 6.82 cum. examples 2560, speed 7124.64 words/sec, time elapsed 174.86 sec\n",
            "epoch 16 (210 / 272), iter 4290, avg. loss 15.96, avg. ppl 7.42 cum. examples 2880, speed 6764.94 words/sec, time elapsed 175.24 sec\n",
            "epoch 16 (220 / 272), iter 4300, avg. loss 15.58, avg. ppl 6.99 cum. examples 3200, speed 6732.15 words/sec, time elapsed 175.62 sec\n",
            "epoch 16, iter 4300, cum. loss 16.50, cum. ppl 7.74 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 4300, dev. ppl 8.533403\n",
            "epoch 16, iter 4300: save currently the best model to [model.bin]\n",
            "epoch 16 (230 / 272), iter 4310, avg. loss 16.12, avg. ppl 7.55 cum. examples 320, speed 4905.85 words/sec, time elapsed 176.14 sec\n",
            "epoch 16 (240 / 272), iter 4320, avg. loss 16.48, avg. ppl 7.48 cum. examples 640, speed 6665.89 words/sec, time elapsed 176.53 sec\n",
            "epoch 16 (250 / 272), iter 4330, avg. loss 16.92, avg. ppl 7.94 cum. examples 960, speed 6110.56 words/sec, time elapsed 176.96 sec\n",
            "epoch 16 (260 / 272), iter 4340, avg. loss 16.10, avg. ppl 7.43 cum. examples 1280, speed 6767.48 words/sec, time elapsed 177.34 sec\n",
            "epoch 16 (270 / 272), iter 4350, avg. loss 16.08, avg. ppl 7.45 cum. examples 1600, speed 6635.02 words/sec, time elapsed 177.73 sec\n",
            "epoch 17 (8 / 272), iter 4360, avg. loss 15.68, avg. ppl 7.06 cum. examples 1917, speed 5942.54 words/sec, time elapsed 178.16 sec\n",
            "epoch 17 (18 / 272), iter 4370, avg. loss 15.67, avg. ppl 7.02 cum. examples 2237, speed 5524.94 words/sec, time elapsed 178.62 sec\n",
            "epoch 17 (28 / 272), iter 4380, avg. loss 16.39, avg. ppl 7.43 cum. examples 2557, speed 6286.56 words/sec, time elapsed 179.04 sec\n",
            "epoch 17 (38 / 272), iter 4390, avg. loss 16.47, avg. ppl 7.42 cum. examples 2877, speed 7055.09 words/sec, time elapsed 179.41 sec\n",
            "epoch 17 (48 / 272), iter 4400, avg. loss 15.94, avg. ppl 7.22 cum. examples 3197, speed 5963.83 words/sec, time elapsed 179.85 sec\n",
            "epoch 17, iter 4400, cum. loss 16.19, cum. ppl 7.40 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 4400, dev. ppl 8.299902\n",
            "epoch 17, iter 4400: save currently the best model to [model.bin]\n",
            "epoch 17 (58 / 272), iter 4410, avg. loss 16.22, avg. ppl 7.38 cum. examples 320, speed 5041.63 words/sec, time elapsed 180.36 sec\n",
            "epoch 17 (68 / 272), iter 4420, avg. loss 15.41, avg. ppl 6.85 cum. examples 640, speed 6967.97 words/sec, time elapsed 180.73 sec\n",
            "epoch 17 (78 / 272), iter 4430, avg. loss 15.33, avg. ppl 6.98 cum. examples 960, speed 5904.69 words/sec, time elapsed 181.16 sec\n",
            "epoch 17 (88 / 272), iter 4440, avg. loss 15.72, avg. ppl 6.99 cum. examples 1280, speed 7031.65 words/sec, time elapsed 181.53 sec\n",
            "epoch 17 (98 / 272), iter 4450, avg. loss 16.19, avg. ppl 7.25 cum. examples 1600, speed 7006.31 words/sec, time elapsed 181.90 sec\n",
            "epoch 17 (108 / 272), iter 4460, avg. loss 15.21, avg. ppl 6.82 cum. examples 1920, speed 7064.42 words/sec, time elapsed 182.26 sec\n",
            "epoch 17 (118 / 272), iter 4470, avg. loss 16.85, avg. ppl 7.83 cum. examples 2240, speed 6533.10 words/sec, time elapsed 182.66 sec\n",
            "epoch 17 (128 / 272), iter 4480, avg. loss 15.43, avg. ppl 6.95 cum. examples 2560, speed 7028.53 words/sec, time elapsed 183.02 sec\n",
            "epoch 17 (138 / 272), iter 4490, avg. loss 14.82, avg. ppl 6.69 cum. examples 2880, speed 7181.66 words/sec, time elapsed 183.37 sec\n",
            "epoch 17 (148 / 272), iter 4500, avg. loss 16.22, avg. ppl 7.62 cum. examples 3200, speed 6497.20 words/sec, time elapsed 183.76 sec\n",
            "epoch 17, iter 4500, cum. loss 15.74, cum. ppl 7.13 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 4500, dev. ppl 8.307105\n",
            "hit patience 1\n",
            "epoch 17 (158 / 272), iter 4510, avg. loss 16.68, avg. ppl 7.50 cum. examples 320, speed 5146.71 words/sec, time elapsed 184.28 sec\n",
            "epoch 17 (168 / 272), iter 4520, avg. loss 16.15, avg. ppl 7.33 cum. examples 640, speed 6520.58 words/sec, time elapsed 184.68 sec\n",
            "epoch 17 (178 / 272), iter 4530, avg. loss 17.99, avg. ppl 8.47 cum. examples 960, speed 7284.22 words/sec, time elapsed 185.05 sec\n",
            "epoch 17 (188 / 272), iter 4540, avg. loss 16.00, avg. ppl 7.28 cum. examples 1280, speed 7220.02 words/sec, time elapsed 185.40 sec\n",
            "epoch 17 (198 / 272), iter 4550, avg. loss 16.48, avg. ppl 7.55 cum. examples 1600, speed 6717.06 words/sec, time elapsed 185.79 sec\n",
            "epoch 17 (208 / 272), iter 4560, avg. loss 15.22, avg. ppl 6.58 cum. examples 1920, speed 6936.76 words/sec, time elapsed 186.16 sec\n",
            "epoch 17 (218 / 272), iter 4570, avg. loss 15.75, avg. ppl 7.13 cum. examples 2240, speed 6893.81 words/sec, time elapsed 186.54 sec\n",
            "epoch 17 (228 / 272), iter 4580, avg. loss 16.31, avg. ppl 7.57 cum. examples 2560, speed 5880.63 words/sec, time elapsed 186.98 sec\n",
            "epoch 17 (238 / 272), iter 4590, avg. loss 15.13, avg. ppl 6.75 cum. examples 2880, speed 7216.97 words/sec, time elapsed 187.33 sec\n",
            "epoch 17 (248 / 272), iter 4600, avg. loss 16.54, avg. ppl 7.52 cum. examples 3200, speed 6659.13 words/sec, time elapsed 187.72 sec\n",
            "epoch 17, iter 4600, cum. loss 16.23, cum. ppl 7.36 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 4600, dev. ppl 8.129399\n",
            "epoch 17, iter 4600: save currently the best model to [model.bin]\n",
            "epoch 17 (258 / 272), iter 4610, avg. loss 16.96, avg. ppl 7.85 cum. examples 320, speed 5294.28 words/sec, time elapsed 188.22 sec\n",
            "epoch 17 (268 / 272), iter 4620, avg. loss 15.73, avg. ppl 7.20 cum. examples 640, speed 7329.12 words/sec, time elapsed 188.57 sec\n",
            "epoch 18 (6 / 272), iter 4630, avg. loss 16.23, avg. ppl 7.37 cum. examples 957, speed 6261.48 words/sec, time elapsed 188.98 sec\n",
            "epoch 18 (16 / 272), iter 4640, avg. loss 15.16, avg. ppl 6.60 cum. examples 1277, speed 6928.91 words/sec, time elapsed 189.35 sec\n",
            "epoch 18 (26 / 272), iter 4650, avg. loss 15.46, avg. ppl 6.73 cum. examples 1597, speed 7178.25 words/sec, time elapsed 189.71 sec\n",
            "epoch 18 (36 / 272), iter 4660, avg. loss 14.52, avg. ppl 6.20 cum. examples 1917, speed 7132.85 words/sec, time elapsed 190.07 sec\n",
            "epoch 18 (46 / 272), iter 4670, avg. loss 16.12, avg. ppl 7.12 cum. examples 2237, speed 6985.12 words/sec, time elapsed 190.45 sec\n",
            "epoch 18 (56 / 272), iter 4680, avg. loss 15.40, avg. ppl 7.03 cum. examples 2557, speed 6210.46 words/sec, time elapsed 190.85 sec\n",
            "epoch 18 (66 / 272), iter 4690, avg. loss 15.84, avg. ppl 7.10 cum. examples 2877, speed 7008.93 words/sec, time elapsed 191.22 sec\n",
            "epoch 18 (76 / 272), iter 4700, avg. loss 16.70, avg. ppl 7.51 cum. examples 3197, speed 6893.51 words/sec, time elapsed 191.61 sec\n",
            "epoch 18, iter 4700, cum. loss 15.81, cum. ppl 7.06 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 4700, dev. ppl 8.133376\n",
            "hit patience 1\n",
            "epoch 18 (86 / 272), iter 4710, avg. loss 15.24, avg. ppl 6.69 cum. examples 320, speed 4786.71 words/sec, time elapsed 192.14 sec\n",
            "epoch 18 (96 / 272), iter 4720, avg. loss 15.70, avg. ppl 6.84 cum. examples 640, speed 6990.47 words/sec, time elapsed 192.52 sec\n",
            "epoch 18 (106 / 272), iter 4730, avg. loss 14.77, avg. ppl 6.30 cum. examples 960, speed 6458.74 words/sec, time elapsed 192.92 sec\n",
            "epoch 18 (116 / 272), iter 4740, avg. loss 14.74, avg. ppl 6.41 cum. examples 1280, speed 6906.27 words/sec, time elapsed 193.28 sec\n",
            "epoch 18 (126 / 272), iter 4750, avg. loss 16.16, avg. ppl 7.24 cum. examples 1600, speed 7061.20 words/sec, time elapsed 193.65 sec\n",
            "epoch 18 (136 / 272), iter 4760, avg. loss 14.93, avg. ppl 6.51 cum. examples 1920, speed 6916.34 words/sec, time elapsed 194.02 sec\n",
            "epoch 18 (146 / 272), iter 4770, avg. loss 16.17, avg. ppl 7.35 cum. examples 2240, speed 7138.46 words/sec, time elapsed 194.39 sec\n",
            "epoch 18 (156 / 272), iter 4780, avg. loss 15.32, avg. ppl 6.62 cum. examples 2560, speed 6658.08 words/sec, time elapsed 194.78 sec\n",
            "epoch 18 (166 / 272), iter 4790, avg. loss 15.97, avg. ppl 7.13 cum. examples 2880, speed 6485.44 words/sec, time elapsed 195.18 sec\n",
            "epoch 18 (176 / 272), iter 4800, avg. loss 17.31, avg. ppl 8.17 cum. examples 3200, speed 6956.05 words/sec, time elapsed 195.56 sec\n",
            "epoch 18, iter 4800, cum. loss 15.63, cum. ppl 6.91 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 4800, dev. ppl 7.935547\n",
            "epoch 18, iter 4800: save currently the best model to [model.bin]\n",
            "epoch 18 (186 / 272), iter 4810, avg. loss 16.12, avg. ppl 7.30 cum. examples 320, speed 4360.78 words/sec, time elapsed 196.15 sec\n",
            "epoch 18 (196 / 272), iter 4820, avg. loss 13.87, avg. ppl 5.69 cum. examples 640, speed 5631.19 words/sec, time elapsed 196.60 sec\n",
            "epoch 18 (206 / 272), iter 4830, avg. loss 15.05, avg. ppl 6.72 cum. examples 960, speed 6630.23 words/sec, time elapsed 196.99 sec\n",
            "epoch 18 (216 / 272), iter 4840, avg. loss 16.24, avg. ppl 7.30 cum. examples 1280, speed 7049.31 words/sec, time elapsed 197.36 sec\n",
            "epoch 18 (226 / 272), iter 4850, avg. loss 15.82, avg. ppl 7.02 cum. examples 1600, speed 6748.61 words/sec, time elapsed 197.74 sec\n",
            "epoch 18 (236 / 272), iter 4860, avg. loss 17.52, avg. ppl 8.35 cum. examples 1920, speed 6689.09 words/sec, time elapsed 198.14 sec\n",
            "epoch 18 (246 / 272), iter 4870, avg. loss 15.84, avg. ppl 7.27 cum. examples 2240, speed 6865.38 words/sec, time elapsed 198.51 sec\n",
            "epoch 18 (256 / 272), iter 4880, avg. loss 16.01, avg. ppl 7.20 cum. examples 2560, speed 6726.98 words/sec, time elapsed 198.90 sec\n",
            "epoch 18 (266 / 272), iter 4890, avg. loss 14.89, avg. ppl 6.50 cum. examples 2880, speed 6835.25 words/sec, time elapsed 199.27 sec\n",
            "epoch 19 (4 / 272), iter 4900, avg. loss 14.84, avg. ppl 6.36 cum. examples 3197, speed 6859.78 words/sec, time elapsed 199.64 sec\n",
            "epoch 19, iter 4900, cum. loss 15.62, cum. ppl 6.95 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 4900, dev. ppl 7.891976\n",
            "epoch 19, iter 4900: save currently the best model to [model.bin]\n",
            "epoch 19 (14 / 272), iter 4910, avg. loss 15.60, avg. ppl 6.75 cum. examples 320, speed 4995.49 words/sec, time elapsed 200.16 sec\n",
            "epoch 19 (24 / 272), iter 4920, avg. loss 15.72, avg. ppl 6.95 cum. examples 640, speed 6629.66 words/sec, time elapsed 200.55 sec\n",
            "epoch 19 (34 / 272), iter 4930, avg. loss 15.32, avg. ppl 6.63 cum. examples 960, speed 6310.04 words/sec, time elapsed 200.96 sec\n",
            "epoch 19 (44 / 272), iter 4940, avg. loss 14.78, avg. ppl 6.29 cum. examples 1280, speed 7060.36 words/sec, time elapsed 201.33 sec\n",
            "epoch 19 (54 / 272), iter 4950, avg. loss 15.93, avg. ppl 7.10 cum. examples 1600, speed 6815.78 words/sec, time elapsed 201.71 sec\n",
            "epoch 19 (64 / 272), iter 4960, avg. loss 15.52, avg. ppl 6.72 cum. examples 1920, speed 6842.08 words/sec, time elapsed 202.09 sec\n",
            "epoch 19 (74 / 272), iter 4970, avg. loss 15.55, avg. ppl 6.70 cum. examples 2240, speed 7031.63 words/sec, time elapsed 202.46 sec\n",
            "epoch 19 (84 / 272), iter 4980, avg. loss 14.94, avg. ppl 6.42 cum. examples 2560, speed 6720.82 words/sec, time elapsed 202.85 sec\n",
            "epoch 19 (94 / 272), iter 4990, avg. loss 15.40, avg. ppl 6.78 cum. examples 2880, speed 6877.61 words/sec, time elapsed 203.22 sec\n",
            "epoch 19 (104 / 272), iter 5000, avg. loss 15.34, avg. ppl 6.67 cum. examples 3200, speed 6809.76 words/sec, time elapsed 203.60 sec\n",
            "epoch 19, iter 5000, cum. loss 15.41, cum. ppl 6.70 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 5000, dev. ppl 7.780243\n",
            "epoch 19, iter 5000: save currently the best model to [model.bin]\n",
            "epoch 19 (114 / 272), iter 5010, avg. loss 15.71, avg. ppl 6.83 cum. examples 320, speed 4966.28 words/sec, time elapsed 204.13 sec\n",
            "epoch 19 (124 / 272), iter 5020, avg. loss 16.84, avg. ppl 7.68 cum. examples 640, speed 6277.95 words/sec, time elapsed 204.55 sec\n",
            "epoch 19 (134 / 272), iter 5030, avg. loss 15.02, avg. ppl 6.40 cum. examples 960, speed 6228.68 words/sec, time elapsed 204.97 sec\n",
            "epoch 19 (144 / 272), iter 5040, avg. loss 15.83, avg. ppl 6.91 cum. examples 1280, speed 6814.16 words/sec, time elapsed 205.35 sec\n",
            "epoch 19 (154 / 272), iter 5050, avg. loss 14.97, avg. ppl 6.45 cum. examples 1600, speed 6713.78 words/sec, time elapsed 205.73 sec\n",
            "epoch 19 (164 / 272), iter 5060, avg. loss 14.65, avg. ppl 6.22 cum. examples 1920, speed 6621.89 words/sec, time elapsed 206.12 sec\n",
            "epoch 19 (174 / 272), iter 5070, avg. loss 15.51, avg. ppl 6.71 cum. examples 2240, speed 6095.44 words/sec, time elapsed 206.55 sec\n",
            "epoch 19 (184 / 272), iter 5080, avg. loss 14.07, avg. ppl 6.09 cum. examples 2560, speed 5822.55 words/sec, time elapsed 206.98 sec\n",
            "epoch 19 (194 / 272), iter 5090, avg. loss 15.64, avg. ppl 7.02 cum. examples 2880, speed 6945.14 words/sec, time elapsed 207.35 sec\n",
            "epoch 19 (204 / 272), iter 5100, avg. loss 15.24, avg. ppl 6.56 cum. examples 3200, speed 6322.46 words/sec, time elapsed 207.76 sec\n",
            "epoch 19, iter 5100, cum. loss 15.35, cum. ppl 6.68 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 5100, dev. ppl 7.789912\n",
            "hit patience 1\n",
            "epoch 19 (214 / 272), iter 5110, avg. loss 15.92, avg. ppl 7.05 cum. examples 320, speed 4925.62 words/sec, time elapsed 208.29 sec\n",
            "epoch 19 (224 / 272), iter 5120, avg. loss 14.08, avg. ppl 5.99 cum. examples 640, speed 6767.20 words/sec, time elapsed 208.66 sec\n",
            "epoch 19 (234 / 272), iter 5130, avg. loss 16.10, avg. ppl 7.10 cum. examples 960, speed 7300.18 words/sec, time elapsed 209.02 sec\n",
            "epoch 19 (244 / 272), iter 5140, avg. loss 14.97, avg. ppl 6.43 cum. examples 1280, speed 6810.64 words/sec, time elapsed 209.40 sec\n",
            "epoch 19 (254 / 272), iter 5150, avg. loss 14.55, avg. ppl 6.22 cum. examples 1600, speed 6284.94 words/sec, time elapsed 209.80 sec\n",
            "epoch 19 (264 / 272), iter 5160, avg. loss 14.30, avg. ppl 6.05 cum. examples 1920, speed 6878.86 words/sec, time elapsed 210.17 sec\n",
            "epoch 20 (2 / 272), iter 5170, avg. loss 15.21, avg. ppl 6.56 cum. examples 2237, speed 6748.44 words/sec, time elapsed 210.55 sec\n",
            "epoch 20 (12 / 272), iter 5180, avg. loss 15.02, avg. ppl 6.36 cum. examples 2557, speed 5668.24 words/sec, time elapsed 211.01 sec\n",
            "epoch 20 (22 / 272), iter 5190, avg. loss 14.22, avg. ppl 5.86 cum. examples 2877, speed 6065.82 words/sec, time elapsed 211.43 sec\n",
            "epoch 20 (32 / 272), iter 5200, avg. loss 14.81, avg. ppl 6.29 cum. examples 3197, speed 6537.99 words/sec, time elapsed 211.83 sec\n",
            "epoch 20, iter 5200, cum. loss 14.92, cum. ppl 6.38 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 5200, dev. ppl 7.613185\n",
            "epoch 20, iter 5200: save currently the best model to [model.bin]\n",
            "epoch 20 (42 / 272), iter 5210, avg. loss 15.07, avg. ppl 6.34 cum. examples 320, speed 4816.01 words/sec, time elapsed 212.37 sec\n",
            "epoch 20 (52 / 272), iter 5220, avg. loss 14.30, avg. ppl 5.92 cum. examples 640, speed 6914.11 words/sec, time elapsed 212.74 sec\n",
            "epoch 20 (62 / 272), iter 5230, avg. loss 14.21, avg. ppl 5.96 cum. examples 960, speed 7156.58 words/sec, time elapsed 213.10 sec\n",
            "epoch 20 (72 / 272), iter 5240, avg. loss 14.98, avg. ppl 6.26 cum. examples 1280, speed 6896.93 words/sec, time elapsed 213.48 sec\n",
            "epoch 20 (82 / 272), iter 5250, avg. loss 14.86, avg. ppl 6.35 cum. examples 1600, speed 6606.54 words/sec, time elapsed 213.87 sec\n",
            "epoch 20 (92 / 272), iter 5260, avg. loss 14.44, avg. ppl 6.06 cum. examples 1920, speed 6683.45 words/sec, time elapsed 214.25 sec\n",
            "epoch 20 (102 / 272), iter 5270, avg. loss 15.46, avg. ppl 6.65 cum. examples 2240, speed 6838.38 words/sec, time elapsed 214.64 sec\n",
            "epoch 20 (112 / 272), iter 5280, avg. loss 14.59, avg. ppl 6.03 cum. examples 2560, speed 6800.17 words/sec, time elapsed 215.02 sec\n",
            "epoch 20 (122 / 272), iter 5290, avg. loss 15.01, avg. ppl 6.49 cum. examples 2880, speed 6741.48 words/sec, time elapsed 215.40 sec\n",
            "epoch 20 (132 / 272), iter 5300, avg. loss 15.86, avg. ppl 7.08 cum. examples 3200, speed 6862.50 words/sec, time elapsed 215.78 sec\n",
            "epoch 20, iter 5300, cum. loss 14.88, cum. ppl 6.31 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 5300, dev. ppl 7.672249\n",
            "hit patience 1\n",
            "epoch 20 (142 / 272), iter 5310, avg. loss 14.76, avg. ppl 6.42 cum. examples 320, speed 4857.68 words/sec, time elapsed 216.30 sec\n",
            "epoch 20 (152 / 272), iter 5320, avg. loss 15.57, avg. ppl 6.73 cum. examples 640, speed 6883.05 words/sec, time elapsed 216.68 sec\n",
            "epoch 20 (162 / 272), iter 5330, avg. loss 14.80, avg. ppl 6.38 cum. examples 960, speed 6973.30 words/sec, time elapsed 217.05 sec\n",
            "epoch 20 (172 / 272), iter 5340, avg. loss 14.65, avg. ppl 6.26 cum. examples 1280, speed 6818.09 words/sec, time elapsed 217.42 sec\n",
            "epoch 20 (182 / 272), iter 5350, avg. loss 14.82, avg. ppl 6.30 cum. examples 1600, speed 6796.59 words/sec, time elapsed 217.80 sec\n",
            "epoch 20 (192 / 272), iter 5360, avg. loss 15.36, avg. ppl 6.66 cum. examples 1920, speed 5649.21 words/sec, time elapsed 218.26 sec\n",
            "epoch 20 (202 / 272), iter 5370, avg. loss 15.45, avg. ppl 6.60 cum. examples 2240, speed 6248.45 words/sec, time elapsed 218.68 sec\n",
            "epoch 20 (212 / 272), iter 5380, avg. loss 14.30, avg. ppl 5.87 cum. examples 2560, speed 7039.02 words/sec, time elapsed 219.05 sec\n",
            "epoch 20 (222 / 272), iter 5390, avg. loss 14.55, avg. ppl 6.13 cum. examples 2880, speed 6273.73 words/sec, time elapsed 219.46 sec\n",
            "epoch 20 (232 / 272), iter 5400, avg. loss 15.33, avg. ppl 6.61 cum. examples 3200, speed 6315.77 words/sec, time elapsed 219.87 sec\n",
            "epoch 20, iter 5400, cum. loss 14.96, cum. ppl 6.39 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 5400, dev. ppl 7.448502\n",
            "epoch 20, iter 5400: save currently the best model to [model.bin]\n",
            "epoch 20 (242 / 272), iter 5410, avg. loss 15.28, avg. ppl 6.48 cum. examples 320, speed 4559.38 words/sec, time elapsed 220.44 sec\n",
            "epoch 20 (252 / 272), iter 5420, avg. loss 15.11, avg. ppl 6.70 cum. examples 640, speed 6694.56 words/sec, time elapsed 220.82 sec\n",
            "epoch 20 (262 / 272), iter 5430, avg. loss 15.78, avg. ppl 6.77 cum. examples 960, speed 6501.06 words/sec, time elapsed 221.23 sec\n",
            "epoch 20 (272 / 272), iter 5440, avg. loss 15.02, avg. ppl 6.35 cum. examples 1277, speed 6051.66 words/sec, time elapsed 221.65 sec\n",
            "epoch 21 (10 / 272), iter 5450, avg. loss 14.20, avg. ppl 5.90 cum. examples 1597, speed 6829.13 words/sec, time elapsed 222.03 sec\n",
            "epoch 21 (20 / 272), iter 5460, avg. loss 14.13, avg. ppl 5.87 cum. examples 1917, speed 6520.94 words/sec, time elapsed 222.42 sec\n",
            "epoch 21 (30 / 272), iter 5470, avg. loss 15.15, avg. ppl 6.30 cum. examples 2237, speed 6422.98 words/sec, time elapsed 222.83 sec\n",
            "epoch 21 (40 / 272), iter 5480, avg. loss 14.19, avg. ppl 5.83 cum. examples 2557, speed 7141.27 words/sec, time elapsed 223.19 sec\n",
            "epoch 21 (50 / 272), iter 5490, avg. loss 13.80, avg. ppl 5.64 cum. examples 2877, speed 5818.84 words/sec, time elapsed 223.63 sec\n",
            "epoch 21 (60 / 272), iter 5500, avg. loss 14.79, avg. ppl 6.09 cum. examples 3197, speed 6992.77 words/sec, time elapsed 224.01 sec\n",
            "epoch 21, iter 5500, cum. loss 14.74, cum. ppl 6.18 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 5500, dev. ppl 7.497154\n",
            "hit patience 1\n",
            "epoch 21 (70 / 272), iter 5510, avg. loss 13.26, avg. ppl 5.31 cum. examples 320, speed 4814.36 words/sec, time elapsed 224.53 sec\n",
            "epoch 21 (80 / 272), iter 5520, avg. loss 14.76, avg. ppl 6.35 cum. examples 640, speed 6427.62 words/sec, time elapsed 224.93 sec\n",
            "epoch 21 (90 / 272), iter 5530, avg. loss 15.08, avg. ppl 6.35 cum. examples 960, speed 7117.04 words/sec, time elapsed 225.30 sec\n",
            "epoch 21 (100 / 272), iter 5540, avg. loss 15.01, avg. ppl 6.29 cum. examples 1280, speed 6163.50 words/sec, time elapsed 225.72 sec\n",
            "epoch 21 (110 / 272), iter 5550, avg. loss 14.70, avg. ppl 6.07 cum. examples 1600, speed 6037.95 words/sec, time elapsed 226.15 sec\n",
            "epoch 21 (120 / 272), iter 5560, avg. loss 14.46, avg. ppl 5.99 cum. examples 1920, speed 5594.25 words/sec, time elapsed 226.62 sec\n",
            "epoch 21 (130 / 272), iter 5570, avg. loss 13.26, avg. ppl 5.45 cum. examples 2240, speed 6507.64 words/sec, time elapsed 227.00 sec\n",
            "epoch 21 (140 / 272), iter 5580, avg. loss 14.12, avg. ppl 5.90 cum. examples 2560, speed 6371.14 words/sec, time elapsed 227.40 sec\n",
            "epoch 21 (150 / 272), iter 5590, avg. loss 14.61, avg. ppl 6.05 cum. examples 2880, speed 6388.48 words/sec, time elapsed 227.81 sec\n",
            "epoch 21 (160 / 272), iter 5600, avg. loss 15.04, avg. ppl 6.28 cum. examples 3200, speed 5805.74 words/sec, time elapsed 228.26 sec\n",
            "epoch 21, iter 5600, cum. loss 14.43, cum. ppl 6.00 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 5600, dev. ppl 7.373754\n",
            "epoch 21, iter 5600: save currently the best model to [model.bin]\n",
            "epoch 21 (170 / 272), iter 5610, avg. loss 15.37, avg. ppl 6.60 cum. examples 320, speed 4646.23 words/sec, time elapsed 228.82 sec\n",
            "epoch 21 (180 / 272), iter 5620, avg. loss 14.38, avg. ppl 5.96 cum. examples 640, speed 7072.33 words/sec, time elapsed 229.19 sec\n",
            "epoch 21 (190 / 272), iter 5630, avg. loss 15.76, avg. ppl 6.86 cum. examples 960, speed 6852.04 words/sec, time elapsed 229.57 sec\n",
            "epoch 21 (200 / 272), iter 5640, avg. loss 13.86, avg. ppl 5.83 cum. examples 1280, speed 6530.06 words/sec, time elapsed 229.95 sec\n",
            "epoch 21 (210 / 272), iter 5650, avg. loss 15.00, avg. ppl 6.31 cum. examples 1600, speed 7250.32 words/sec, time elapsed 230.31 sec\n",
            "epoch 21 (220 / 272), iter 5660, avg. loss 14.62, avg. ppl 6.18 cum. examples 1920, speed 6730.16 words/sec, time elapsed 230.69 sec\n",
            "epoch 21 (230 / 272), iter 5670, avg. loss 14.57, avg. ppl 6.09 cum. examples 2240, speed 6484.88 words/sec, time elapsed 231.09 sec\n",
            "epoch 21 (240 / 272), iter 5680, avg. loss 15.01, avg. ppl 6.40 cum. examples 2560, speed 6697.43 words/sec, time elapsed 231.48 sec\n",
            "epoch 21 (250 / 272), iter 5690, avg. loss 14.96, avg. ppl 6.34 cum. examples 2880, speed 6722.71 words/sec, time elapsed 231.86 sec\n",
            "epoch 21 (260 / 272), iter 5700, avg. loss 15.23, avg. ppl 6.49 cum. examples 3200, speed 6654.17 words/sec, time elapsed 232.26 sec\n",
            "epoch 21, iter 5700, cum. loss 14.88, cum. ppl 6.30 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 5700, dev. ppl 7.237744\n",
            "epoch 21, iter 5700: save currently the best model to [model.bin]\n",
            "epoch 21 (270 / 272), iter 5710, avg. loss 15.72, avg. ppl 6.69 cum. examples 320, speed 4933.65 words/sec, time elapsed 232.79 sec\n",
            "epoch 22 (8 / 272), iter 5720, avg. loss 14.46, avg. ppl 6.07 cum. examples 637, speed 6744.41 words/sec, time elapsed 233.17 sec\n",
            "epoch 22 (18 / 272), iter 5730, avg. loss 13.99, avg. ppl 5.81 cum. examples 957, speed 7045.39 words/sec, time elapsed 233.53 sec\n",
            "epoch 22 (28 / 272), iter 5740, avg. loss 15.77, avg. ppl 6.65 cum. examples 1277, speed 6825.55 words/sec, time elapsed 233.92 sec\n",
            "epoch 22 (38 / 272), iter 5750, avg. loss 14.20, avg. ppl 5.74 cum. examples 1597, speed 7082.11 words/sec, time elapsed 234.29 sec\n",
            "epoch 22 (48 / 272), iter 5760, avg. loss 14.30, avg. ppl 5.92 cum. examples 1917, speed 5936.74 words/sec, time elapsed 234.72 sec\n",
            "epoch 22 (58 / 272), iter 5770, avg. loss 14.40, avg. ppl 5.78 cum. examples 2237, speed 6363.37 words/sec, time elapsed 235.14 sec\n",
            "epoch 22 (68 / 272), iter 5780, avg. loss 14.64, avg. ppl 5.92 cum. examples 2557, speed 7174.12 words/sec, time elapsed 235.50 sec\n",
            "epoch 22 (78 / 272), iter 5790, avg. loss 14.23, avg. ppl 5.86 cum. examples 2877, speed 6122.99 words/sec, time elapsed 235.92 sec\n",
            "epoch 22 (88 / 272), iter 5800, avg. loss 13.77, avg. ppl 5.56 cum. examples 3197, speed 6907.92 words/sec, time elapsed 236.30 sec\n",
            "epoch 22, iter 5800, cum. loss 14.55, cum. ppl 5.99 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 5800, dev. ppl 7.184008\n",
            "epoch 22, iter 5800: save currently the best model to [model.bin]\n",
            "epoch 22 (98 / 272), iter 5810, avg. loss 14.62, avg. ppl 6.12 cum. examples 320, speed 4825.04 words/sec, time elapsed 236.83 sec\n",
            "epoch 22 (108 / 272), iter 5820, avg. loss 13.47, avg. ppl 5.39 cum. examples 640, speed 7074.19 words/sec, time elapsed 237.19 sec\n",
            "epoch 22 (118 / 272), iter 5830, avg. loss 14.89, avg. ppl 6.25 cum. examples 960, speed 6912.64 words/sec, time elapsed 237.57 sec\n",
            "epoch 22 (128 / 272), iter 5840, avg. loss 13.79, avg. ppl 5.68 cum. examples 1280, speed 6024.15 words/sec, time elapsed 237.99 sec\n",
            "epoch 22 (138 / 272), iter 5850, avg. loss 13.59, avg. ppl 5.46 cum. examples 1600, speed 6929.95 words/sec, time elapsed 238.36 sec\n",
            "epoch 22 (148 / 272), iter 5860, avg. loss 13.88, avg. ppl 5.60 cum. examples 1920, speed 7090.31 words/sec, time elapsed 238.72 sec\n",
            "epoch 22 (158 / 272), iter 5870, avg. loss 15.02, avg. ppl 6.32 cum. examples 2240, speed 6558.87 words/sec, time elapsed 239.12 sec\n",
            "epoch 22 (168 / 272), iter 5880, avg. loss 14.47, avg. ppl 5.95 cum. examples 2560, speed 5807.17 words/sec, time elapsed 239.57 sec\n",
            "epoch 22 (178 / 272), iter 5890, avg. loss 14.73, avg. ppl 6.15 cum. examples 2880, speed 6531.17 words/sec, time elapsed 239.97 sec\n",
            "epoch 22 (188 / 272), iter 5900, avg. loss 13.98, avg. ppl 5.70 cum. examples 3200, speed 7044.53 words/sec, time elapsed 240.33 sec\n",
            "epoch 22, iter 5900, cum. loss 14.24, cum. ppl 5.86 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 5900, dev. ppl 7.145183\n",
            "epoch 22, iter 5900: save currently the best model to [model.bin]\n",
            "epoch 22 (198 / 272), iter 5910, avg. loss 15.19, avg. ppl 6.47 cum. examples 320, speed 4639.13 words/sec, time elapsed 240.89 sec\n",
            "epoch 22 (208 / 272), iter 5920, avg. loss 14.85, avg. ppl 6.18 cum. examples 640, speed 6003.08 words/sec, time elapsed 241.33 sec\n",
            "epoch 22 (218 / 272), iter 5930, avg. loss 13.97, avg. ppl 5.69 cum. examples 960, speed 5782.49 words/sec, time elapsed 241.77 sec\n",
            "epoch 22 (228 / 272), iter 5940, avg. loss 14.06, avg. ppl 5.75 cum. examples 1280, speed 7169.58 words/sec, time elapsed 242.13 sec\n",
            "epoch 22 (238 / 272), iter 5950, avg. loss 14.11, avg. ppl 5.89 cum. examples 1600, speed 6747.88 words/sec, time elapsed 242.51 sec\n",
            "epoch 22 (248 / 272), iter 5960, avg. loss 13.26, avg. ppl 5.33 cum. examples 1920, speed 6226.69 words/sec, time elapsed 242.92 sec\n",
            "epoch 22 (258 / 272), iter 5970, avg. loss 15.01, avg. ppl 6.21 cum. examples 2240, speed 7130.38 words/sec, time elapsed 243.28 sec\n",
            "epoch 22 (268 / 272), iter 5980, avg. loss 14.85, avg. ppl 6.27 cum. examples 2560, speed 7006.17 words/sec, time elapsed 243.65 sec\n",
            "epoch 23 (6 / 272), iter 5990, avg. loss 14.71, avg. ppl 5.93 cum. examples 2877, speed 6676.21 words/sec, time elapsed 244.05 sec\n",
            "epoch 23 (16 / 272), iter 6000, avg. loss 14.67, avg. ppl 5.82 cum. examples 3197, speed 7032.43 words/sec, time elapsed 244.43 sec\n",
            "epoch 23, iter 6000, cum. loss 14.47, cum. ppl 5.95 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 6000, dev. ppl 7.036855\n",
            "epoch 23, iter 6000: save currently the best model to [model.bin]\n",
            "epoch 23 (26 / 272), iter 6010, avg. loss 14.28, avg. ppl 5.80 cum. examples 320, speed 4888.59 words/sec, time elapsed 244.96 sec\n",
            "epoch 23 (36 / 272), iter 6020, avg. loss 13.08, avg. ppl 5.10 cum. examples 640, speed 7019.31 words/sec, time elapsed 245.32 sec\n",
            "epoch 23 (46 / 272), iter 6030, avg. loss 14.67, avg. ppl 6.09 cum. examples 960, speed 6866.38 words/sec, time elapsed 245.70 sec\n",
            "epoch 23 (56 / 272), iter 6040, avg. loss 13.09, avg. ppl 5.20 cum. examples 1280, speed 6818.27 words/sec, time elapsed 246.08 sec\n",
            "epoch 23 (66 / 272), iter 6050, avg. loss 13.95, avg. ppl 5.54 cum. examples 1600, speed 6791.53 words/sec, time elapsed 246.46 sec\n",
            "epoch 23 (76 / 272), iter 6060, avg. loss 13.70, avg. ppl 5.38 cum. examples 1920, speed 6612.42 words/sec, time elapsed 246.85 sec\n",
            "epoch 23 (86 / 272), iter 6070, avg. loss 13.66, avg. ppl 5.47 cum. examples 2240, speed 6372.09 words/sec, time elapsed 247.26 sec\n",
            "epoch 23 (96 / 272), iter 6080, avg. loss 14.08, avg. ppl 5.73 cum. examples 2560, speed 6199.53 words/sec, time elapsed 247.67 sec\n",
            "epoch 23 (106 / 272), iter 6090, avg. loss 14.01, avg. ppl 5.68 cum. examples 2880, speed 6136.96 words/sec, time elapsed 248.10 sec\n",
            "epoch 23 (116 / 272), iter 6100, avg. loss 14.76, avg. ppl 6.08 cum. examples 3200, speed 5909.15 words/sec, time elapsed 248.54 sec\n",
            "epoch 23, iter 6100, cum. loss 13.93, cum. ppl 5.60 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 6100, dev. ppl 7.084336\n",
            "hit patience 1\n",
            "epoch 23 (126 / 272), iter 6110, avg. loss 13.04, avg. ppl 5.21 cum. examples 320, speed 4829.79 words/sec, time elapsed 249.06 sec\n",
            "epoch 23 (136 / 272), iter 6120, avg. loss 14.17, avg. ppl 5.72 cum. examples 640, speed 6876.62 words/sec, time elapsed 249.44 sec\n",
            "epoch 23 (146 / 272), iter 6130, avg. loss 13.13, avg. ppl 5.14 cum. examples 960, speed 6749.07 words/sec, time elapsed 249.82 sec\n",
            "epoch 23 (156 / 272), iter 6140, avg. loss 14.86, avg. ppl 6.13 cum. examples 1280, speed 5848.83 words/sec, time elapsed 250.27 sec\n",
            "epoch 23 (166 / 272), iter 6150, avg. loss 13.17, avg. ppl 5.11 cum. examples 1600, speed 6719.32 words/sec, time elapsed 250.65 sec\n",
            "epoch 23 (176 / 272), iter 6160, avg. loss 14.41, avg. ppl 5.98 cum. examples 1920, speed 6685.94 words/sec, time elapsed 251.04 sec\n",
            "epoch 23 (186 / 272), iter 6170, avg. loss 15.37, avg. ppl 6.46 cum. examples 2240, speed 7009.80 words/sec, time elapsed 251.42 sec\n",
            "epoch 23 (196 / 272), iter 6180, avg. loss 14.22, avg. ppl 5.95 cum. examples 2560, speed 6120.52 words/sec, time elapsed 251.83 sec\n",
            "epoch 23 (206 / 272), iter 6190, avg. loss 14.16, avg. ppl 5.83 cum. examples 2880, speed 6538.54 words/sec, time elapsed 252.23 sec\n",
            "epoch 23 (216 / 272), iter 6200, avg. loss 14.86, avg. ppl 6.30 cum. examples 3200, speed 6973.54 words/sec, time elapsed 252.60 sec\n",
            "epoch 23, iter 6200, cum. loss 14.14, cum. ppl 5.77 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 6200, dev. ppl 7.055617\n",
            "hit patience 2\n",
            "epoch 23 (226 / 272), iter 6210, avg. loss 13.15, avg. ppl 5.18 cum. examples 320, speed 4933.89 words/sec, time elapsed 253.12 sec\n",
            "epoch 23 (236 / 272), iter 6220, avg. loss 14.49, avg. ppl 5.95 cum. examples 640, speed 7126.90 words/sec, time elapsed 253.48 sec\n",
            "epoch 23 (246 / 272), iter 6230, avg. loss 13.35, avg. ppl 5.46 cum. examples 960, speed 6565.60 words/sec, time elapsed 253.86 sec\n",
            "epoch 23 (256 / 272), iter 6240, avg. loss 14.20, avg. ppl 5.77 cum. examples 1280, speed 6818.33 words/sec, time elapsed 254.24 sec\n",
            "epoch 23 (266 / 272), iter 6250, avg. loss 13.71, avg. ppl 5.63 cum. examples 1600, speed 6990.03 words/sec, time elapsed 254.61 sec\n",
            "epoch 24 (4 / 272), iter 6260, avg. loss 13.43, avg. ppl 5.37 cum. examples 1917, speed 6604.43 words/sec, time elapsed 254.99 sec\n",
            "epoch 24 (14 / 272), iter 6270, avg. loss 13.24, avg. ppl 5.19 cum. examples 2237, speed 5749.98 words/sec, time elapsed 255.44 sec\n",
            "epoch 24 (24 / 272), iter 6280, avg. loss 13.02, avg. ppl 5.16 cum. examples 2557, speed 6334.04 words/sec, time elapsed 255.84 sec\n",
            "epoch 24 (34 / 272), iter 6290, avg. loss 14.32, avg. ppl 5.86 cum. examples 2877, speed 7135.62 words/sec, time elapsed 256.20 sec\n",
            "epoch 24 (44 / 272), iter 6300, avg. loss 13.90, avg. ppl 5.58 cum. examples 3197, speed 7194.79 words/sec, time elapsed 256.56 sec\n",
            "epoch 24, iter 6300, cum. loss 13.68, cum. ppl 5.51 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 6300, dev. ppl 6.951092\n",
            "epoch 24, iter 6300: save currently the best model to [model.bin]\n",
            "epoch 24 (54 / 272), iter 6310, avg. loss 13.06, avg. ppl 5.19 cum. examples 320, speed 5264.02 words/sec, time elapsed 257.05 sec\n",
            "epoch 24 (64 / 272), iter 6320, avg. loss 13.97, avg. ppl 5.62 cum. examples 640, speed 6834.18 words/sec, time elapsed 257.43 sec\n",
            "epoch 24 (74 / 272), iter 6330, avg. loss 14.86, avg. ppl 5.98 cum. examples 960, speed 6858.84 words/sec, time elapsed 257.81 sec\n",
            "epoch 24 (84 / 272), iter 6340, avg. loss 14.09, avg. ppl 5.69 cum. examples 1280, speed 7105.33 words/sec, time elapsed 258.18 sec\n",
            "epoch 24 (94 / 272), iter 6350, avg. loss 13.30, avg. ppl 5.25 cum. examples 1600, speed 7070.55 words/sec, time elapsed 258.54 sec\n",
            "epoch 24 (104 / 272), iter 6360, avg. loss 14.31, avg. ppl 5.98 cum. examples 1920, speed 7007.98 words/sec, time elapsed 258.91 sec\n",
            "epoch 24 (114 / 272), iter 6370, avg. loss 13.41, avg. ppl 5.22 cum. examples 2240, speed 7260.08 words/sec, time elapsed 259.27 sec\n",
            "epoch 24 (124 / 272), iter 6380, avg. loss 13.37, avg. ppl 5.25 cum. examples 2560, speed 7187.85 words/sec, time elapsed 259.62 sec\n",
            "epoch 24 (134 / 272), iter 6390, avg. loss 13.08, avg. ppl 5.15 cum. examples 2880, speed 7207.07 words/sec, time elapsed 259.98 sec\n",
            "epoch 24 (144 / 272), iter 6400, avg. loss 13.03, avg. ppl 5.05 cum. examples 3200, speed 6816.41 words/sec, time elapsed 260.36 sec\n",
            "epoch 24, iter 6400, cum. loss 13.65, cum. ppl 5.43 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 6400, dev. ppl 6.880551\n",
            "epoch 24, iter 6400: save currently the best model to [model.bin]\n",
            "epoch 24 (154 / 272), iter 6410, avg. loss 13.80, avg. ppl 5.39 cum. examples 320, speed 5011.30 words/sec, time elapsed 260.88 sec\n",
            "epoch 24 (164 / 272), iter 6420, avg. loss 13.78, avg. ppl 5.49 cum. examples 640, speed 6718.11 words/sec, time elapsed 261.27 sec\n",
            "epoch 24 (174 / 272), iter 6430, avg. loss 13.30, avg. ppl 5.30 cum. examples 960, speed 6354.55 words/sec, time elapsed 261.67 sec\n",
            "epoch 24 (184 / 272), iter 6440, avg. loss 14.44, avg. ppl 5.85 cum. examples 1280, speed 6121.84 words/sec, time elapsed 262.09 sec\n",
            "epoch 24 (194 / 272), iter 6450, avg. loss 14.47, avg. ppl 5.81 cum. examples 1600, speed 5779.72 words/sec, time elapsed 262.55 sec\n",
            "epoch 24 (204 / 272), iter 6460, avg. loss 13.95, avg. ppl 5.60 cum. examples 1920, speed 6230.90 words/sec, time elapsed 262.97 sec\n",
            "epoch 24 (214 / 272), iter 6470, avg. loss 14.18, avg. ppl 5.71 cum. examples 2240, speed 6935.88 words/sec, time elapsed 263.34 sec\n",
            "epoch 24 (224 / 272), iter 6480, avg. loss 14.16, avg. ppl 5.67 cum. examples 2560, speed 6946.95 words/sec, time elapsed 263.72 sec\n",
            "epoch 24 (234 / 272), iter 6490, avg. loss 13.79, avg. ppl 5.52 cum. examples 2880, speed 7349.41 words/sec, time elapsed 264.07 sec\n",
            "epoch 24 (244 / 272), iter 6500, avg. loss 14.25, avg. ppl 5.78 cum. examples 3200, speed 6768.01 words/sec, time elapsed 264.45 sec\n",
            "epoch 24, iter 6500, cum. loss 14.01, cum. ppl 5.61 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 6500, dev. ppl 6.852176\n",
            "epoch 24, iter 6500: save currently the best model to [model.bin]\n",
            "epoch 24 (254 / 272), iter 6510, avg. loss 14.53, avg. ppl 5.94 cum. examples 320, speed 4882.65 words/sec, time elapsed 264.99 sec\n",
            "epoch 24 (264 / 272), iter 6520, avg. loss 13.04, avg. ppl 5.11 cum. examples 640, speed 6669.17 words/sec, time elapsed 265.37 sec\n",
            "epoch 25 (2 / 272), iter 6530, avg. loss 13.45, avg. ppl 5.43 cum. examples 957, speed 6541.21 words/sec, time elapsed 265.76 sec\n",
            "epoch 25 (12 / 272), iter 6540, avg. loss 12.42, avg. ppl 4.83 cum. examples 1277, speed 6855.15 words/sec, time elapsed 266.13 sec\n",
            "epoch 25 (22 / 272), iter 6550, avg. loss 14.27, avg. ppl 5.69 cum. examples 1597, speed 7167.55 words/sec, time elapsed 266.49 sec\n",
            "epoch 25 (32 / 272), iter 6560, avg. loss 13.47, avg. ppl 5.40 cum. examples 1917, speed 6976.40 words/sec, time elapsed 266.86 sec\n",
            "epoch 25 (42 / 272), iter 6570, avg. loss 13.19, avg. ppl 5.18 cum. examples 2237, speed 7133.58 words/sec, time elapsed 267.22 sec\n",
            "epoch 25 (52 / 272), iter 6580, avg. loss 12.24, avg. ppl 4.68 cum. examples 2557, speed 7042.66 words/sec, time elapsed 267.58 sec\n",
            "epoch 25 (62 / 272), iter 6590, avg. loss 13.91, avg. ppl 5.46 cum. examples 2877, speed 6804.00 words/sec, time elapsed 267.96 sec\n",
            "epoch 25 (72 / 272), iter 6600, avg. loss 13.18, avg. ppl 5.12 cum. examples 3197, speed 6915.93 words/sec, time elapsed 268.34 sec\n",
            "epoch 25, iter 6600, cum. loss 13.37, cum. ppl 5.27 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 6600, dev. ppl 6.780182\n",
            "epoch 25, iter 6600: save currently the best model to [model.bin]\n",
            "epoch 25 (82 / 272), iter 6610, avg. loss 13.04, avg. ppl 5.08 cum. examples 320, speed 4765.96 words/sec, time elapsed 268.88 sec\n",
            "epoch 25 (92 / 272), iter 6620, avg. loss 12.77, avg. ppl 4.90 cum. examples 640, speed 7103.36 words/sec, time elapsed 269.24 sec\n",
            "epoch 25 (102 / 272), iter 6630, avg. loss 13.71, avg. ppl 5.35 cum. examples 960, speed 6942.95 words/sec, time elapsed 269.62 sec\n",
            "epoch 25 (112 / 272), iter 6640, avg. loss 13.68, avg. ppl 5.43 cum. examples 1280, speed 6940.83 words/sec, time elapsed 269.99 sec\n",
            "epoch 25 (122 / 272), iter 6650, avg. loss 13.60, avg. ppl 5.45 cum. examples 1600, speed 6633.47 words/sec, time elapsed 270.38 sec\n",
            "epoch 25 (132 / 272), iter 6660, avg. loss 13.29, avg. ppl 5.25 cum. examples 1920, speed 6738.63 words/sec, time elapsed 270.76 sec\n",
            "epoch 25 (142 / 272), iter 6670, avg. loss 14.44, avg. ppl 5.94 cum. examples 2240, speed 6895.18 words/sec, time elapsed 271.13 sec\n",
            "epoch 25 (152 / 272), iter 6680, avg. loss 13.24, avg. ppl 5.23 cum. examples 2560, speed 6966.03 words/sec, time elapsed 271.50 sec\n",
            "epoch 25 (162 / 272), iter 6690, avg. loss 13.17, avg. ppl 5.16 cum. examples 2880, speed 6236.48 words/sec, time elapsed 271.91 sec\n",
            "epoch 25 (172 / 272), iter 6700, avg. loss 13.29, avg. ppl 5.21 cum. examples 3200, speed 5538.32 words/sec, time elapsed 272.38 sec\n",
            "epoch 25, iter 6700, cum. loss 13.42, cum. ppl 5.29 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 6700, dev. ppl 6.726309\n",
            "epoch 25, iter 6700: save currently the best model to [model.bin]\n",
            "epoch 25 (182 / 272), iter 6710, avg. loss 13.49, avg. ppl 5.24 cum. examples 320, speed 4721.80 words/sec, time elapsed 272.93 sec\n",
            "epoch 25 (192 / 272), iter 6720, avg. loss 13.52, avg. ppl 5.20 cum. examples 640, speed 7338.11 words/sec, time elapsed 273.29 sec\n",
            "epoch 25 (202 / 272), iter 6730, avg. loss 13.60, avg. ppl 5.31 cum. examples 960, speed 7237.40 words/sec, time elapsed 273.65 sec\n",
            "epoch 25 (212 / 272), iter 6740, avg. loss 13.41, avg. ppl 5.31 cum. examples 1280, speed 6812.17 words/sec, time elapsed 274.03 sec\n",
            "epoch 25 (222 / 272), iter 6750, avg. loss 14.45, avg. ppl 5.81 cum. examples 1600, speed 6888.86 words/sec, time elapsed 274.41 sec\n",
            "epoch 25 (232 / 272), iter 6760, avg. loss 13.99, avg. ppl 5.66 cum. examples 1920, speed 7012.40 words/sec, time elapsed 274.78 sec\n",
            "epoch 25 (242 / 272), iter 6770, avg. loss 14.10, avg. ppl 5.56 cum. examples 2240, speed 7252.54 words/sec, time elapsed 275.14 sec\n",
            "epoch 25 (252 / 272), iter 6780, avg. loss 13.98, avg. ppl 5.58 cum. examples 2560, speed 6961.44 words/sec, time elapsed 275.51 sec\n",
            "epoch 25 (262 / 272), iter 6790, avg. loss 12.98, avg. ppl 5.16 cum. examples 2880, speed 6492.22 words/sec, time elapsed 275.90 sec\n",
            "epoch 25 (272 / 272), iter 6800, avg. loss 14.27, avg. ppl 5.68 cum. examples 3197, speed 6845.39 words/sec, time elapsed 276.28 sec\n",
            "epoch 25, iter 6800, cum. loss 13.78, cum. ppl 5.45 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 6800, dev. ppl 6.664145\n",
            "epoch 25, iter 6800: save currently the best model to [model.bin]\n",
            "epoch 26 (10 / 272), iter 6810, avg. loss 12.69, avg. ppl 4.77 cum. examples 320, speed 4884.93 words/sec, time elapsed 276.82 sec\n",
            "epoch 26 (20 / 272), iter 6820, avg. loss 12.00, avg. ppl 4.54 cum. examples 640, speed 5973.41 words/sec, time elapsed 277.24 sec\n",
            "epoch 26 (30 / 272), iter 6830, avg. loss 12.38, avg. ppl 4.73 cum. examples 960, speed 5918.72 words/sec, time elapsed 277.67 sec\n",
            "epoch 26 (40 / 272), iter 6840, avg. loss 12.97, avg. ppl 4.98 cum. examples 1280, speed 6897.97 words/sec, time elapsed 278.05 sec\n",
            "epoch 26 (50 / 272), iter 6850, avg. loss 13.98, avg. ppl 5.41 cum. examples 1600, speed 7007.41 words/sec, time elapsed 278.42 sec\n",
            "epoch 26 (60 / 272), iter 6860, avg. loss 13.69, avg. ppl 5.27 cum. examples 1920, speed 6738.84 words/sec, time elapsed 278.82 sec\n",
            "epoch 26 (70 / 272), iter 6870, avg. loss 14.01, avg. ppl 5.59 cum. examples 2240, speed 6955.17 words/sec, time elapsed 279.19 sec\n",
            "epoch 26 (80 / 272), iter 6880, avg. loss 13.76, avg. ppl 5.45 cum. examples 2560, speed 5651.53 words/sec, time elapsed 279.65 sec\n",
            "epoch 26 (90 / 272), iter 6890, avg. loss 13.48, avg. ppl 5.30 cum. examples 2880, speed 6651.15 words/sec, time elapsed 280.04 sec\n",
            "epoch 26 (100 / 272), iter 6900, avg. loss 13.18, avg. ppl 5.08 cum. examples 3200, speed 6637.89 words/sec, time elapsed 280.43 sec\n",
            "epoch 26, iter 6900, cum. loss 13.21, cum. ppl 5.10 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 6900, dev. ppl 6.608798\n",
            "epoch 26, iter 6900: save currently the best model to [model.bin]\n",
            "epoch 26 (110 / 272), iter 6910, avg. loss 13.23, avg. ppl 5.07 cum. examples 320, speed 4996.73 words/sec, time elapsed 280.95 sec\n",
            "epoch 26 (120 / 272), iter 6920, avg. loss 13.05, avg. ppl 5.21 cum. examples 640, speed 7035.64 words/sec, time elapsed 281.31 sec\n",
            "epoch 26 (130 / 272), iter 6930, avg. loss 12.16, avg. ppl 4.61 cum. examples 960, speed 6922.11 words/sec, time elapsed 281.68 sec\n",
            "epoch 26 (140 / 272), iter 6940, avg. loss 13.03, avg. ppl 5.01 cum. examples 1280, speed 6719.13 words/sec, time elapsed 282.07 sec\n",
            "epoch 26 (150 / 272), iter 6950, avg. loss 13.38, avg. ppl 5.28 cum. examples 1600, speed 7019.57 words/sec, time elapsed 282.43 sec\n",
            "epoch 26 (160 / 272), iter 6960, avg. loss 13.50, avg. ppl 5.31 cum. examples 1920, speed 6355.42 words/sec, time elapsed 282.84 sec\n",
            "epoch 26 (170 / 272), iter 6970, avg. loss 12.93, avg. ppl 4.94 cum. examples 2240, speed 6973.35 words/sec, time elapsed 283.21 sec\n",
            "epoch 26 (180 / 272), iter 6980, avg. loss 12.56, avg. ppl 4.82 cum. examples 2560, speed 7292.99 words/sec, time elapsed 283.56 sec\n",
            "epoch 26 (190 / 272), iter 6990, avg. loss 13.47, avg. ppl 5.31 cum. examples 2880, speed 6211.48 words/sec, time elapsed 283.98 sec\n",
            "epoch 26 (200 / 272), iter 7000, avg. loss 13.84, avg. ppl 5.47 cum. examples 3200, speed 7011.07 words/sec, time elapsed 284.35 sec\n",
            "epoch 26, iter 7000, cum. loss 13.11, cum. ppl 5.10 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 7000, dev. ppl 6.540307\n",
            "epoch 26, iter 7000: save currently the best model to [model.bin]\n",
            "epoch 26 (210 / 272), iter 7010, avg. loss 13.55, avg. ppl 5.38 cum. examples 320, speed 4956.83 words/sec, time elapsed 284.87 sec\n",
            "epoch 26 (220 / 272), iter 7020, avg. loss 13.94, avg. ppl 5.53 cum. examples 640, speed 6794.43 words/sec, time elapsed 285.25 sec\n",
            "epoch 26 (230 / 272), iter 7030, avg. loss 13.31, avg. ppl 5.17 cum. examples 960, speed 6995.28 words/sec, time elapsed 285.62 sec\n",
            "epoch 26 (240 / 272), iter 7040, avg. loss 14.14, avg. ppl 5.49 cum. examples 1280, speed 6995.92 words/sec, time elapsed 286.00 sec\n",
            "epoch 26 (250 / 272), iter 7050, avg. loss 13.90, avg. ppl 5.56 cum. examples 1600, speed 6931.19 words/sec, time elapsed 286.38 sec\n",
            "epoch 26 (260 / 272), iter 7060, avg. loss 12.53, avg. ppl 4.86 cum. examples 1920, speed 6604.35 words/sec, time elapsed 286.76 sec\n",
            "epoch 26 (270 / 272), iter 7070, avg. loss 12.20, avg. ppl 4.63 cum. examples 2240, speed 6806.16 words/sec, time elapsed 287.14 sec\n",
            "epoch 27 (8 / 272), iter 7080, avg. loss 11.82, avg. ppl 4.55 cum. examples 2557, speed 6764.13 words/sec, time elapsed 287.50 sec\n",
            "epoch 27 (18 / 272), iter 7090, avg. loss 11.29, avg. ppl 4.22 cum. examples 2877, speed 6525.93 words/sec, time elapsed 287.89 sec\n",
            "epoch 27 (28 / 272), iter 7100, avg. loss 13.58, avg. ppl 5.21 cum. examples 3197, speed 7149.67 words/sec, time elapsed 288.26 sec\n",
            "epoch 27, iter 7100, cum. loss 13.03, cum. ppl 5.05 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 7100, dev. ppl 6.529268\n",
            "epoch 27, iter 7100: save currently the best model to [model.bin]\n",
            "epoch 27 (38 / 272), iter 7110, avg. loss 12.60, avg. ppl 4.75 cum. examples 320, speed 4835.63 words/sec, time elapsed 288.79 sec\n",
            "epoch 27 (48 / 272), iter 7120, avg. loss 12.73, avg. ppl 4.83 cum. examples 640, speed 6819.09 words/sec, time elapsed 289.17 sec\n",
            "epoch 27 (58 / 272), iter 7130, avg. loss 14.06, avg. ppl 5.46 cum. examples 960, speed 7127.41 words/sec, time elapsed 289.54 sec\n",
            "epoch 27 (68 / 272), iter 7140, avg. loss 13.04, avg. ppl 4.96 cum. examples 1280, speed 6045.31 words/sec, time elapsed 289.98 sec\n",
            "epoch 27 (78 / 272), iter 7150, avg. loss 13.39, avg. ppl 5.29 cum. examples 1600, speed 6947.51 words/sec, time elapsed 290.35 sec\n",
            "epoch 27 (88 / 272), iter 7160, avg. loss 13.38, avg. ppl 5.28 cum. examples 1920, speed 6466.36 words/sec, time elapsed 290.75 sec\n",
            "epoch 27 (98 / 272), iter 7170, avg. loss 14.18, avg. ppl 5.46 cum. examples 2240, speed 6774.64 words/sec, time elapsed 291.14 sec\n",
            "epoch 27 (108 / 272), iter 7180, avg. loss 13.86, avg. ppl 5.48 cum. examples 2560, speed 7251.08 words/sec, time elapsed 291.50 sec\n",
            "epoch 27 (118 / 272), iter 7190, avg. loss 12.30, avg. ppl 4.71 cum. examples 2880, speed 6041.99 words/sec, time elapsed 291.92 sec\n",
            "epoch 27 (128 / 272), iter 7200, avg. loss 12.95, avg. ppl 5.00 cum. examples 3200, speed 7229.71 words/sec, time elapsed 292.28 sec\n",
            "epoch 27, iter 7200, cum. loss 13.25, cum. ppl 5.12 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 7200, dev. ppl 6.424477\n",
            "epoch 27, iter 7200: save currently the best model to [model.bin]\n",
            "epoch 27 (138 / 272), iter 7210, avg. loss 13.15, avg. ppl 5.08 cum. examples 320, speed 4849.93 words/sec, time elapsed 292.81 sec\n",
            "epoch 27 (148 / 272), iter 7220, avg. loss 11.88, avg. ppl 4.41 cum. examples 640, speed 5617.93 words/sec, time elapsed 293.27 sec\n",
            "epoch 27 (158 / 272), iter 7230, avg. loss 13.13, avg. ppl 5.06 cum. examples 960, speed 6163.33 words/sec, time elapsed 293.69 sec\n",
            "epoch 27 (168 / 272), iter 7240, avg. loss 12.84, avg. ppl 4.91 cum. examples 1280, speed 6597.39 words/sec, time elapsed 294.08 sec\n",
            "epoch 27 (178 / 272), iter 7250, avg. loss 12.75, avg. ppl 4.92 cum. examples 1600, speed 7009.01 words/sec, time elapsed 294.45 sec\n",
            "epoch 27 (188 / 272), iter 7260, avg. loss 14.04, avg. ppl 5.49 cum. examples 1920, speed 6927.59 words/sec, time elapsed 294.83 sec\n",
            "epoch 27 (198 / 272), iter 7270, avg. loss 11.54, avg. ppl 4.38 cum. examples 2240, speed 5657.78 words/sec, time elapsed 295.27 sec\n",
            "epoch 27 (208 / 272), iter 7280, avg. loss 13.83, avg. ppl 5.45 cum. examples 2560, speed 6380.14 words/sec, time elapsed 295.68 sec\n",
            "epoch 27 (218 / 272), iter 7290, avg. loss 12.45, avg. ppl 4.73 cum. examples 2880, speed 6446.60 words/sec, time elapsed 296.08 sec\n",
            "epoch 27 (228 / 272), iter 7300, avg. loss 12.87, avg. ppl 5.01 cum. examples 3200, speed 6961.51 words/sec, time elapsed 296.45 sec\n",
            "epoch 27, iter 7300, cum. loss 12.85, cum. ppl 4.93 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 7300, dev. ppl 6.384385\n",
            "epoch 27, iter 7300: save currently the best model to [model.bin]\n",
            "epoch 27 (238 / 272), iter 7310, avg. loss 14.02, avg. ppl 5.45 cum. examples 320, speed 4973.65 words/sec, time elapsed 296.98 sec\n",
            "epoch 27 (248 / 272), iter 7320, avg. loss 12.23, avg. ppl 4.53 cum. examples 640, speed 6816.99 words/sec, time elapsed 297.36 sec\n",
            "epoch 27 (258 / 272), iter 7330, avg. loss 12.28, avg. ppl 4.67 cum. examples 960, speed 6919.26 words/sec, time elapsed 297.73 sec\n",
            "epoch 27 (268 / 272), iter 7340, avg. loss 13.58, avg. ppl 5.31 cum. examples 1280, speed 6859.06 words/sec, time elapsed 298.11 sec\n",
            "epoch 28 (6 / 272), iter 7350, avg. loss 12.50, avg. ppl 4.75 cum. examples 1597, speed 6570.99 words/sec, time elapsed 298.50 sec\n",
            "epoch 28 (16 / 272), iter 7360, avg. loss 12.50, avg. ppl 4.63 cum. examples 1917, speed 6582.61 words/sec, time elapsed 298.89 sec\n",
            "epoch 28 (26 / 272), iter 7370, avg. loss 12.38, avg. ppl 4.77 cum. examples 2237, speed 5718.33 words/sec, time elapsed 299.34 sec\n",
            "epoch 28 (36 / 272), iter 7380, avg. loss 12.03, avg. ppl 4.49 cum. examples 2557, speed 6685.69 words/sec, time elapsed 299.72 sec\n",
            "epoch 28 (46 / 272), iter 7390, avg. loss 12.34, avg. ppl 4.58 cum. examples 2877, speed 6697.53 words/sec, time elapsed 300.11 sec\n",
            "epoch 28 (56 / 272), iter 7400, avg. loss 12.89, avg. ppl 4.88 cum. examples 3197, speed 6756.04 words/sec, time elapsed 300.49 sec\n",
            "epoch 28, iter 7400, cum. loss 12.67, cum. ppl 4.80 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 7400, dev. ppl 6.339558\n",
            "epoch 28, iter 7400: save currently the best model to [model.bin]\n",
            "epoch 28 (66 / 272), iter 7410, avg. loss 12.29, avg. ppl 4.70 cum. examples 320, speed 4962.82 words/sec, time elapsed 301.01 sec\n",
            "epoch 28 (76 / 272), iter 7420, avg. loss 13.47, avg. ppl 5.12 cum. examples 640, speed 6767.41 words/sec, time elapsed 301.40 sec\n",
            "epoch 28 (86 / 272), iter 7430, avg. loss 12.63, avg. ppl 4.79 cum. examples 960, speed 6481.68 words/sec, time elapsed 301.80 sec\n",
            "epoch 28 (96 / 272), iter 7440, avg. loss 13.17, avg. ppl 5.09 cum. examples 1280, speed 6418.44 words/sec, time elapsed 302.20 sec\n",
            "epoch 28 (106 / 272), iter 7450, avg. loss 12.61, avg. ppl 4.76 cum. examples 1600, speed 6725.97 words/sec, time elapsed 302.58 sec\n",
            "epoch 28 (116 / 272), iter 7460, avg. loss 12.96, avg. ppl 4.97 cum. examples 1920, speed 6698.13 words/sec, time elapsed 302.97 sec\n",
            "epoch 28 (126 / 272), iter 7470, avg. loss 12.93, avg. ppl 4.93 cum. examples 2240, speed 6406.94 words/sec, time elapsed 303.38 sec\n",
            "epoch 28 (136 / 272), iter 7480, avg. loss 11.68, avg. ppl 4.42 cum. examples 2560, speed 7211.54 words/sec, time elapsed 303.72 sec\n",
            "epoch 28 (146 / 272), iter 7490, avg. loss 13.20, avg. ppl 5.11 cum. examples 2880, speed 7009.83 words/sec, time elapsed 304.09 sec\n",
            "epoch 28 (156 / 272), iter 7500, avg. loss 12.78, avg. ppl 4.78 cum. examples 3200, speed 7037.84 words/sec, time elapsed 304.47 sec\n",
            "epoch 28, iter 7500, cum. loss 12.77, cum. ppl 4.86 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 7500, dev. ppl 6.396517\n",
            "hit patience 1\n",
            "epoch 28 (166 / 272), iter 7510, avg. loss 12.80, avg. ppl 4.88 cum. examples 320, speed 5060.24 words/sec, time elapsed 304.98 sec\n",
            "epoch 28 (176 / 272), iter 7520, avg. loss 12.48, avg. ppl 4.68 cum. examples 640, speed 6850.03 words/sec, time elapsed 305.36 sec\n",
            "epoch 28 (186 / 272), iter 7530, avg. loss 12.16, avg. ppl 4.60 cum. examples 960, speed 7077.20 words/sec, time elapsed 305.72 sec\n",
            "epoch 28 (196 / 272), iter 7540, avg. loss 13.74, avg. ppl 5.12 cum. examples 1280, speed 5959.32 words/sec, time elapsed 306.17 sec\n",
            "epoch 28 (206 / 272), iter 7550, avg. loss 13.57, avg. ppl 5.22 cum. examples 1600, speed 5602.13 words/sec, time elapsed 306.64 sec\n",
            "epoch 28 (216 / 272), iter 7560, avg. loss 13.32, avg. ppl 5.15 cum. examples 1920, speed 6830.00 words/sec, time elapsed 307.02 sec\n",
            "epoch 28 (226 / 272), iter 7570, avg. loss 12.71, avg. ppl 4.81 cum. examples 2240, speed 6457.45 words/sec, time elapsed 307.42 sec\n",
            "epoch 28 (236 / 272), iter 7580, avg. loss 13.10, avg. ppl 4.98 cum. examples 2560, speed 6597.98 words/sec, time elapsed 307.82 sec\n",
            "epoch 28 (246 / 272), iter 7590, avg. loss 12.15, avg. ppl 4.65 cum. examples 2880, speed 6791.36 words/sec, time elapsed 308.19 sec\n",
            "epoch 28 (256 / 272), iter 7600, avg. loss 11.76, avg. ppl 4.39 cum. examples 3200, speed 6774.36 words/sec, time elapsed 308.57 sec\n",
            "epoch 28, iter 7600, cum. loss 12.78, cum. ppl 4.85 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 7600, dev. ppl 6.329166\n",
            "epoch 28, iter 7600: save currently the best model to [model.bin]\n",
            "epoch 28 (266 / 272), iter 7610, avg. loss 13.54, avg. ppl 5.26 cum. examples 320, speed 4970.40 words/sec, time elapsed 309.09 sec\n",
            "epoch 29 (4 / 272), iter 7620, avg. loss 11.69, avg. ppl 4.32 cum. examples 637, speed 6735.69 words/sec, time elapsed 309.47 sec\n",
            "epoch 29 (14 / 272), iter 7630, avg. loss 12.29, avg. ppl 4.57 cum. examples 957, speed 6606.78 words/sec, time elapsed 309.86 sec\n",
            "epoch 29 (24 / 272), iter 7640, avg. loss 11.99, avg. ppl 4.46 cum. examples 1277, speed 6707.75 words/sec, time elapsed 310.24 sec\n",
            "epoch 29 (34 / 272), iter 7650, avg. loss 12.37, avg. ppl 4.65 cum. examples 1597, speed 6725.26 words/sec, time elapsed 310.63 sec\n",
            "epoch 29 (44 / 272), iter 7660, avg. loss 12.73, avg. ppl 4.75 cum. examples 1917, speed 7058.96 words/sec, time elapsed 311.00 sec\n",
            "epoch 29 (54 / 272), iter 7670, avg. loss 12.47, avg. ppl 4.71 cum. examples 2237, speed 6939.49 words/sec, time elapsed 311.37 sec\n",
            "epoch 29 (64 / 272), iter 7680, avg. loss 12.66, avg. ppl 4.78 cum. examples 2557, speed 6918.55 words/sec, time elapsed 311.74 sec\n",
            "epoch 29 (74 / 272), iter 7690, avg. loss 12.55, avg. ppl 4.71 cum. examples 2877, speed 6803.89 words/sec, time elapsed 312.12 sec\n",
            "epoch 29 (84 / 272), iter 7700, avg. loss 11.42, avg. ppl 4.24 cum. examples 3197, speed 6897.12 words/sec, time elapsed 312.49 sec\n",
            "epoch 29, iter 7700, cum. loss 12.37, cum. ppl 4.64 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 7700, dev. ppl 6.343553\n",
            "hit patience 1\n",
            "epoch 29 (94 / 272), iter 7710, avg. loss 12.81, avg. ppl 4.87 cum. examples 320, speed 5268.79 words/sec, time elapsed 312.98 sec\n",
            "epoch 29 (104 / 272), iter 7720, avg. loss 12.43, avg. ppl 4.78 cum. examples 640, speed 6599.73 words/sec, time elapsed 313.37 sec\n",
            "epoch 29 (114 / 272), iter 7730, avg. loss 11.38, avg. ppl 4.21 cum. examples 960, speed 6445.43 words/sec, time elapsed 313.76 sec\n",
            "epoch 29 (124 / 272), iter 7740, avg. loss 12.45, avg. ppl 4.69 cum. examples 1280, speed 6314.88 words/sec, time elapsed 314.17 sec\n",
            "epoch 29 (134 / 272), iter 7750, avg. loss 12.11, avg. ppl 4.59 cum. examples 1600, speed 6765.72 words/sec, time elapsed 314.55 sec\n",
            "epoch 29 (144 / 272), iter 7760, avg. loss 13.12, avg. ppl 4.98 cum. examples 1920, speed 6060.02 words/sec, time elapsed 314.98 sec\n",
            "epoch 29 (154 / 272), iter 7770, avg. loss 12.39, avg. ppl 4.72 cum. examples 2240, speed 6818.36 words/sec, time elapsed 315.35 sec\n",
            "epoch 29 (164 / 272), iter 7780, avg. loss 12.94, avg. ppl 4.83 cum. examples 2560, speed 6649.46 words/sec, time elapsed 315.75 sec\n",
            "epoch 29 (174 / 272), iter 7790, avg. loss 11.93, avg. ppl 4.37 cum. examples 2880, speed 5823.46 words/sec, time elapsed 316.19 sec\n",
            "epoch 29 (184 / 272), iter 7800, avg. loss 12.10, avg. ppl 4.53 cum. examples 3200, speed 5751.39 words/sec, time elapsed 316.64 sec\n",
            "epoch 29, iter 7800, cum. loss 12.36, cum. ppl 4.65 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 7800, dev. ppl 6.353106\n",
            "hit patience 2\n",
            "epoch 29 (194 / 272), iter 7810, avg. loss 12.34, avg. ppl 4.66 cum. examples 320, speed 5156.02 words/sec, time elapsed 317.14 sec\n",
            "epoch 29 (204 / 272), iter 7820, avg. loss 13.18, avg. ppl 5.01 cum. examples 640, speed 6583.06 words/sec, time elapsed 317.53 sec\n",
            "epoch 29 (214 / 272), iter 7830, avg. loss 12.49, avg. ppl 4.68 cum. examples 960, speed 6969.14 words/sec, time elapsed 317.91 sec\n",
            "epoch 29 (224 / 272), iter 7840, avg. loss 12.54, avg. ppl 4.79 cum. examples 1280, speed 6845.55 words/sec, time elapsed 318.28 sec\n",
            "epoch 29 (234 / 272), iter 7850, avg. loss 12.29, avg. ppl 4.61 cum. examples 1600, speed 5462.09 words/sec, time elapsed 318.75 sec\n",
            "epoch 29 (244 / 272), iter 7860, avg. loss 13.27, avg. ppl 4.98 cum. examples 1920, speed 6692.08 words/sec, time elapsed 319.15 sec\n",
            "epoch 29 (254 / 272), iter 7870, avg. loss 13.35, avg. ppl 5.10 cum. examples 2240, speed 6689.42 words/sec, time elapsed 319.54 sec\n",
            "epoch 29 (264 / 272), iter 7880, avg. loss 13.07, avg. ppl 4.86 cum. examples 2560, speed 6530.35 words/sec, time elapsed 319.94 sec\n",
            "epoch 30 (2 / 272), iter 7890, avg. loss 12.41, avg. ppl 4.64 cum. examples 2877, speed 6662.56 words/sec, time elapsed 320.33 sec\n",
            "epoch 30 (12 / 272), iter 7900, avg. loss 11.52, avg. ppl 4.20 cum. examples 3197, speed 6526.60 words/sec, time elapsed 320.72 sec\n",
            "epoch 30, iter 7900, cum. loss 12.65, cum. ppl 4.75 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 7900, dev. ppl 6.211786\n",
            "epoch 30, iter 7900: save currently the best model to [model.bin]\n",
            "epoch 30 (22 / 272), iter 7910, avg. loss 11.35, avg. ppl 4.14 cum. examples 320, speed 4921.23 words/sec, time elapsed 321.24 sec\n",
            "epoch 30 (32 / 272), iter 7920, avg. loss 11.83, avg. ppl 4.34 cum. examples 640, speed 6503.86 words/sec, time elapsed 321.64 sec\n",
            "epoch 30 (42 / 272), iter 7930, avg. loss 12.49, avg. ppl 4.58 cum. examples 960, speed 6787.77 words/sec, time elapsed 322.03 sec\n",
            "epoch 30 (52 / 272), iter 7940, avg. loss 11.48, avg. ppl 4.24 cum. examples 1280, speed 6814.85 words/sec, time elapsed 322.40 sec\n",
            "epoch 30 (62 / 272), iter 7950, avg. loss 12.01, avg. ppl 4.49 cum. examples 1600, speed 6484.44 words/sec, time elapsed 322.79 sec\n",
            "epoch 30 (72 / 272), iter 7960, avg. loss 12.48, avg. ppl 4.72 cum. examples 1920, speed 6866.58 words/sec, time elapsed 323.17 sec\n",
            "epoch 30 (82 / 272), iter 7970, avg. loss 12.08, avg. ppl 4.48 cum. examples 2240, speed 6722.72 words/sec, time elapsed 323.55 sec\n",
            "epoch 30 (92 / 272), iter 7980, avg. loss 11.57, avg. ppl 4.27 cum. examples 2560, speed 6248.41 words/sec, time elapsed 323.96 sec\n",
            "epoch 30 (102 / 272), iter 7990, avg. loss 12.58, avg. ppl 4.80 cum. examples 2880, speed 6603.21 words/sec, time elapsed 324.35 sec\n",
            "epoch 30 (112 / 272), iter 8000, avg. loss 12.02, avg. ppl 4.39 cum. examples 3200, speed 6577.71 words/sec, time elapsed 324.75 sec\n",
            "epoch 30, iter 8000, cum. loss 11.99, cum. ppl 4.44 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 8000, dev. ppl 6.203777\n",
            "epoch 30, iter 8000: save currently the best model to [model.bin]\n",
            "epoch 30 (122 / 272), iter 8010, avg. loss 12.89, avg. ppl 4.79 cum. examples 320, speed 4970.41 words/sec, time elapsed 325.28 sec\n",
            "epoch 30 (132 / 272), iter 8020, avg. loss 11.51, avg. ppl 4.24 cum. examples 640, speed 6811.51 words/sec, time elapsed 325.65 sec\n",
            "epoch 30 (142 / 272), iter 8030, avg. loss 13.03, avg. ppl 4.97 cum. examples 960, speed 6529.01 words/sec, time elapsed 326.05 sec\n",
            "epoch 30 (152 / 272), iter 8040, avg. loss 13.63, avg. ppl 5.16 cum. examples 1280, speed 6740.39 words/sec, time elapsed 326.44 sec\n",
            "epoch 30 (162 / 272), iter 8050, avg. loss 13.10, avg. ppl 4.82 cum. examples 1600, speed 6238.32 words/sec, time elapsed 326.87 sec\n",
            "epoch 30 (172 / 272), iter 8060, avg. loss 12.71, avg. ppl 4.76 cum. examples 1920, speed 6745.18 words/sec, time elapsed 327.26 sec\n",
            "epoch 30 (182 / 272), iter 8070, avg. loss 12.43, avg. ppl 4.58 cum. examples 2240, speed 6627.95 words/sec, time elapsed 327.65 sec\n",
            "epoch 30 (192 / 272), iter 8080, avg. loss 10.78, avg. ppl 3.97 cum. examples 2560, speed 5612.92 words/sec, time elapsed 328.10 sec\n",
            "epoch 30 (202 / 272), iter 8090, avg. loss 11.78, avg. ppl 4.37 cum. examples 2880, speed 6558.77 words/sec, time elapsed 328.49 sec\n",
            "epoch 30 (212 / 272), iter 8100, avg. loss 12.78, avg. ppl 4.70 cum. examples 3200, speed 6426.50 words/sec, time elapsed 328.90 sec\n",
            "epoch 30, iter 8100, cum. loss 12.46, cum. ppl 4.63 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 8100, dev. ppl 6.196064\n",
            "epoch 30, iter 8100: save currently the best model to [model.bin]\n",
            "epoch 30 (222 / 272), iter 8110, avg. loss 12.47, avg. ppl 4.66 cum. examples 320, speed 4835.35 words/sec, time elapsed 329.44 sec\n",
            "epoch 30 (232 / 272), iter 8120, avg. loss 12.72, avg. ppl 4.91 cum. examples 640, speed 6549.02 words/sec, time elapsed 329.83 sec\n",
            "epoch 30 (242 / 272), iter 8130, avg. loss 12.53, avg. ppl 4.73 cum. examples 960, speed 6734.94 words/sec, time elapsed 330.21 sec\n",
            "epoch 30 (252 / 272), iter 8140, avg. loss 12.82, avg. ppl 4.81 cum. examples 1280, speed 5872.25 words/sec, time elapsed 330.66 sec\n",
            "epoch 30 (262 / 272), iter 8150, avg. loss 12.35, avg. ppl 4.54 cum. examples 1600, speed 6419.62 words/sec, time elapsed 331.06 sec\n",
            "epoch 30 (272 / 272), iter 8160, avg. loss 11.71, avg. ppl 4.38 cum. examples 1917, speed 6265.86 words/sec, time elapsed 331.46 sec\n",
            "epoch 31 (10 / 272), iter 8170, avg. loss 11.48, avg. ppl 4.27 cum. examples 2237, speed 5984.44 words/sec, time elapsed 331.89 sec\n",
            "epoch 31 (20 / 272), iter 8180, avg. loss 11.28, avg. ppl 4.12 cum. examples 2557, speed 6365.01 words/sec, time elapsed 332.29 sec\n",
            "epoch 31 (30 / 272), iter 8190, avg. loss 12.14, avg. ppl 4.38 cum. examples 2877, speed 6506.37 words/sec, time elapsed 332.69 sec\n",
            "epoch 31 (40 / 272), iter 8200, avg. loss 11.23, avg. ppl 4.09 cum. examples 3197, speed 6739.66 words/sec, time elapsed 333.07 sec\n",
            "epoch 31, iter 8200, cum. loss 12.07, cum. ppl 4.48 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 8200, dev. ppl 6.183288\n",
            "epoch 31, iter 8200: save currently the best model to [model.bin]\n",
            "epoch 31 (50 / 272), iter 8210, avg. loss 11.45, avg. ppl 4.24 cum. examples 320, speed 4732.04 words/sec, time elapsed 333.61 sec\n",
            "epoch 31 (60 / 272), iter 8220, avg. loss 11.81, avg. ppl 4.42 cum. examples 640, speed 6245.65 words/sec, time elapsed 334.02 sec\n",
            "epoch 31 (70 / 272), iter 8230, avg. loss 11.90, avg. ppl 4.38 cum. examples 960, speed 6645.35 words/sec, time elapsed 334.40 sec\n",
            "epoch 31 (80 / 272), iter 8240, avg. loss 11.74, avg. ppl 4.29 cum. examples 1280, speed 6632.55 words/sec, time elapsed 334.79 sec\n",
            "epoch 31 (90 / 272), iter 8250, avg. loss 12.54, avg. ppl 4.77 cum. examples 1600, speed 6654.92 words/sec, time elapsed 335.18 sec\n",
            "epoch 31 (100 / 272), iter 8260, avg. loss 12.12, avg. ppl 4.52 cum. examples 1920, speed 6547.98 words/sec, time elapsed 335.57 sec\n",
            "epoch 31 (110 / 272), iter 8270, avg. loss 11.52, avg. ppl 4.19 cum. examples 2240, speed 6657.31 words/sec, time elapsed 335.96 sec\n",
            "epoch 31 (120 / 272), iter 8280, avg. loss 12.43, avg. ppl 4.68 cum. examples 2560, speed 6598.57 words/sec, time elapsed 336.35 sec\n",
            "epoch 31 (130 / 272), iter 8290, avg. loss 11.81, avg. ppl 4.26 cum. examples 2880, speed 6669.92 words/sec, time elapsed 336.74 sec\n",
            "epoch 31 (140 / 272), iter 8300, avg. loss 13.06, avg. ppl 4.77 cum. examples 3200, speed 6667.56 words/sec, time elapsed 337.14 sec\n",
            "epoch 31, iter 8300, cum. loss 12.04, cum. ppl 4.45 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 8300, dev. ppl 6.100714\n",
            "epoch 31, iter 8300: save currently the best model to [model.bin]\n",
            "epoch 31 (150 / 272), iter 8310, avg. loss 12.31, avg. ppl 4.53 cum. examples 320, speed 4661.35 words/sec, time elapsed 337.70 sec\n",
            "epoch 31 (160 / 272), iter 8320, avg. loss 12.25, avg. ppl 4.55 cum. examples 640, speed 6579.55 words/sec, time elapsed 338.09 sec\n",
            "epoch 31 (170 / 272), iter 8330, avg. loss 13.04, avg. ppl 4.81 cum. examples 960, speed 6773.36 words/sec, time elapsed 338.49 sec\n",
            "epoch 31 (180 / 272), iter 8340, avg. loss 12.00, avg. ppl 4.41 cum. examples 1280, speed 5647.37 words/sec, time elapsed 338.95 sec\n",
            "epoch 31 (190 / 272), iter 8350, avg. loss 11.33, avg. ppl 4.16 cum. examples 1600, speed 5658.48 words/sec, time elapsed 339.39 sec\n",
            "epoch 31 (200 / 272), iter 8360, avg. loss 12.49, avg. ppl 4.67 cum. examples 1920, speed 6779.99 words/sec, time elapsed 339.78 sec\n",
            "epoch 31 (210 / 272), iter 8370, avg. loss 12.35, avg. ppl 4.63 cum. examples 2240, speed 6453.66 words/sec, time elapsed 340.18 sec\n",
            "epoch 31 (220 / 272), iter 8380, avg. loss 12.73, avg. ppl 4.77 cum. examples 2560, speed 6513.89 words/sec, time elapsed 340.58 sec\n",
            "epoch 31 (230 / 272), iter 8390, avg. loss 11.55, avg. ppl 4.19 cum. examples 2880, speed 6044.00 words/sec, time elapsed 341.01 sec\n",
            "epoch 31 (240 / 272), iter 8400, avg. loss 11.63, avg. ppl 4.29 cum. examples 3200, speed 5698.43 words/sec, time elapsed 341.46 sec\n",
            "epoch 31, iter 8400, cum. loss 12.17, cum. ppl 4.50 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 8400, dev. ppl 6.031060\n",
            "epoch 31, iter 8400: save currently the best model to [model.bin]\n",
            "epoch 31 (250 / 272), iter 8410, avg. loss 13.02, avg. ppl 4.85 cum. examples 320, speed 4891.73 words/sec, time elapsed 342.00 sec\n",
            "epoch 31 (260 / 272), iter 8420, avg. loss 11.26, avg. ppl 4.11 cum. examples 640, speed 6741.92 words/sec, time elapsed 342.37 sec\n",
            "epoch 31 (270 / 272), iter 8430, avg. loss 12.31, avg. ppl 4.52 cum. examples 960, speed 6236.57 words/sec, time elapsed 342.79 sec\n",
            "epoch 32 (8 / 272), iter 8440, avg. loss 12.05, avg. ppl 4.28 cum. examples 1277, speed 6595.53 words/sec, time elapsed 343.19 sec\n",
            "epoch 32 (18 / 272), iter 8450, avg. loss 12.16, avg. ppl 4.39 cum. examples 1597, speed 6784.32 words/sec, time elapsed 343.58 sec\n",
            "epoch 32 (28 / 272), iter 8460, avg. loss 12.50, avg. ppl 4.68 cum. examples 1917, speed 6138.35 words/sec, time elapsed 344.00 sec\n",
            "epoch 32 (38 / 272), iter 8470, avg. loss 11.70, avg. ppl 4.17 cum. examples 2237, speed 6370.26 words/sec, time elapsed 344.41 sec\n",
            "epoch 32 (48 / 272), iter 8480, avg. loss 11.87, avg. ppl 4.34 cum. examples 2557, speed 6591.13 words/sec, time elapsed 344.81 sec\n",
            "epoch 32 (58 / 272), iter 8490, avg. loss 11.48, avg. ppl 4.21 cum. examples 2877, speed 6570.95 words/sec, time elapsed 345.20 sec\n",
            "epoch 32 (68 / 272), iter 8500, avg. loss 12.07, avg. ppl 4.44 cum. examples 3197, speed 6687.47 words/sec, time elapsed 345.58 sec\n",
            "epoch 32, iter 8500, cum. loss 12.04, cum. ppl 4.39 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 8500, dev. ppl 6.030822\n",
            "epoch 32, iter 8500: save currently the best model to [model.bin]\n",
            "epoch 32 (78 / 272), iter 8510, avg. loss 11.75, avg. ppl 4.34 cum. examples 320, speed 4266.55 words/sec, time elapsed 346.18 sec\n",
            "epoch 32 (88 / 272), iter 8520, avg. loss 11.83, avg. ppl 4.26 cum. examples 640, speed 5463.38 words/sec, time elapsed 346.66 sec\n",
            "epoch 32 (98 / 272), iter 8530, avg. loss 12.84, avg. ppl 4.76 cum. examples 960, speed 6260.71 words/sec, time elapsed 347.08 sec\n",
            "epoch 32 (108 / 272), iter 8540, avg. loss 10.74, avg. ppl 3.89 cum. examples 1280, speed 6885.21 words/sec, time elapsed 347.45 sec\n",
            "epoch 32 (118 / 272), iter 8550, avg. loss 11.26, avg. ppl 4.10 cum. examples 1600, speed 6602.71 words/sec, time elapsed 347.84 sec\n",
            "epoch 32 (128 / 272), iter 8560, avg. loss 11.40, avg. ppl 4.17 cum. examples 1920, speed 6358.31 words/sec, time elapsed 348.24 sec\n",
            "epoch 32 (138 / 272), iter 8570, avg. loss 11.29, avg. ppl 4.10 cum. examples 2240, speed 6633.15 words/sec, time elapsed 348.63 sec\n",
            "epoch 32 (148 / 272), iter 8580, avg. loss 10.94, avg. ppl 3.94 cum. examples 2560, speed 5890.11 words/sec, time elapsed 349.06 sec\n",
            "epoch 32 (158 / 272), iter 8590, avg. loss 12.53, avg. ppl 4.66 cum. examples 2880, speed 5442.00 words/sec, time elapsed 349.54 sec\n",
            "epoch 32 (168 / 272), iter 8600, avg. loss 11.40, avg. ppl 4.15 cum. examples 3200, speed 6396.18 words/sec, time elapsed 349.94 sec\n",
            "epoch 32, iter 8600, cum. loss 11.60, cum. ppl 4.23 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 8600, dev. ppl 6.027478\n",
            "epoch 32, iter 8600: save currently the best model to [model.bin]\n",
            "epoch 32 (178 / 272), iter 8610, avg. loss 12.00, avg. ppl 4.41 cum. examples 320, speed 4760.66 words/sec, time elapsed 350.48 sec\n",
            "epoch 32 (188 / 272), iter 8620, avg. loss 11.59, avg. ppl 4.32 cum. examples 640, speed 6203.66 words/sec, time elapsed 350.89 sec\n",
            "epoch 32 (198 / 272), iter 8630, avg. loss 11.87, avg. ppl 4.26 cum. examples 960, speed 6821.79 words/sec, time elapsed 351.28 sec\n",
            "epoch 32 (208 / 272), iter 8640, avg. loss 11.59, avg. ppl 4.20 cum. examples 1280, speed 6715.06 words/sec, time elapsed 351.66 sec\n",
            "epoch 32 (218 / 272), iter 8650, avg. loss 11.88, avg. ppl 4.38 cum. examples 1600, speed 6455.79 words/sec, time elapsed 352.06 sec\n",
            "epoch 32 (228 / 272), iter 8660, avg. loss 11.67, avg. ppl 4.28 cum. examples 1920, speed 6398.32 words/sec, time elapsed 352.46 sec\n",
            "epoch 32 (238 / 272), iter 8670, avg. loss 11.95, avg. ppl 4.43 cum. examples 2240, speed 6536.91 words/sec, time elapsed 352.85 sec\n",
            "epoch 32 (248 / 272), iter 8680, avg. loss 11.90, avg. ppl 4.30 cum. examples 2560, speed 6668.49 words/sec, time elapsed 353.25 sec\n",
            "epoch 32 (258 / 272), iter 8690, avg. loss 12.59, avg. ppl 4.62 cum. examples 2880, speed 6698.36 words/sec, time elapsed 353.64 sec\n",
            "epoch 32 (268 / 272), iter 8700, avg. loss 12.45, avg. ppl 4.71 cum. examples 3200, speed 6676.05 words/sec, time elapsed 354.03 sec\n",
            "epoch 32, iter 8700, cum. loss 11.95, cum. ppl 4.39 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 8700, dev. ppl 5.950440\n",
            "epoch 32, iter 8700: save currently the best model to [model.bin]\n",
            "epoch 33 (6 / 272), iter 8710, avg. loss 12.16, avg. ppl 4.44 cum. examples 317, speed 4727.35 words/sec, time elapsed 354.57 sec\n",
            "epoch 33 (16 / 272), iter 8720, avg. loss 11.87, avg. ppl 4.33 cum. examples 637, speed 6230.23 words/sec, time elapsed 354.99 sec\n",
            "epoch 33 (26 / 272), iter 8730, avg. loss 11.53, avg. ppl 4.09 cum. examples 957, speed 6420.00 words/sec, time elapsed 355.40 sec\n",
            "epoch 33 (36 / 272), iter 8740, avg. loss 12.29, avg. ppl 4.32 cum. examples 1277, speed 6566.20 words/sec, time elapsed 355.81 sec\n",
            "epoch 33 (46 / 272), iter 8750, avg. loss 10.99, avg. ppl 3.95 cum. examples 1597, speed 6495.31 words/sec, time elapsed 356.20 sec\n",
            "epoch 33 (56 / 272), iter 8760, avg. loss 11.70, avg. ppl 4.21 cum. examples 1917, speed 6405.48 words/sec, time elapsed 356.61 sec\n",
            "epoch 33 (66 / 272), iter 8770, avg. loss 10.96, avg. ppl 3.94 cum. examples 2237, speed 6294.71 words/sec, time elapsed 357.02 sec\n",
            "epoch 33 (76 / 272), iter 8780, avg. loss 11.99, avg. ppl 4.37 cum. examples 2557, speed 6094.91 words/sec, time elapsed 357.44 sec\n",
            "epoch 33 (86 / 272), iter 8790, avg. loss 12.33, avg. ppl 4.57 cum. examples 2877, speed 6451.98 words/sec, time elapsed 357.85 sec\n",
            "epoch 33 (96 / 272), iter 8800, avg. loss 11.18, avg. ppl 4.03 cum. examples 3197, speed 6830.83 words/sec, time elapsed 358.22 sec\n",
            "epoch 33, iter 8800, cum. loss 11.70, cum. ppl 4.22 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 8800, dev. ppl 5.903632\n",
            "epoch 33, iter 8800: save currently the best model to [model.bin]\n",
            "epoch 33 (106 / 272), iter 8810, avg. loss 11.36, avg. ppl 4.18 cum. examples 320, speed 4503.15 words/sec, time elapsed 358.79 sec\n",
            "epoch 33 (116 / 272), iter 8820, avg. loss 11.81, avg. ppl 4.40 cum. examples 640, speed 6670.52 words/sec, time elapsed 359.17 sec\n",
            "epoch 33 (126 / 272), iter 8830, avg. loss 11.92, avg. ppl 4.34 cum. examples 960, speed 6201.22 words/sec, time elapsed 359.59 sec\n",
            "epoch 33 (136 / 272), iter 8840, avg. loss 11.05, avg. ppl 4.04 cum. examples 1280, speed 6765.77 words/sec, time elapsed 359.96 sec\n",
            "epoch 33 (146 / 272), iter 8850, avg. loss 12.45, avg. ppl 4.53 cum. examples 1600, speed 6598.31 words/sec, time elapsed 360.36 sec\n",
            "epoch 33 (156 / 272), iter 8860, avg. loss 11.38, avg. ppl 4.17 cum. examples 1920, speed 6617.03 words/sec, time elapsed 360.75 sec\n",
            "epoch 33 (166 / 272), iter 8870, avg. loss 11.29, avg. ppl 4.05 cum. examples 2240, speed 6419.39 words/sec, time elapsed 361.15 sec\n",
            "epoch 33 (176 / 272), iter 8880, avg. loss 11.06, avg. ppl 4.04 cum. examples 2560, speed 6458.71 words/sec, time elapsed 361.54 sec\n",
            "epoch 33 (186 / 272), iter 8890, avg. loss 11.12, avg. ppl 4.05 cum. examples 2880, speed 6141.99 words/sec, time elapsed 361.96 sec\n",
            "epoch 33 (196 / 272), iter 8900, avg. loss 11.32, avg. ppl 4.12 cum. examples 3200, speed 6786.95 words/sec, time elapsed 362.33 sec\n",
            "epoch 33, iter 8900, cum. loss 11.48, cum. ppl 4.19 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 8900, dev. ppl 5.961424\n",
            "hit patience 1\n",
            "epoch 33 (206 / 272), iter 8910, avg. loss 10.79, avg. ppl 3.82 cum. examples 320, speed 4987.04 words/sec, time elapsed 362.85 sec\n",
            "epoch 33 (216 / 272), iter 8920, avg. loss 11.51, avg. ppl 4.22 cum. examples 640, speed 6802.12 words/sec, time elapsed 363.23 sec\n",
            "epoch 33 (226 / 272), iter 8930, avg. loss 11.46, avg. ppl 4.12 cum. examples 960, speed 6549.73 words/sec, time elapsed 363.62 sec\n",
            "epoch 33 (236 / 272), iter 8940, avg. loss 11.39, avg. ppl 4.19 cum. examples 1280, speed 6424.15 words/sec, time elapsed 364.02 sec\n",
            "epoch 33 (246 / 272), iter 8950, avg. loss 12.60, avg. ppl 4.58 cum. examples 1600, speed 6756.02 words/sec, time elapsed 364.41 sec\n",
            "epoch 33 (256 / 272), iter 8960, avg. loss 12.16, avg. ppl 4.40 cum. examples 1920, speed 5741.98 words/sec, time elapsed 364.87 sec\n",
            "epoch 33 (266 / 272), iter 8970, avg. loss 12.38, avg. ppl 4.55 cum. examples 2240, speed 6250.09 words/sec, time elapsed 365.29 sec\n",
            "epoch 34 (4 / 272), iter 8980, avg. loss 11.54, avg. ppl 4.14 cum. examples 2557, speed 6388.86 words/sec, time elapsed 365.69 sec\n",
            "epoch 34 (14 / 272), iter 8990, avg. loss 10.31, avg. ppl 3.63 cum. examples 2877, speed 6566.20 words/sec, time elapsed 366.08 sec\n",
            "epoch 34 (24 / 272), iter 9000, avg. loss 11.05, avg. ppl 3.92 cum. examples 3197, speed 6591.14 words/sec, time elapsed 366.47 sec\n",
            "epoch 34, iter 9000, cum. loss 11.52, cum. ppl 4.15 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 9000, dev. ppl 5.920260\n",
            "hit patience 2\n",
            "epoch 34 (34 / 272), iter 9010, avg. loss 11.33, avg. ppl 4.08 cum. examples 320, speed 4887.86 words/sec, time elapsed 367.00 sec\n",
            "epoch 34 (44 / 272), iter 9020, avg. loss 10.77, avg. ppl 3.89 cum. examples 640, speed 6789.60 words/sec, time elapsed 367.37 sec\n",
            "epoch 34 (54 / 272), iter 9030, avg. loss 11.20, avg. ppl 4.06 cum. examples 960, speed 6105.00 words/sec, time elapsed 367.79 sec\n",
            "epoch 34 (64 / 272), iter 9040, avg. loss 10.83, avg. ppl 3.87 cum. examples 1280, speed 6853.20 words/sec, time elapsed 368.17 sec\n",
            "epoch 34 (74 / 272), iter 9050, avg. loss 11.45, avg. ppl 4.09 cum. examples 1600, speed 6631.75 words/sec, time elapsed 368.56 sec\n",
            "epoch 34 (84 / 272), iter 9060, avg. loss 12.21, avg. ppl 4.42 cum. examples 1920, speed 6793.10 words/sec, time elapsed 368.95 sec\n",
            "epoch 34 (94 / 272), iter 9070, avg. loss 12.98, avg. ppl 4.74 cum. examples 2240, speed 6852.50 words/sec, time elapsed 369.34 sec\n",
            "epoch 34 (104 / 272), iter 9080, avg. loss 12.28, avg. ppl 4.49 cum. examples 2560, speed 6253.46 words/sec, time elapsed 369.76 sec\n",
            "epoch 34 (114 / 272), iter 9090, avg. loss 12.00, avg. ppl 4.29 cum. examples 2880, speed 7000.72 words/sec, time elapsed 370.13 sec\n",
            "epoch 34 (124 / 272), iter 9100, avg. loss 10.57, avg. ppl 3.79 cum. examples 3200, speed 6730.43 words/sec, time elapsed 370.51 sec\n",
            "epoch 34, iter 9100, cum. loss 11.56, cum. ppl 4.17 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 9100, dev. ppl 5.805834\n",
            "epoch 34, iter 9100: save currently the best model to [model.bin]\n",
            "epoch 34 (134 / 272), iter 9110, avg. loss 11.48, avg. ppl 4.17 cum. examples 320, speed 4868.36 words/sec, time elapsed 371.04 sec\n",
            "epoch 34 (144 / 272), iter 9120, avg. loss 11.58, avg. ppl 4.19 cum. examples 640, speed 7353.74 words/sec, time elapsed 371.39 sec\n",
            "epoch 34 (154 / 272), iter 9130, avg. loss 11.19, avg. ppl 3.98 cum. examples 960, speed 6513.93 words/sec, time elapsed 371.79 sec\n",
            "epoch 34 (164 / 272), iter 9140, avg. loss 10.99, avg. ppl 3.87 cum. examples 1280, speed 7214.21 words/sec, time elapsed 372.15 sec\n",
            "epoch 34 (174 / 272), iter 9150, avg. loss 11.28, avg. ppl 4.03 cum. examples 1600, speed 6842.09 words/sec, time elapsed 372.53 sec\n",
            "epoch 34 (184 / 272), iter 9160, avg. loss 10.42, avg. ppl 3.73 cum. examples 1920, speed 6515.62 words/sec, time elapsed 372.92 sec\n",
            "epoch 34 (194 / 272), iter 9170, avg. loss 11.53, avg. ppl 4.11 cum. examples 2240, speed 7269.12 words/sec, time elapsed 373.27 sec\n",
            "epoch 34 (204 / 272), iter 9180, avg. loss 10.76, avg. ppl 3.81 cum. examples 2560, speed 6643.06 words/sec, time elapsed 373.66 sec\n",
            "epoch 34 (214 / 272), iter 9190, avg. loss 11.28, avg. ppl 4.07 cum. examples 2880, speed 6573.06 words/sec, time elapsed 374.05 sec\n",
            "epoch 34 (224 / 272), iter 9200, avg. loss 12.19, avg. ppl 4.49 cum. examples 3200, speed 6382.95 words/sec, time elapsed 374.46 sec\n",
            "epoch 34, iter 9200, cum. loss 11.27, cum. ppl 4.04 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 9200, dev. ppl 5.872740\n",
            "hit patience 1\n",
            "epoch 34 (234 / 272), iter 9210, avg. loss 11.48, avg. ppl 4.19 cum. examples 320, speed 5051.52 words/sec, time elapsed 374.97 sec\n",
            "epoch 34 (244 / 272), iter 9220, avg. loss 11.09, avg. ppl 3.97 cum. examples 640, speed 7181.15 words/sec, time elapsed 375.33 sec\n",
            "epoch 34 (254 / 272), iter 9230, avg. loss 11.78, avg. ppl 4.29 cum. examples 960, speed 6930.45 words/sec, time elapsed 375.70 sec\n",
            "epoch 34 (264 / 272), iter 9240, avg. loss 11.21, avg. ppl 4.02 cum. examples 1280, speed 6444.66 words/sec, time elapsed 376.10 sec\n",
            "epoch 35 (2 / 272), iter 9250, avg. loss 11.34, avg. ppl 4.13 cum. examples 1597, speed 6858.47 words/sec, time elapsed 376.47 sec\n",
            "epoch 35 (12 / 272), iter 9260, avg. loss 11.02, avg. ppl 3.89 cum. examples 1917, speed 6885.61 words/sec, time elapsed 376.85 sec\n",
            "epoch 35 (22 / 272), iter 9270, avg. loss 12.21, avg. ppl 4.41 cum. examples 2237, speed 6947.32 words/sec, time elapsed 377.23 sec\n",
            "epoch 35 (32 / 272), iter 9280, avg. loss 10.32, avg. ppl 3.67 cum. examples 2557, speed 6552.78 words/sec, time elapsed 377.61 sec\n",
            "epoch 35 (42 / 272), iter 9290, avg. loss 11.42, avg. ppl 4.06 cum. examples 2877, speed 6547.40 words/sec, time elapsed 378.01 sec\n",
            "epoch 35 (52 / 272), iter 9300, avg. loss 11.38, avg. ppl 4.08 cum. examples 3197, speed 6889.24 words/sec, time elapsed 378.39 sec\n",
            "epoch 35, iter 9300, cum. loss 11.32, cum. ppl 4.07 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 9300, dev. ppl 5.831182\n",
            "hit patience 2\n",
            "epoch 35 (62 / 272), iter 9310, avg. loss 11.65, avg. ppl 4.13 cum. examples 320, speed 4771.69 words/sec, time elapsed 378.94 sec\n",
            "epoch 35 (72 / 272), iter 9320, avg. loss 10.64, avg. ppl 3.83 cum. examples 640, speed 7233.41 words/sec, time elapsed 379.29 sec\n",
            "epoch 35 (82 / 272), iter 9330, avg. loss 11.12, avg. ppl 3.99 cum. examples 960, speed 6698.73 words/sec, time elapsed 379.67 sec\n",
            "epoch 35 (92 / 272), iter 9340, avg. loss 10.58, avg. ppl 3.77 cum. examples 1280, speed 6689.57 words/sec, time elapsed 380.06 sec\n",
            "epoch 35 (102 / 272), iter 9350, avg. loss 11.10, avg. ppl 3.92 cum. examples 1600, speed 6889.35 words/sec, time elapsed 380.43 sec\n",
            "epoch 35 (112 / 272), iter 9360, avg. loss 9.38, avg. ppl 3.31 cum. examples 1920, speed 6415.75 words/sec, time elapsed 380.83 sec\n",
            "epoch 35 (122 / 272), iter 9370, avg. loss 11.48, avg. ppl 4.09 cum. examples 2240, speed 5751.52 words/sec, time elapsed 381.28 sec\n",
            "epoch 35 (132 / 272), iter 9380, avg. loss 11.61, avg. ppl 4.17 cum. examples 2560, speed 6892.06 words/sec, time elapsed 381.66 sec\n",
            "epoch 35 (142 / 272), iter 9390, avg. loss 11.47, avg. ppl 4.14 cum. examples 2880, speed 6714.77 words/sec, time elapsed 382.04 sec\n",
            "epoch 35 (152 / 272), iter 9400, avg. loss 10.88, avg. ppl 3.90 cum. examples 3200, speed 6895.18 words/sec, time elapsed 382.41 sec\n",
            "epoch 35, iter 9400, cum. loss 10.99, cum. ppl 3.92 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 9400, dev. ppl 5.788589\n",
            "epoch 35, iter 9400: save currently the best model to [model.bin]\n",
            "epoch 35 (162 / 272), iter 9410, avg. loss 11.11, avg. ppl 4.05 cum. examples 320, speed 4868.62 words/sec, time elapsed 382.94 sec\n",
            "epoch 35 (172 / 272), iter 9420, avg. loss 11.50, avg. ppl 4.04 cum. examples 640, speed 7163.71 words/sec, time elapsed 383.30 sec\n",
            "epoch 35 (182 / 272), iter 9430, avg. loss 11.44, avg. ppl 4.10 cum. examples 960, speed 6929.80 words/sec, time elapsed 383.68 sec\n",
            "epoch 35 (192 / 272), iter 9440, avg. loss 11.16, avg. ppl 4.03 cum. examples 1280, speed 6850.19 words/sec, time elapsed 384.05 sec\n",
            "epoch 35 (202 / 272), iter 9450, avg. loss 10.12, avg. ppl 3.66 cum. examples 1600, speed 6725.75 words/sec, time elapsed 384.42 sec\n",
            "epoch 35 (212 / 272), iter 9460, avg. loss 12.53, avg. ppl 4.47 cum. examples 1920, speed 6407.39 words/sec, time elapsed 384.84 sec\n",
            "epoch 35 (222 / 272), iter 9470, avg. loss 11.31, avg. ppl 3.97 cum. examples 2240, speed 6418.03 words/sec, time elapsed 385.25 sec\n",
            "epoch 35 (232 / 272), iter 9480, avg. loss 10.90, avg. ppl 3.85 cum. examples 2560, speed 6918.49 words/sec, time elapsed 385.63 sec\n",
            "epoch 35 (242 / 272), iter 9490, avg. loss 11.96, avg. ppl 4.31 cum. examples 2880, speed 6785.52 words/sec, time elapsed 386.01 sec\n",
            "epoch 35 (252 / 272), iter 9500, avg. loss 11.37, avg. ppl 4.05 cum. examples 3200, speed 7021.93 words/sec, time elapsed 386.38 sec\n",
            "epoch 35, iter 9500, cum. loss 11.34, cum. ppl 4.05 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 9500, dev. ppl 5.799615\n",
            "hit patience 1\n",
            "epoch 35 (262 / 272), iter 9510, avg. loss 11.33, avg. ppl 4.01 cum. examples 320, speed 5193.65 words/sec, time elapsed 386.88 sec\n",
            "epoch 35 (272 / 272), iter 9520, avg. loss 11.01, avg. ppl 4.00 cum. examples 637, speed 6708.62 words/sec, time elapsed 387.26 sec\n",
            "epoch 36 (10 / 272), iter 9530, avg. loss 11.49, avg. ppl 4.03 cum. examples 957, speed 6721.37 words/sec, time elapsed 387.65 sec\n",
            "epoch 36 (20 / 272), iter 9540, avg. loss 10.76, avg. ppl 3.78 cum. examples 1277, speed 6394.34 words/sec, time elapsed 388.06 sec\n",
            "epoch 36 (30 / 272), iter 9550, avg. loss 10.37, avg. ppl 3.65 cum. examples 1597, speed 7364.27 words/sec, time elapsed 388.41 sec\n",
            "epoch 36 (40 / 272), iter 9560, avg. loss 10.73, avg. ppl 3.82 cum. examples 1917, speed 6614.60 words/sec, time elapsed 388.79 sec\n",
            "epoch 36 (50 / 272), iter 9570, avg. loss 11.07, avg. ppl 3.97 cum. examples 2237, speed 6900.13 words/sec, time elapsed 389.17 sec\n",
            "epoch 36 (60 / 272), iter 9580, avg. loss 10.46, avg. ppl 3.71 cum. examples 2557, speed 6715.83 words/sec, time elapsed 389.55 sec\n",
            "epoch 36 (70 / 272), iter 9590, avg. loss 11.12, avg. ppl 3.92 cum. examples 2877, speed 6752.10 words/sec, time elapsed 389.93 sec\n",
            "epoch 36 (80 / 272), iter 9600, avg. loss 11.39, avg. ppl 4.00 cum. examples 3197, speed 5989.91 words/sec, time elapsed 390.37 sec\n",
            "epoch 36, iter 9600, cum. loss 10.97, cum. ppl 3.89 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 9600, dev. ppl 5.718734\n",
            "epoch 36, iter 9600: save currently the best model to [model.bin]\n",
            "epoch 36 (90 / 272), iter 9610, avg. loss 11.27, avg. ppl 4.02 cum. examples 320, speed 4652.80 words/sec, time elapsed 390.93 sec\n",
            "epoch 36 (100 / 272), iter 9620, avg. loss 11.88, avg. ppl 4.17 cum. examples 640, speed 5540.55 words/sec, time elapsed 391.41 sec\n",
            "epoch 36 (110 / 272), iter 9630, avg. loss 9.82, avg. ppl 3.50 cum. examples 960, speed 6049.72 words/sec, time elapsed 391.82 sec\n",
            "epoch 36 (120 / 272), iter 9640, avg. loss 10.86, avg. ppl 3.81 cum. examples 1280, speed 7137.26 words/sec, time elapsed 392.19 sec\n",
            "epoch 36 (130 / 272), iter 9650, avg. loss 12.18, avg. ppl 4.37 cum. examples 1600, speed 6916.66 words/sec, time elapsed 392.57 sec\n",
            "epoch 36 (140 / 272), iter 9660, avg. loss 10.21, avg. ppl 3.61 cum. examples 1920, speed 6989.23 words/sec, time elapsed 392.94 sec\n",
            "epoch 36 (150 / 272), iter 9670, avg. loss 10.93, avg. ppl 3.91 cum. examples 2240, speed 7018.98 words/sec, time elapsed 393.30 sec\n",
            "epoch 36 (160 / 272), iter 9680, avg. loss 10.73, avg. ppl 3.83 cum. examples 2560, speed 7018.11 words/sec, time elapsed 393.67 sec\n",
            "epoch 36 (170 / 272), iter 9690, avg. loss 10.09, avg. ppl 3.54 cum. examples 2880, speed 6326.46 words/sec, time elapsed 394.07 sec\n",
            "epoch 36 (180 / 272), iter 9700, avg. loss 10.69, avg. ppl 3.81 cum. examples 3200, speed 6252.50 words/sec, time elapsed 394.48 sec\n",
            "epoch 36, iter 9700, cum. loss 10.87, cum. ppl 3.85 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 9700, dev. ppl 5.714031\n",
            "epoch 36, iter 9700: save currently the best model to [model.bin]\n",
            "epoch 36 (190 / 272), iter 9710, avg. loss 10.44, avg. ppl 3.69 cum. examples 320, speed 4431.19 words/sec, time elapsed 395.06 sec\n",
            "epoch 36 (200 / 272), iter 9720, avg. loss 10.78, avg. ppl 3.81 cum. examples 640, speed 5518.99 words/sec, time elapsed 395.52 sec\n",
            "epoch 36 (210 / 272), iter 9730, avg. loss 11.26, avg. ppl 4.08 cum. examples 960, speed 6869.14 words/sec, time elapsed 395.90 sec\n",
            "epoch 36 (220 / 272), iter 9740, avg. loss 11.58, avg. ppl 4.09 cum. examples 1280, speed 6668.23 words/sec, time elapsed 396.29 sec\n",
            "epoch 36 (230 / 272), iter 9750, avg. loss 11.14, avg. ppl 3.95 cum. examples 1600, speed 6741.95 words/sec, time elapsed 396.68 sec\n",
            "epoch 36 (240 / 272), iter 9760, avg. loss 11.48, avg. ppl 4.10 cum. examples 1920, speed 6667.72 words/sec, time elapsed 397.07 sec\n",
            "epoch 36 (250 / 272), iter 9770, avg. loss 11.32, avg. ppl 3.99 cum. examples 2240, speed 6644.58 words/sec, time elapsed 397.46 sec\n",
            "epoch 36 (260 / 272), iter 9780, avg. loss 11.63, avg. ppl 4.21 cum. examples 2560, speed 6788.01 words/sec, time elapsed 397.84 sec\n",
            "epoch 36 (270 / 272), iter 9790, avg. loss 10.92, avg. ppl 3.92 cum. examples 2880, speed 6836.09 words/sec, time elapsed 398.22 sec\n",
            "epoch 37 (8 / 272), iter 9800, avg. loss 10.22, avg. ppl 3.59 cum. examples 3197, speed 6989.51 words/sec, time elapsed 398.58 sec\n",
            "epoch 37, iter 9800, cum. loss 11.08, cum. ppl 3.94 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 9800, dev. ppl 5.658756\n",
            "epoch 37, iter 9800: save currently the best model to [model.bin]\n",
            "epoch 37 (18 / 272), iter 9810, avg. loss 10.41, avg. ppl 3.63 cum. examples 320, speed 4966.72 words/sec, time elapsed 399.10 sec\n",
            "epoch 37 (28 / 272), iter 9820, avg. loss 10.15, avg. ppl 3.54 cum. examples 640, speed 5681.61 words/sec, time elapsed 399.55 sec\n",
            "epoch 37 (38 / 272), iter 9830, avg. loss 10.77, avg. ppl 3.76 cum. examples 960, speed 6028.45 words/sec, time elapsed 399.98 sec\n",
            "epoch 37 (48 / 272), iter 9840, avg. loss 11.37, avg. ppl 4.06 cum. examples 1280, speed 6760.18 words/sec, time elapsed 400.37 sec\n",
            "epoch 37 (58 / 272), iter 9850, avg. loss 10.05, avg. ppl 3.55 cum. examples 1600, speed 6813.06 words/sec, time elapsed 400.74 sec\n",
            "epoch 37 (68 / 272), iter 9860, avg. loss 10.26, avg. ppl 3.55 cum. examples 1920, speed 6856.30 words/sec, time elapsed 401.12 sec\n",
            "epoch 37 (78 / 272), iter 9870, avg. loss 10.34, avg. ppl 3.57 cum. examples 2240, speed 7005.26 words/sec, time elapsed 401.49 sec\n",
            "epoch 37 (88 / 272), iter 9880, avg. loss 11.08, avg. ppl 3.91 cum. examples 2560, speed 6159.99 words/sec, time elapsed 401.91 sec\n",
            "epoch 37 (98 / 272), iter 9890, avg. loss 11.01, avg. ppl 3.86 cum. examples 2880, speed 5727.95 words/sec, time elapsed 402.37 sec\n",
            "epoch 37 (108 / 272), iter 9900, avg. loss 11.29, avg. ppl 4.02 cum. examples 3200, speed 5792.26 words/sec, time elapsed 402.82 sec\n",
            "epoch 37, iter 9900, cum. loss 10.67, cum. ppl 3.74 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 9900, dev. ppl 5.692756\n",
            "hit patience 1\n",
            "epoch 37 (118 / 272), iter 9910, avg. loss 10.94, avg. ppl 3.82 cum. examples 320, speed 5304.02 words/sec, time elapsed 403.31 sec\n",
            "epoch 37 (128 / 272), iter 9920, avg. loss 10.40, avg. ppl 3.71 cum. examples 640, speed 6993.31 words/sec, time elapsed 403.67 sec\n",
            "epoch 37 (138 / 272), iter 9930, avg. loss 11.85, avg. ppl 4.26 cum. examples 960, speed 6551.34 words/sec, time elapsed 404.07 sec\n",
            "epoch 37 (148 / 272), iter 9940, avg. loss 10.56, avg. ppl 3.74 cum. examples 1280, speed 6615.14 words/sec, time elapsed 404.46 sec\n",
            "epoch 37 (158 / 272), iter 9950, avg. loss 10.90, avg. ppl 3.79 cum. examples 1600, speed 6093.73 words/sec, time elapsed 404.89 sec\n",
            "epoch 37 (168 / 272), iter 9960, avg. loss 11.48, avg. ppl 4.01 cum. examples 1920, speed 5963.55 words/sec, time elapsed 405.33 sec\n",
            "epoch 37 (178 / 272), iter 9970, avg. loss 11.13, avg. ppl 3.92 cum. examples 2240, speed 5985.16 words/sec, time elapsed 405.77 sec\n",
            "epoch 37 (188 / 272), iter 9980, avg. loss 10.89, avg. ppl 3.84 cum. examples 2560, speed 7010.49 words/sec, time elapsed 406.14 sec\n",
            "epoch 37 (198 / 272), iter 9990, avg. loss 11.21, avg. ppl 4.04 cum. examples 2880, speed 6550.93 words/sec, time elapsed 406.53 sec\n",
            "epoch 37 (208 / 272), iter 10000, avg. loss 10.63, avg. ppl 3.71 cum. examples 3200, speed 6747.73 words/sec, time elapsed 406.91 sec\n",
            "epoch 37, iter 10000, cum. loss 11.00, cum. ppl 3.88 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 10000, dev. ppl 5.656840\n",
            "epoch 37, iter 10000: save currently the best model to [model.bin]\n",
            "epoch 37 (218 / 272), iter 10010, avg. loss 10.86, avg. ppl 3.90 cum. examples 320, speed 4871.31 words/sec, time elapsed 407.44 sec\n",
            "epoch 37 (228 / 272), iter 10020, avg. loss 10.83, avg. ppl 3.90 cum. examples 640, speed 6870.56 words/sec, time elapsed 407.81 sec\n",
            "epoch 37 (238 / 272), iter 10030, avg. loss 10.77, avg. ppl 3.81 cum. examples 960, speed 5824.14 words/sec, time elapsed 408.25 sec\n",
            "epoch 37 (248 / 272), iter 10040, avg. loss 10.43, avg. ppl 3.70 cum. examples 1280, speed 5819.41 words/sec, time elapsed 408.69 sec\n",
            "epoch 37 (258 / 272), iter 10050, avg. loss 10.88, avg. ppl 3.88 cum. examples 1600, speed 7097.22 words/sec, time elapsed 409.05 sec\n",
            "epoch 37 (268 / 272), iter 10060, avg. loss 11.51, avg. ppl 4.05 cum. examples 1920, speed 6882.38 words/sec, time elapsed 409.44 sec\n",
            "epoch 38 (6 / 272), iter 10070, avg. loss 10.99, avg. ppl 3.92 cum. examples 2237, speed 6839.40 words/sec, time elapsed 409.81 sec\n",
            "epoch 38 (16 / 272), iter 10080, avg. loss 10.46, avg. ppl 3.72 cum. examples 2557, speed 6965.35 words/sec, time elapsed 410.18 sec\n",
            "epoch 38 (26 / 272), iter 10090, avg. loss 10.45, avg. ppl 3.57 cum. examples 2877, speed 6942.40 words/sec, time elapsed 410.55 sec\n",
            "epoch 38 (36 / 272), iter 10100, avg. loss 11.11, avg. ppl 3.86 cum. examples 3197, speed 7025.68 words/sec, time elapsed 410.93 sec\n",
            "epoch 38, iter 10100, cum. loss 10.83, cum. ppl 3.83 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 10100, dev. ppl 5.669618\n",
            "hit patience 1\n",
            "epoch 38 (46 / 272), iter 10110, avg. loss 9.52, avg. ppl 3.34 cum. examples 320, speed 5298.94 words/sec, time elapsed 411.41 sec\n",
            "epoch 38 (56 / 272), iter 10120, avg. loss 10.57, avg. ppl 3.67 cum. examples 640, speed 6839.59 words/sec, time elapsed 411.79 sec\n",
            "epoch 38 (66 / 272), iter 10130, avg. loss 10.35, avg. ppl 3.59 cum. examples 960, speed 6327.69 words/sec, time elapsed 412.20 sec\n",
            "epoch 38 (76 / 272), iter 10140, avg. loss 9.66, avg. ppl 3.39 cum. examples 1280, speed 6597.08 words/sec, time elapsed 412.58 sec\n",
            "epoch 38 (86 / 272), iter 10150, avg. loss 10.86, avg. ppl 3.73 cum. examples 1600, speed 6669.29 words/sec, time elapsed 412.98 sec\n",
            "epoch 38 (96 / 272), iter 10160, avg. loss 10.87, avg. ppl 3.77 cum. examples 1920, speed 6646.87 words/sec, time elapsed 413.37 sec\n",
            "epoch 38 (106 / 272), iter 10170, avg. loss 10.92, avg. ppl 3.84 cum. examples 2240, speed 6550.74 words/sec, time elapsed 413.77 sec\n",
            "epoch 38 (116 / 272), iter 10180, avg. loss 11.09, avg. ppl 3.92 cum. examples 2560, speed 6038.27 words/sec, time elapsed 414.20 sec\n",
            "epoch 38 (126 / 272), iter 10190, avg. loss 10.89, avg. ppl 3.88 cum. examples 2880, speed 6559.19 words/sec, time elapsed 414.59 sec\n",
            "epoch 38 (136 / 272), iter 10200, avg. loss 10.41, avg. ppl 3.72 cum. examples 3200, speed 5800.23 words/sec, time elapsed 415.03 sec\n",
            "epoch 38, iter 10200, cum. loss 10.51, cum. ppl 3.68 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 10200, dev. ppl 5.693028\n",
            "hit patience 2\n",
            "epoch 38 (146 / 272), iter 10210, avg. loss 10.62, avg. ppl 3.75 cum. examples 320, speed 4735.17 words/sec, time elapsed 415.57 sec\n",
            "epoch 38 (156 / 272), iter 10220, avg. loss 10.38, avg. ppl 3.61 cum. examples 640, speed 6681.70 words/sec, time elapsed 415.96 sec\n",
            "epoch 38 (166 / 272), iter 10230, avg. loss 11.75, avg. ppl 4.18 cum. examples 960, speed 6812.00 words/sec, time elapsed 416.34 sec\n",
            "epoch 38 (176 / 272), iter 10240, avg. loss 11.12, avg. ppl 3.89 cum. examples 1280, speed 7123.69 words/sec, time elapsed 416.71 sec\n",
            "epoch 38 (186 / 272), iter 10250, avg. loss 9.93, avg. ppl 3.49 cum. examples 1600, speed 7022.20 words/sec, time elapsed 417.07 sec\n",
            "epoch 38 (196 / 272), iter 10260, avg. loss 9.69, avg. ppl 3.40 cum. examples 1920, speed 7070.88 words/sec, time elapsed 417.43 sec\n",
            "epoch 38 (206 / 272), iter 10270, avg. loss 9.88, avg. ppl 3.49 cum. examples 2240, speed 6467.41 words/sec, time elapsed 417.82 sec\n",
            "epoch 38 (216 / 272), iter 10280, avg. loss 10.84, avg. ppl 3.80 cum. examples 2560, speed 6833.56 words/sec, time elapsed 418.20 sec\n",
            "epoch 38 (226 / 272), iter 10290, avg. loss 10.65, avg. ppl 3.71 cum. examples 2880, speed 6805.20 words/sec, time elapsed 418.59 sec\n",
            "epoch 38 (236 / 272), iter 10300, avg. loss 10.88, avg. ppl 3.77 cum. examples 3200, speed 6779.37 words/sec, time elapsed 418.97 sec\n",
            "epoch 38, iter 10300, cum. loss 10.57, cum. ppl 3.71 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 10300, dev. ppl 5.651739\n",
            "epoch 38, iter 10300: save currently the best model to [model.bin]\n",
            "epoch 38 (246 / 272), iter 10310, avg. loss 10.01, avg. ppl 3.56 cum. examples 320, speed 5026.87 words/sec, time elapsed 419.48 sec\n",
            "epoch 38 (256 / 272), iter 10320, avg. loss 11.47, avg. ppl 4.02 cum. examples 640, speed 6812.29 words/sec, time elapsed 419.86 sec\n",
            "epoch 38 (266 / 272), iter 10330, avg. loss 11.25, avg. ppl 4.00 cum. examples 960, speed 6923.68 words/sec, time elapsed 420.24 sec\n",
            "epoch 39 (4 / 272), iter 10340, avg. loss 10.57, avg. ppl 3.69 cum. examples 1277, speed 6533.65 words/sec, time elapsed 420.63 sec\n",
            "epoch 39 (14 / 272), iter 10350, avg. loss 9.66, avg. ppl 3.38 cum. examples 1597, speed 6069.02 words/sec, time elapsed 421.05 sec\n",
            "epoch 39 (24 / 272), iter 10360, avg. loss 10.28, avg. ppl 3.57 cum. examples 1917, speed 6374.09 words/sec, time elapsed 421.46 sec\n",
            "epoch 39 (34 / 272), iter 10370, avg. loss 10.87, avg. ppl 3.73 cum. examples 2237, speed 6592.99 words/sec, time elapsed 421.86 sec\n",
            "epoch 39 (44 / 272), iter 10380, avg. loss 9.52, avg. ppl 3.30 cum. examples 2557, speed 7326.35 words/sec, time elapsed 422.20 sec\n",
            "epoch 39 (54 / 272), iter 10390, avg. loss 10.54, avg. ppl 3.68 cum. examples 2877, speed 6920.58 words/sec, time elapsed 422.58 sec\n",
            "epoch 39 (64 / 272), iter 10400, avg. loss 10.04, avg. ppl 3.52 cum. examples 3197, speed 6404.23 words/sec, time elapsed 422.98 sec\n",
            "epoch 39, iter 10400, cum. loss 10.42, cum. ppl 3.64 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 10400, dev. ppl 5.571855\n",
            "epoch 39, iter 10400: save currently the best model to [model.bin]\n",
            "epoch 39 (74 / 272), iter 10410, avg. loss 11.06, avg. ppl 3.80 cum. examples 320, speed 5079.31 words/sec, time elapsed 423.50 sec\n",
            "epoch 39 (84 / 272), iter 10420, avg. loss 11.04, avg. ppl 3.87 cum. examples 640, speed 6606.50 words/sec, time elapsed 423.89 sec\n",
            "epoch 39 (94 / 272), iter 10430, avg. loss 10.39, avg. ppl 3.63 cum. examples 960, speed 6938.81 words/sec, time elapsed 424.27 sec\n",
            "epoch 39 (104 / 272), iter 10440, avg. loss 9.50, avg. ppl 3.28 cum. examples 1280, speed 6751.24 words/sec, time elapsed 424.64 sec\n",
            "epoch 39 (114 / 272), iter 10450, avg. loss 10.13, avg. ppl 3.56 cum. examples 1600, speed 6502.21 words/sec, time elapsed 425.04 sec\n",
            "epoch 39 (124 / 272), iter 10460, avg. loss 10.17, avg. ppl 3.52 cum. examples 1920, speed 7050.40 words/sec, time elapsed 425.40 sec\n",
            "epoch 39 (134 / 272), iter 10470, avg. loss 10.87, avg. ppl 3.82 cum. examples 2240, speed 6533.83 words/sec, time elapsed 425.80 sec\n",
            "epoch 39 (144 / 272), iter 10480, avg. loss 10.18, avg. ppl 3.57 cum. examples 2560, speed 6690.87 words/sec, time elapsed 426.18 sec\n",
            "epoch 39 (154 / 272), iter 10490, avg. loss 11.80, avg. ppl 4.21 cum. examples 2880, speed 7124.90 words/sec, time elapsed 426.55 sec\n",
            "epoch 39 (164 / 272), iter 10500, avg. loss 10.65, avg. ppl 3.70 cum. examples 3200, speed 5998.04 words/sec, time elapsed 426.99 sec\n",
            "epoch 39, iter 10500, cum. loss 10.58, cum. ppl 3.69 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 10500, dev. ppl 5.571510\n",
            "epoch 39, iter 10500: save currently the best model to [model.bin]\n",
            "epoch 39 (174 / 272), iter 10510, avg. loss 9.18, avg. ppl 3.20 cum. examples 320, speed 4970.34 words/sec, time elapsed 427.50 sec\n",
            "epoch 39 (184 / 272), iter 10520, avg. loss 10.51, avg. ppl 3.62 cum. examples 640, speed 6801.15 words/sec, time elapsed 427.88 sec\n",
            "epoch 39 (194 / 272), iter 10530, avg. loss 11.11, avg. ppl 3.95 cum. examples 960, speed 6907.05 words/sec, time elapsed 428.26 sec\n",
            "epoch 39 (204 / 272), iter 10540, avg. loss 10.56, avg. ppl 3.70 cum. examples 1280, speed 6660.65 words/sec, time elapsed 428.64 sec\n",
            "epoch 39 (214 / 272), iter 10550, avg. loss 9.87, avg. ppl 3.41 cum. examples 1600, speed 6618.31 words/sec, time elapsed 429.03 sec\n",
            "epoch 39 (224 / 272), iter 10560, avg. loss 11.21, avg. ppl 3.93 cum. examples 1920, speed 7121.30 words/sec, time elapsed 429.40 sec\n",
            "epoch 39 (234 / 272), iter 10570, avg. loss 10.40, avg. ppl 3.65 cum. examples 2240, speed 6699.75 words/sec, time elapsed 429.79 sec\n",
            "epoch 39 (244 / 272), iter 10580, avg. loss 10.27, avg. ppl 3.60 cum. examples 2560, speed 6762.99 words/sec, time elapsed 430.16 sec\n",
            "epoch 39 (254 / 272), iter 10590, avg. loss 10.66, avg. ppl 3.78 cum. examples 2880, speed 6863.76 words/sec, time elapsed 430.54 sec\n",
            "epoch 39 (264 / 272), iter 10600, avg. loss 10.76, avg. ppl 3.74 cum. examples 3200, speed 6349.86 words/sec, time elapsed 430.95 sec\n",
            "epoch 39, iter 10600, cum. loss 10.45, cum. ppl 3.65 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 10600, dev. ppl 5.553408\n",
            "epoch 39, iter 10600: save currently the best model to [model.bin]\n",
            "epoch 40 (2 / 272), iter 10610, avg. loss 9.66, avg. ppl 3.36 cum. examples 317, speed 5049.56 words/sec, time elapsed 431.45 sec\n",
            "epoch 40 (12 / 272), iter 10620, avg. loss 9.90, avg. ppl 3.38 cum. examples 637, speed 6816.19 words/sec, time elapsed 431.83 sec\n",
            "epoch 40 (22 / 272), iter 10630, avg. loss 9.79, avg. ppl 3.39 cum. examples 957, speed 6949.29 words/sec, time elapsed 432.20 sec\n",
            "epoch 40 (32 / 272), iter 10640, avg. loss 9.49, avg. ppl 3.31 cum. examples 1277, speed 7021.02 words/sec, time elapsed 432.56 sec\n",
            "epoch 40 (42 / 272), iter 10650, avg. loss 9.68, avg. ppl 3.28 cum. examples 1597, speed 6755.11 words/sec, time elapsed 432.95 sec\n",
            "epoch 40 (52 / 272), iter 10660, avg. loss 10.39, avg. ppl 3.65 cum. examples 1917, speed 6615.54 words/sec, time elapsed 433.34 sec\n",
            "epoch 40 (62 / 272), iter 10670, avg. loss 10.60, avg. ppl 3.70 cum. examples 2237, speed 7155.91 words/sec, time elapsed 433.70 sec\n",
            "epoch 40 (72 / 272), iter 10680, avg. loss 10.00, avg. ppl 3.44 cum. examples 2557, speed 7053.21 words/sec, time elapsed 434.07 sec\n",
            "epoch 40 (82 / 272), iter 10690, avg. loss 10.76, avg. ppl 3.75 cum. examples 2877, speed 7146.51 words/sec, time elapsed 434.43 sec\n",
            "epoch 40 (92 / 272), iter 10700, avg. loss 10.93, avg. ppl 3.83 cum. examples 3197, speed 7115.70 words/sec, time elapsed 434.80 sec\n",
            "epoch 40, iter 10700, cum. loss 10.12, cum. ppl 3.51 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 10700, dev. ppl 5.495867\n",
            "epoch 40, iter 10700: save currently the best model to [model.bin]\n",
            "epoch 40 (102 / 272), iter 10710, avg. loss 10.25, avg. ppl 3.56 cum. examples 320, speed 4377.75 words/sec, time elapsed 435.39 sec\n",
            "epoch 40 (112 / 272), iter 10720, avg. loss 10.83, avg. ppl 3.83 cum. examples 640, speed 6449.50 words/sec, time elapsed 435.79 sec\n",
            "epoch 40 (122 / 272), iter 10730, avg. loss 10.77, avg. ppl 3.68 cum. examples 960, speed 6464.33 words/sec, time elapsed 436.20 sec\n",
            "epoch 40 (132 / 272), iter 10740, avg. loss 10.53, avg. ppl 3.65 cum. examples 1280, speed 6986.84 words/sec, time elapsed 436.57 sec\n",
            "epoch 40 (142 / 272), iter 10750, avg. loss 10.23, avg. ppl 3.48 cum. examples 1600, speed 6956.34 words/sec, time elapsed 436.95 sec\n",
            "epoch 40 (152 / 272), iter 10760, avg. loss 9.97, avg. ppl 3.52 cum. examples 1920, speed 6829.12 words/sec, time elapsed 437.32 sec\n",
            "epoch 40 (162 / 272), iter 10770, avg. loss 9.72, avg. ppl 3.40 cum. examples 2240, speed 7004.69 words/sec, time elapsed 437.68 sec\n",
            "epoch 40 (172 / 272), iter 10780, avg. loss 9.40, avg. ppl 3.27 cum. examples 2560, speed 6982.94 words/sec, time elapsed 438.05 sec\n",
            "epoch 40 (182 / 272), iter 10790, avg. loss 10.65, avg. ppl 3.72 cum. examples 2880, speed 7489.33 words/sec, time elapsed 438.39 sec\n",
            "epoch 40 (192 / 272), iter 10800, avg. loss 9.88, avg. ppl 3.43 cum. examples 3200, speed 7167.17 words/sec, time elapsed 438.75 sec\n",
            "epoch 40, iter 10800, cum. loss 10.22, cum. ppl 3.55 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 10800, dev. ppl 5.498641\n",
            "hit patience 1\n",
            "epoch 40 (202 / 272), iter 10810, avg. loss 10.02, avg. ppl 3.48 cum. examples 320, speed 5249.20 words/sec, time elapsed 439.24 sec\n",
            "epoch 40 (212 / 272), iter 10820, avg. loss 11.06, avg. ppl 3.82 cum. examples 640, speed 7071.37 words/sec, time elapsed 439.62 sec\n",
            "epoch 40 (222 / 272), iter 10830, avg. loss 10.93, avg. ppl 3.85 cum. examples 960, speed 7022.21 words/sec, time elapsed 439.99 sec\n",
            "epoch 40 (232 / 272), iter 10840, avg. loss 11.19, avg. ppl 3.95 cum. examples 1280, speed 7015.10 words/sec, time elapsed 440.36 sec\n",
            "epoch 40 (242 / 272), iter 10850, avg. loss 9.53, avg. ppl 3.33 cum. examples 1600, speed 6894.74 words/sec, time elapsed 440.73 sec\n",
            "epoch 40 (252 / 272), iter 10860, avg. loss 10.15, avg. ppl 3.54 cum. examples 1920, speed 6596.28 words/sec, time elapsed 441.12 sec\n",
            "epoch 40 (262 / 272), iter 10870, avg. loss 10.57, avg. ppl 3.66 cum. examples 2240, speed 6826.37 words/sec, time elapsed 441.50 sec\n",
            "epoch 40 (272 / 272), iter 10880, avg. loss 10.02, avg. ppl 3.42 cum. examples 2557, speed 6815.18 words/sec, time elapsed 441.88 sec\n",
            "epoch 41 (10 / 272), iter 10890, avg. loss 10.27, avg. ppl 3.49 cum. examples 2877, speed 6958.33 words/sec, time elapsed 442.26 sec\n",
            "epoch 41 (20 / 272), iter 10900, avg. loss 9.29, avg. ppl 3.18 cum. examples 3197, speed 7010.92 words/sec, time elapsed 442.62 sec\n",
            "epoch 41, iter 10900, cum. loss 10.30, cum. ppl 3.56 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 10900, dev. ppl 5.557372\n",
            "hit patience 2\n",
            "epoch 41 (30 / 272), iter 10910, avg. loss 9.09, avg. ppl 3.12 cum. examples 320, speed 5277.31 words/sec, time elapsed 443.11 sec\n",
            "epoch 41 (40 / 272), iter 10920, avg. loss 10.28, avg. ppl 3.56 cum. examples 640, speed 7024.16 words/sec, time elapsed 443.48 sec\n",
            "epoch 41 (50 / 272), iter 10930, avg. loss 9.81, avg. ppl 3.39 cum. examples 960, speed 6932.51 words/sec, time elapsed 443.85 sec\n",
            "epoch 41 (60 / 272), iter 10940, avg. loss 10.62, avg. ppl 3.69 cum. examples 1280, speed 6885.11 words/sec, time elapsed 444.23 sec\n",
            "epoch 41 (70 / 272), iter 10950, avg. loss 10.66, avg. ppl 3.69 cum. examples 1600, speed 6860.93 words/sec, time elapsed 444.61 sec\n",
            "epoch 41 (80 / 272), iter 10960, avg. loss 10.63, avg. ppl 3.58 cum. examples 1920, speed 7101.73 words/sec, time elapsed 444.98 sec\n",
            "epoch 41 (90 / 272), iter 10970, avg. loss 10.72, avg. ppl 3.67 cum. examples 2240, speed 6630.49 words/sec, time elapsed 445.38 sec\n",
            "epoch 41 (100 / 272), iter 10980, avg. loss 10.54, avg. ppl 3.71 cum. examples 2560, speed 6654.48 words/sec, time elapsed 445.77 sec\n",
            "epoch 41 (110 / 272), iter 10990, avg. loss 9.62, avg. ppl 3.31 cum. examples 2880, speed 6874.76 words/sec, time elapsed 446.14 sec\n",
            "epoch 41 (120 / 272), iter 11000, avg. loss 9.93, avg. ppl 3.43 cum. examples 3200, speed 7189.47 words/sec, time elapsed 446.50 sec\n",
            "epoch 41, iter 11000, cum. loss 10.19, cum. ppl 3.51 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 11000, dev. ppl 5.495861\n",
            "epoch 41, iter 11000: save currently the best model to [model.bin]\n",
            "epoch 41 (130 / 272), iter 11010, avg. loss 9.20, avg. ppl 3.18 cum. examples 320, speed 4731.24 words/sec, time elapsed 447.04 sec\n",
            "epoch 41 (140 / 272), iter 11020, avg. loss 9.85, avg. ppl 3.37 cum. examples 640, speed 6845.76 words/sec, time elapsed 447.42 sec\n",
            "epoch 41 (150 / 272), iter 11030, avg. loss 10.37, avg. ppl 3.59 cum. examples 960, speed 6691.70 words/sec, time elapsed 447.81 sec\n",
            "epoch 41 (160 / 272), iter 11040, avg. loss 10.27, avg. ppl 3.57 cum. examples 1280, speed 6926.14 words/sec, time elapsed 448.18 sec\n",
            "epoch 41 (170 / 272), iter 11050, avg. loss 10.16, avg. ppl 3.52 cum. examples 1600, speed 6738.44 words/sec, time elapsed 448.56 sec\n",
            "epoch 41 (180 / 272), iter 11060, avg. loss 9.78, avg. ppl 3.39 cum. examples 1920, speed 6649.56 words/sec, time elapsed 448.95 sec\n",
            "epoch 41 (190 / 272), iter 11070, avg. loss 9.31, avg. ppl 3.23 cum. examples 2240, speed 6660.88 words/sec, time elapsed 449.33 sec\n",
            "epoch 41 (200 / 272), iter 11080, avg. loss 10.02, avg. ppl 3.45 cum. examples 2560, speed 6517.63 words/sec, time elapsed 449.73 sec\n",
            "epoch 41 (210 / 272), iter 11090, avg. loss 10.33, avg. ppl 3.62 cum. examples 2880, speed 6662.50 words/sec, time elapsed 450.11 sec\n",
            "epoch 41 (220 / 272), iter 11100, avg. loss 10.51, avg. ppl 3.72 cum. examples 3200, speed 7003.82 words/sec, time elapsed 450.48 sec\n",
            "epoch 41, iter 11100, cum. loss 9.98, cum. ppl 3.46 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 11100, dev. ppl 5.484445\n",
            "epoch 41, iter 11100: save currently the best model to [model.bin]\n",
            "epoch 41 (230 / 272), iter 11110, avg. loss 10.58, avg. ppl 3.69 cum. examples 320, speed 5086.33 words/sec, time elapsed 450.99 sec\n",
            "epoch 41 (240 / 272), iter 11120, avg. loss 10.09, avg. ppl 3.47 cum. examples 640, speed 6794.01 words/sec, time elapsed 451.37 sec\n",
            "epoch 41 (250 / 272), iter 11130, avg. loss 10.19, avg. ppl 3.48 cum. examples 960, speed 6889.30 words/sec, time elapsed 451.75 sec\n",
            "epoch 41 (260 / 272), iter 11140, avg. loss 9.96, avg. ppl 3.50 cum. examples 1280, speed 6843.64 words/sec, time elapsed 452.12 sec\n",
            "epoch 41 (270 / 272), iter 11150, avg. loss 10.15, avg. ppl 3.53 cum. examples 1600, speed 6807.62 words/sec, time elapsed 452.50 sec\n",
            "epoch 42 (8 / 272), iter 11160, avg. loss 9.48, avg. ppl 3.30 cum. examples 1917, speed 6489.90 words/sec, time elapsed 452.89 sec\n",
            "epoch 42 (18 / 272), iter 11170, avg. loss 10.43, avg. ppl 3.57 cum. examples 2237, speed 6758.93 words/sec, time elapsed 453.28 sec\n",
            "epoch 42 (28 / 272), iter 11180, avg. loss 9.60, avg. ppl 3.34 cum. examples 2557, speed 6319.05 words/sec, time elapsed 453.68 sec\n",
            "epoch 42 (38 / 272), iter 11190, avg. loss 10.17, avg. ppl 3.49 cum. examples 2877, speed 7017.09 words/sec, time elapsed 454.05 sec\n",
            "epoch 42 (48 / 272), iter 11200, avg. loss 9.91, avg. ppl 3.40 cum. examples 3197, speed 6606.11 words/sec, time elapsed 454.44 sec\n",
            "epoch 42, iter 11200, cum. loss 10.06, cum. ppl 3.48 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 11200, dev. ppl 5.421064\n",
            "epoch 42, iter 11200: save currently the best model to [model.bin]\n",
            "epoch 42 (58 / 272), iter 11210, avg. loss 10.05, avg. ppl 3.58 cum. examples 320, speed 4618.37 words/sec, time elapsed 454.99 sec\n",
            "epoch 42 (68 / 272), iter 11220, avg. loss 10.09, avg. ppl 3.50 cum. examples 640, speed 6885.57 words/sec, time elapsed 455.36 sec\n",
            "epoch 42 (78 / 272), iter 11230, avg. loss 9.11, avg. ppl 3.15 cum. examples 960, speed 6772.49 words/sec, time elapsed 455.74 sec\n",
            "epoch 42 (88 / 272), iter 11240, avg. loss 9.62, avg. ppl 3.21 cum. examples 1280, speed 7003.45 words/sec, time elapsed 456.12 sec\n",
            "epoch 42 (98 / 272), iter 11250, avg. loss 10.35, avg. ppl 3.57 cum. examples 1600, speed 6390.45 words/sec, time elapsed 456.52 sec\n",
            "epoch 42 (108 / 272), iter 11260, avg. loss 9.69, avg. ppl 3.36 cum. examples 1920, speed 6383.90 words/sec, time elapsed 456.92 sec\n",
            "epoch 42 (118 / 272), iter 11270, avg. loss 9.89, avg. ppl 3.40 cum. examples 2240, speed 6894.48 words/sec, time elapsed 457.30 sec\n",
            "epoch 42 (128 / 272), iter 11280, avg. loss 10.37, avg. ppl 3.53 cum. examples 2560, speed 6804.30 words/sec, time elapsed 457.69 sec\n",
            "epoch 42 (138 / 272), iter 11290, avg. loss 10.36, avg. ppl 3.53 cum. examples 2880, speed 7257.70 words/sec, time elapsed 458.05 sec\n",
            "epoch 42 (148 / 272), iter 11300, avg. loss 9.77, avg. ppl 3.33 cum. examples 3200, speed 6681.86 words/sec, time elapsed 458.44 sec\n",
            "epoch 42, iter 11300, cum. loss 9.93, cum. ppl 3.41 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 11300, dev. ppl 5.377649\n",
            "epoch 42, iter 11300: save currently the best model to [model.bin]\n",
            "epoch 42 (158 / 272), iter 11310, avg. loss 11.72, avg. ppl 4.06 cum. examples 320, speed 5063.26 words/sec, time elapsed 458.96 sec\n",
            "epoch 42 (168 / 272), iter 11320, avg. loss 9.48, avg. ppl 3.27 cum. examples 640, speed 6486.53 words/sec, time elapsed 459.36 sec\n",
            "epoch 42 (178 / 272), iter 11330, avg. loss 10.01, avg. ppl 3.40 cum. examples 960, speed 6696.06 words/sec, time elapsed 459.75 sec\n",
            "epoch 42 (188 / 272), iter 11340, avg. loss 9.19, avg. ppl 3.16 cum. examples 1280, speed 6907.70 words/sec, time elapsed 460.12 sec\n",
            "epoch 42 (198 / 272), iter 11350, avg. loss 9.53, avg. ppl 3.26 cum. examples 1600, speed 6570.28 words/sec, time elapsed 460.51 sec\n",
            "epoch 42 (208 / 272), iter 11360, avg. loss 11.25, avg. ppl 3.87 cum. examples 1920, speed 6322.90 words/sec, time elapsed 460.93 sec\n",
            "epoch 42 (218 / 272), iter 11370, avg. loss 8.86, avg. ppl 3.12 cum. examples 2240, speed 6003.42 words/sec, time elapsed 461.35 sec\n",
            "epoch 42 (228 / 272), iter 11380, avg. loss 10.06, avg. ppl 3.44 cum. examples 2560, speed 6488.34 words/sec, time elapsed 461.75 sec\n",
            "epoch 42 (238 / 272), iter 11390, avg. loss 9.65, avg. ppl 3.30 cum. examples 2880, speed 6600.44 words/sec, time elapsed 462.14 sec\n",
            "epoch 42 (248 / 272), iter 11400, avg. loss 10.87, avg. ppl 3.74 cum. examples 3200, speed 6977.29 words/sec, time elapsed 462.52 sec\n",
            "epoch 42, iter 11400, cum. loss 10.06, cum. ppl 3.46 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 11400, dev. ppl 5.455783\n",
            "hit patience 1\n",
            "epoch 42 (258 / 272), iter 11410, avg. loss 9.45, avg. ppl 3.26 cum. examples 320, speed 4772.89 words/sec, time elapsed 463.06 sec\n",
            "epoch 42 (268 / 272), iter 11420, avg. loss 8.91, avg. ppl 3.14 cum. examples 640, speed 6951.37 words/sec, time elapsed 463.42 sec\n",
            "epoch 43 (6 / 272), iter 11430, avg. loss 9.12, avg. ppl 3.16 cum. examples 957, speed 6726.94 words/sec, time elapsed 463.79 sec\n",
            "epoch 43 (16 / 272), iter 11440, avg. loss 9.67, avg. ppl 3.23 cum. examples 1277, speed 6456.82 words/sec, time elapsed 464.20 sec\n",
            "epoch 43 (26 / 272), iter 11450, avg. loss 9.99, avg. ppl 3.44 cum. examples 1597, speed 6907.11 words/sec, time elapsed 464.57 sec\n",
            "epoch 43 (36 / 272), iter 11460, avg. loss 9.70, avg. ppl 3.30 cum. examples 1917, speed 6665.88 words/sec, time elapsed 464.96 sec\n",
            "epoch 43 (46 / 272), iter 11470, avg. loss 9.56, avg. ppl 3.26 cum. examples 2237, speed 6905.74 words/sec, time elapsed 465.34 sec\n",
            "epoch 43 (56 / 272), iter 11480, avg. loss 9.61, avg. ppl 3.33 cum. examples 2557, speed 6619.11 words/sec, time elapsed 465.73 sec\n",
            "epoch 43 (66 / 272), iter 11490, avg. loss 9.31, avg. ppl 3.18 cum. examples 2877, speed 6439.02 words/sec, time elapsed 466.13 sec\n",
            "epoch 43 (76 / 272), iter 11500, avg. loss 10.57, avg. ppl 3.51 cum. examples 3197, speed 6920.99 words/sec, time elapsed 466.52 sec\n",
            "epoch 43, iter 11500, cum. loss 9.59, cum. ppl 3.28 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 11500, dev. ppl 5.469115\n",
            "hit patience 2\n",
            "epoch 43 (86 / 272), iter 11510, avg. loss 9.89, avg. ppl 3.43 cum. examples 320, speed 4903.36 words/sec, time elapsed 467.04 sec\n",
            "epoch 43 (96 / 272), iter 11520, avg. loss 10.94, avg. ppl 3.71 cum. examples 640, speed 6921.64 words/sec, time elapsed 467.43 sec\n",
            "epoch 43 (106 / 272), iter 11530, avg. loss 9.25, avg. ppl 3.21 cum. examples 960, speed 6791.25 words/sec, time elapsed 467.80 sec\n",
            "epoch 43 (116 / 272), iter 11540, avg. loss 9.52, avg. ppl 3.25 cum. examples 1280, speed 6678.48 words/sec, time elapsed 468.19 sec\n",
            "epoch 43 (126 / 272), iter 11550, avg. loss 9.38, avg. ppl 3.24 cum. examples 1600, speed 6259.21 words/sec, time elapsed 468.60 sec\n",
            "epoch 43 (136 / 272), iter 11560, avg. loss 9.47, avg. ppl 3.26 cum. examples 1920, speed 6944.25 words/sec, time elapsed 468.97 sec\n",
            "epoch 43 (146 / 272), iter 11570, avg. loss 9.82, avg. ppl 3.35 cum. examples 2240, speed 5871.51 words/sec, time elapsed 469.41 sec\n",
            "epoch 43 (156 / 272), iter 11580, avg. loss 9.71, avg. ppl 3.36 cum. examples 2560, speed 6262.78 words/sec, time elapsed 469.82 sec\n",
            "epoch 43 (166 / 272), iter 11590, avg. loss 9.73, avg. ppl 3.36 cum. examples 2880, speed 6817.35 words/sec, time elapsed 470.19 sec\n",
            "epoch 43 (176 / 272), iter 11600, avg. loss 10.04, avg. ppl 3.43 cum. examples 3200, speed 6873.73 words/sec, time elapsed 470.57 sec\n",
            "epoch 43, iter 11600, cum. loss 9.77, cum. ppl 3.36 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 11600, dev. ppl 5.398718\n",
            "hit patience 3\n",
            "epoch 43 (186 / 272), iter 11610, avg. loss 9.66, avg. ppl 3.34 cum. examples 320, speed 4734.10 words/sec, time elapsed 471.12 sec\n",
            "epoch 43 (196 / 272), iter 11620, avg. loss 9.46, avg. ppl 3.29 cum. examples 640, speed 6688.85 words/sec, time elapsed 471.50 sec\n",
            "epoch 43 (206 / 272), iter 11630, avg. loss 9.74, avg. ppl 3.40 cum. examples 960, speed 6465.19 words/sec, time elapsed 471.89 sec\n",
            "epoch 43 (216 / 272), iter 11640, avg. loss 10.06, avg. ppl 3.50 cum. examples 1280, speed 6886.06 words/sec, time elapsed 472.26 sec\n",
            "epoch 43 (226 / 272), iter 11650, avg. loss 10.17, avg. ppl 3.46 cum. examples 1600, speed 6789.48 words/sec, time elapsed 472.65 sec\n",
            "epoch 43 (236 / 272), iter 11660, avg. loss 9.34, avg. ppl 3.21 cum. examples 1920, speed 6688.40 words/sec, time elapsed 473.03 sec\n",
            "epoch 43 (246 / 272), iter 11670, avg. loss 8.99, avg. ppl 3.09 cum. examples 2240, speed 7021.67 words/sec, time elapsed 473.40 sec\n",
            "epoch 43 (256 / 272), iter 11680, avg. loss 9.88, avg. ppl 3.38 cum. examples 2560, speed 6660.66 words/sec, time elapsed 473.79 sec\n",
            "epoch 43 (266 / 272), iter 11690, avg. loss 10.47, avg. ppl 3.58 cum. examples 2880, speed 7161.43 words/sec, time elapsed 474.16 sec\n",
            "epoch 44 (4 / 272), iter 11700, avg. loss 9.02, avg. ppl 3.13 cum. examples 3197, speed 6907.29 words/sec, time elapsed 474.52 sec\n",
            "epoch 44, iter 11700, cum. loss 9.68, cum. ppl 3.33 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 11700, dev. ppl 5.439767\n",
            "hit patience 4\n",
            "epoch 44 (14 / 272), iter 11710, avg. loss 9.66, avg. ppl 3.30 cum. examples 320, speed 4671.71 words/sec, time elapsed 475.07 sec\n",
            "epoch 44 (24 / 272), iter 11720, avg. loss 9.53, avg. ppl 3.25 cum. examples 640, speed 5993.75 words/sec, time elapsed 475.51 sec\n",
            "epoch 44 (34 / 272), iter 11730, avg. loss 9.67, avg. ppl 3.31 cum. examples 960, speed 6153.62 words/sec, time elapsed 475.93 sec\n",
            "epoch 44 (44 / 272), iter 11740, avg. loss 9.62, avg. ppl 3.23 cum. examples 1280, speed 5728.91 words/sec, time elapsed 476.39 sec\n",
            "epoch 44 (54 / 272), iter 11750, avg. loss 9.40, avg. ppl 3.20 cum. examples 1600, speed 6104.68 words/sec, time elapsed 476.81 sec\n",
            "epoch 44 (64 / 272), iter 11760, avg. loss 10.21, avg. ppl 3.49 cum. examples 1920, speed 6441.51 words/sec, time elapsed 477.22 sec\n",
            "epoch 44 (74 / 272), iter 11770, avg. loss 9.44, avg. ppl 3.17 cum. examples 2240, speed 6978.83 words/sec, time elapsed 477.59 sec\n",
            "epoch 44 (84 / 272), iter 11780, avg. loss 8.62, avg. ppl 2.97 cum. examples 2560, speed 6576.10 words/sec, time elapsed 477.98 sec\n",
            "epoch 44 (94 / 272), iter 11790, avg. loss 9.56, avg. ppl 3.19 cum. examples 2880, speed 7112.33 words/sec, time elapsed 478.35 sec\n",
            "epoch 44 (104 / 272), iter 11800, avg. loss 9.12, avg. ppl 3.18 cum. examples 3200, speed 6726.41 words/sec, time elapsed 478.72 sec\n",
            "epoch 44, iter 11800, cum. loss 9.48, cum. ppl 3.23 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 11800, dev. ppl 5.478078\n",
            "hit patience 5\n",
            "hit #1 trial\n",
            "load previously best model and decay learning rate to 0.000500\n",
            "restore parameters of the optimizers\n",
            "epoch 44 (114 / 272), iter 11810, avg. loss 9.98, avg. ppl 3.41 cum. examples 320, speed 4875.71 words/sec, time elapsed 479.26 sec\n",
            "epoch 44 (124 / 272), iter 11820, avg. loss 9.40, avg. ppl 3.20 cum. examples 640, speed 6926.00 words/sec, time elapsed 479.63 sec\n",
            "epoch 44 (134 / 272), iter 11830, avg. loss 9.21, avg. ppl 3.15 cum. examples 960, speed 6457.15 words/sec, time elapsed 480.03 sec\n",
            "epoch 44 (144 / 272), iter 11840, avg. loss 9.02, avg. ppl 3.06 cum. examples 1280, speed 6944.75 words/sec, time elapsed 480.40 sec\n",
            "epoch 44 (154 / 272), iter 11850, avg. loss 8.97, avg. ppl 3.07 cum. examples 1600, speed 6918.41 words/sec, time elapsed 480.77 sec\n",
            "epoch 44 (164 / 272), iter 11860, avg. loss 9.56, avg. ppl 3.23 cum. examples 1920, speed 6959.15 words/sec, time elapsed 481.15 sec\n",
            "epoch 44 (174 / 272), iter 11870, avg. loss 9.21, avg. ppl 3.16 cum. examples 2240, speed 7085.88 words/sec, time elapsed 481.51 sec\n",
            "epoch 44 (184 / 272), iter 11880, avg. loss 10.19, avg. ppl 3.45 cum. examples 2560, speed 6484.32 words/sec, time elapsed 481.91 sec\n",
            "epoch 44 (194 / 272), iter 11890, avg. loss 9.88, avg. ppl 3.43 cum. examples 2880, speed 6662.65 words/sec, time elapsed 482.30 sec\n",
            "epoch 44 (204 / 272), iter 11900, avg. loss 9.47, avg. ppl 3.23 cum. examples 3200, speed 6472.32 words/sec, time elapsed 482.70 sec\n",
            "epoch 44, iter 11900, cum. loss 9.49, cum. ppl 3.24 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 11900, dev. ppl 5.392155\n",
            "hit patience 1\n",
            "epoch 44 (214 / 272), iter 11910, avg. loss 10.58, avg. ppl 3.63 cum. examples 320, speed 5009.28 words/sec, time elapsed 483.22 sec\n",
            "epoch 44 (224 / 272), iter 11920, avg. loss 9.98, avg. ppl 3.39 cum. examples 640, speed 6636.73 words/sec, time elapsed 483.62 sec\n",
            "epoch 44 (234 / 272), iter 11930, avg. loss 9.27, avg. ppl 3.17 cum. examples 960, speed 6839.78 words/sec, time elapsed 483.99 sec\n",
            "epoch 44 (244 / 272), iter 11940, avg. loss 10.03, avg. ppl 3.39 cum. examples 1280, speed 6890.98 words/sec, time elapsed 484.38 sec\n",
            "epoch 44 (254 / 272), iter 11950, avg. loss 8.87, avg. ppl 3.07 cum. examples 1600, speed 6606.21 words/sec, time elapsed 484.76 sec\n",
            "epoch 44 (264 / 272), iter 11960, avg. loss 9.25, avg. ppl 3.14 cum. examples 1920, speed 6867.84 words/sec, time elapsed 485.14 sec\n",
            "epoch 45 (2 / 272), iter 11970, avg. loss 9.01, avg. ppl 3.12 cum. examples 2237, speed 6832.40 words/sec, time elapsed 485.50 sec\n",
            "epoch 45 (12 / 272), iter 11980, avg. loss 9.06, avg. ppl 3.09 cum. examples 2557, speed 6143.47 words/sec, time elapsed 485.92 sec\n",
            "epoch 45 (22 / 272), iter 11990, avg. loss 9.47, avg. ppl 3.23 cum. examples 2877, speed 6595.41 words/sec, time elapsed 486.31 sec\n",
            "epoch 45 (32 / 272), iter 12000, avg. loss 11.10, avg. ppl 3.77 cum. examples 3197, speed 6181.03 words/sec, time elapsed 486.75 sec\n",
            "epoch 45, iter 12000, cum. loss 9.66, cum. ppl 3.30 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 12000, dev. ppl 5.368229\n",
            "epoch 45, iter 12000: save currently the best model to [model.bin]\n",
            "epoch 45 (42 / 272), iter 12010, avg. loss 9.12, avg. ppl 3.12 cum. examples 320, speed 4745.97 words/sec, time elapsed 487.29 sec\n",
            "epoch 45 (52 / 272), iter 12020, avg. loss 9.23, avg. ppl 3.15 cum. examples 640, speed 6266.25 words/sec, time elapsed 487.70 sec\n",
            "epoch 45 (62 / 272), iter 12030, avg. loss 9.74, avg. ppl 3.37 cum. examples 960, speed 6595.26 words/sec, time elapsed 488.09 sec\n",
            "epoch 45 (72 / 272), iter 12040, avg. loss 9.39, avg. ppl 3.19 cum. examples 1280, speed 6687.12 words/sec, time elapsed 488.48 sec\n",
            "epoch 45 (82 / 272), iter 12050, avg. loss 8.33, avg. ppl 2.86 cum. examples 1600, speed 6582.34 words/sec, time elapsed 488.86 sec\n",
            "epoch 45 (92 / 272), iter 12060, avg. loss 10.16, avg. ppl 3.47 cum. examples 1920, speed 6727.46 words/sec, time elapsed 489.25 sec\n",
            "epoch 45 (102 / 272), iter 12070, avg. loss 9.45, avg. ppl 3.29 cum. examples 2240, speed 6930.92 words/sec, time elapsed 489.62 sec\n",
            "epoch 45 (112 / 272), iter 12080, avg. loss 8.90, avg. ppl 3.01 cum. examples 2560, speed 7022.03 words/sec, time elapsed 489.99 sec\n",
            "epoch 45 (122 / 272), iter 12090, avg. loss 8.64, avg. ppl 2.95 cum. examples 2880, speed 6626.55 words/sec, time elapsed 490.37 sec\n",
            "epoch 45 (132 / 272), iter 12100, avg. loss 8.45, avg. ppl 2.93 cum. examples 3200, speed 6194.65 words/sec, time elapsed 490.78 sec\n",
            "epoch 45, iter 12100, cum. loss 9.14, cum. ppl 3.13 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 12100, dev. ppl 5.335083\n",
            "epoch 45, iter 12100: save currently the best model to [model.bin]\n",
            "epoch 45 (142 / 272), iter 12110, avg. loss 9.54, avg. ppl 3.21 cum. examples 320, speed 4823.93 words/sec, time elapsed 491.32 sec\n",
            "epoch 45 (152 / 272), iter 12120, avg. loss 9.87, avg. ppl 3.38 cum. examples 640, speed 6198.93 words/sec, time elapsed 491.74 sec\n",
            "epoch 45 (162 / 272), iter 12130, avg. loss 10.02, avg. ppl 3.47 cum. examples 960, speed 6508.61 words/sec, time elapsed 492.14 sec\n",
            "epoch 45 (172 / 272), iter 12140, avg. loss 9.31, avg. ppl 3.20 cum. examples 1280, speed 6610.70 words/sec, time elapsed 492.52 sec\n",
            "epoch 45 (182 / 272), iter 12150, avg. loss 8.68, avg. ppl 2.99 cum. examples 1600, speed 6475.17 words/sec, time elapsed 492.91 sec\n",
            "epoch 45 (192 / 272), iter 12160, avg. loss 9.13, avg. ppl 3.09 cum. examples 1920, speed 6513.03 words/sec, time elapsed 493.31 sec\n",
            "epoch 45 (202 / 272), iter 12170, avg. loss 9.79, avg. ppl 3.32 cum. examples 2240, speed 6821.31 words/sec, time elapsed 493.70 sec\n",
            "epoch 45 (212 / 272), iter 12180, avg. loss 10.59, avg. ppl 3.61 cum. examples 2560, speed 6684.60 words/sec, time elapsed 494.09 sec\n",
            "epoch 45 (222 / 272), iter 12190, avg. loss 9.15, avg. ppl 3.12 cum. examples 2880, speed 6403.01 words/sec, time elapsed 494.49 sec\n",
            "epoch 45 (232 / 272), iter 12200, avg. loss 10.26, avg. ppl 3.46 cum. examples 3200, speed 6018.80 words/sec, time elapsed 494.93 sec\n",
            "epoch 45, iter 12200, cum. loss 9.63, cum. ppl 3.28 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 12200, dev. ppl 5.358549\n",
            "hit patience 1\n",
            "epoch 45 (242 / 272), iter 12210, avg. loss 9.66, avg. ppl 3.28 cum. examples 320, speed 5023.73 words/sec, time elapsed 495.45 sec\n",
            "epoch 45 (252 / 272), iter 12220, avg. loss 9.79, avg. ppl 3.30 cum. examples 640, speed 6669.62 words/sec, time elapsed 495.85 sec\n",
            "epoch 45 (262 / 272), iter 12230, avg. loss 9.92, avg. ppl 3.43 cum. examples 960, speed 6550.10 words/sec, time elapsed 496.24 sec\n",
            "epoch 45 (272 / 272), iter 12240, avg. loss 8.54, avg. ppl 2.89 cum. examples 1277, speed 6486.01 words/sec, time elapsed 496.63 sec\n",
            "epoch 46 (10 / 272), iter 12250, avg. loss 8.41, avg. ppl 2.89 cum. examples 1597, speed 6719.12 words/sec, time elapsed 497.01 sec\n",
            "epoch 46 (20 / 272), iter 12260, avg. loss 9.41, avg. ppl 3.17 cum. examples 1917, speed 6167.71 words/sec, time elapsed 497.43 sec\n",
            "epoch 46 (30 / 272), iter 12270, avg. loss 9.63, avg. ppl 3.33 cum. examples 2237, speed 6584.56 words/sec, time elapsed 497.82 sec\n",
            "epoch 46 (40 / 272), iter 12280, avg. loss 8.70, avg. ppl 2.99 cum. examples 2557, speed 6483.63 words/sec, time elapsed 498.22 sec\n",
            "epoch 46 (50 / 272), iter 12290, avg. loss 9.29, avg. ppl 3.15 cum. examples 2877, speed 6454.39 words/sec, time elapsed 498.62 sec\n",
            "epoch 46 (60 / 272), iter 12300, avg. loss 9.56, avg. ppl 3.21 cum. examples 3197, speed 6502.79 words/sec, time elapsed 499.02 sec\n",
            "epoch 46, iter 12300, cum. loss 9.29, cum. ppl 3.16 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 12300, dev. ppl 5.332387\n",
            "epoch 46, iter 12300: save currently the best model to [model.bin]\n",
            "epoch 46 (70 / 272), iter 12310, avg. loss 8.36, avg. ppl 2.82 cum. examples 320, speed 4717.02 words/sec, time elapsed 499.57 sec\n",
            "epoch 46 (80 / 272), iter 12320, avg. loss 9.40, avg. ppl 3.20 cum. examples 640, speed 6426.50 words/sec, time elapsed 499.97 sec\n",
            "epoch 46 (90 / 272), iter 12330, avg. loss 9.39, avg. ppl 3.17 cum. examples 960, speed 6487.55 words/sec, time elapsed 500.37 sec\n",
            "epoch 46 (100 / 272), iter 12340, avg. loss 9.94, avg. ppl 3.37 cum. examples 1280, speed 6563.19 words/sec, time elapsed 500.77 sec\n",
            "epoch 46 (110 / 272), iter 12350, avg. loss 9.18, avg. ppl 3.12 cum. examples 1600, speed 6765.61 words/sec, time elapsed 501.15 sec\n",
            "epoch 46 (120 / 272), iter 12360, avg. loss 9.47, avg. ppl 3.27 cum. examples 1920, speed 6439.92 words/sec, time elapsed 501.55 sec\n",
            "epoch 46 (130 / 272), iter 12370, avg. loss 10.41, avg. ppl 3.52 cum. examples 2240, speed 6786.85 words/sec, time elapsed 501.94 sec\n",
            "epoch 46 (140 / 272), iter 12380, avg. loss 10.22, avg. ppl 3.39 cum. examples 2560, speed 6631.88 words/sec, time elapsed 502.34 sec\n",
            "epoch 46 (150 / 272), iter 12390, avg. loss 9.11, avg. ppl 3.15 cum. examples 2880, speed 6163.68 words/sec, time elapsed 502.76 sec\n",
            "epoch 46 (160 / 272), iter 12400, avg. loss 8.74, avg. ppl 2.99 cum. examples 3200, speed 6709.61 words/sec, time elapsed 503.14 sec\n",
            "epoch 46, iter 12400, cum. loss 9.42, cum. ppl 3.20 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 12400, dev. ppl 5.330432\n",
            "epoch 46, iter 12400: save currently the best model to [model.bin]\n",
            "epoch 46 (170 / 272), iter 12410, avg. loss 8.73, avg. ppl 2.92 cum. examples 320, speed 4791.81 words/sec, time elapsed 503.68 sec\n",
            "epoch 46 (180 / 272), iter 12420, avg. loss 9.01, avg. ppl 3.10 cum. examples 640, speed 6671.91 words/sec, time elapsed 504.06 sec\n",
            "epoch 46 (190 / 272), iter 12430, avg. loss 8.18, avg. ppl 2.85 cum. examples 960, speed 6423.90 words/sec, time elapsed 504.45 sec\n",
            "epoch 46 (200 / 272), iter 12440, avg. loss 10.08, avg. ppl 3.46 cum. examples 1280, speed 6452.80 words/sec, time elapsed 504.85 sec\n",
            "epoch 46 (210 / 272), iter 12450, avg. loss 9.65, avg. ppl 3.31 cum. examples 1600, speed 6427.49 words/sec, time elapsed 505.26 sec\n",
            "epoch 46 (220 / 272), iter 12460, avg. loss 9.13, avg. ppl 3.12 cum. examples 1920, speed 6262.69 words/sec, time elapsed 505.67 sec\n",
            "epoch 46 (230 / 272), iter 12470, avg. loss 8.74, avg. ppl 2.95 cum. examples 2240, speed 6598.49 words/sec, time elapsed 506.06 sec\n",
            "epoch 46 (240 / 272), iter 12480, avg. loss 10.06, avg. ppl 3.35 cum. examples 2560, speed 6685.85 words/sec, time elapsed 506.46 sec\n",
            "epoch 46 (250 / 272), iter 12490, avg. loss 8.51, avg. ppl 2.90 cum. examples 2880, speed 6064.61 words/sec, time elapsed 506.88 sec\n",
            "epoch 46 (260 / 272), iter 12500, avg. loss 9.84, avg. ppl 3.30 cum. examples 3200, speed 6807.03 words/sec, time elapsed 507.27 sec\n",
            "epoch 46, iter 12500, cum. loss 9.19, cum. ppl 3.12 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 12500, dev. ppl 5.332385\n",
            "hit patience 1\n",
            "epoch 46 (270 / 272), iter 12510, avg. loss 9.31, avg. ppl 3.21 cum. examples 320, speed 4711.35 words/sec, time elapsed 507.81 sec\n",
            "epoch 47 (8 / 272), iter 12520, avg. loss 8.96, avg. ppl 3.07 cum. examples 637, speed 6692.40 words/sec, time elapsed 508.19 sec\n",
            "epoch 47 (18 / 272), iter 12530, avg. loss 8.59, avg. ppl 2.96 cum. examples 957, speed 6531.04 words/sec, time elapsed 508.58 sec\n",
            "epoch 47 (28 / 272), iter 12540, avg. loss 8.47, avg. ppl 2.91 cum. examples 1277, speed 6767.64 words/sec, time elapsed 508.95 sec\n",
            "epoch 47 (38 / 272), iter 12550, avg. loss 9.37, avg. ppl 3.19 cum. examples 1597, speed 6546.75 words/sec, time elapsed 509.35 sec\n",
            "epoch 47 (48 / 272), iter 12560, avg. loss 9.59, avg. ppl 3.22 cum. examples 1917, speed 6584.63 words/sec, time elapsed 509.74 sec\n",
            "epoch 47 (58 / 272), iter 12570, avg. loss 8.86, avg. ppl 3.00 cum. examples 2237, speed 5913.96 words/sec, time elapsed 510.18 sec\n",
            "epoch 47 (68 / 272), iter 12580, avg. loss 9.64, avg. ppl 3.27 cum. examples 2557, speed 5921.47 words/sec, time elapsed 510.62 sec\n",
            "epoch 47 (78 / 272), iter 12590, avg. loss 8.98, avg. ppl 3.06 cum. examples 2877, speed 6477.16 words/sec, time elapsed 511.02 sec\n",
            "epoch 47 (88 / 272), iter 12600, avg. loss 8.76, avg. ppl 2.98 cum. examples 3197, speed 6406.41 words/sec, time elapsed 511.42 sec\n",
            "epoch 47, iter 12600, cum. loss 9.05, cum. ppl 3.08 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 12600, dev. ppl 5.335509\n",
            "hit patience 2\n",
            "epoch 47 (98 / 272), iter 12610, avg. loss 9.02, avg. ppl 3.09 cum. examples 320, speed 4693.22 words/sec, time elapsed 511.96 sec\n",
            "epoch 47 (108 / 272), iter 12620, avg. loss 8.88, avg. ppl 3.00 cum. examples 640, speed 6693.88 words/sec, time elapsed 512.35 sec\n",
            "epoch 47 (118 / 272), iter 12630, avg. loss 10.30, avg. ppl 3.55 cum. examples 960, speed 6317.86 words/sec, time elapsed 512.76 sec\n",
            "epoch 47 (128 / 272), iter 12640, avg. loss 9.56, avg. ppl 3.23 cum. examples 1280, speed 6876.48 words/sec, time elapsed 513.14 sec\n",
            "epoch 47 (138 / 272), iter 12650, avg. loss 9.23, avg. ppl 3.11 cum. examples 1600, speed 6740.08 words/sec, time elapsed 513.53 sec\n",
            "epoch 47 (148 / 272), iter 12660, avg. loss 9.58, avg. ppl 3.23 cum. examples 1920, speed 6539.12 words/sec, time elapsed 513.93 sec\n",
            "epoch 47 (158 / 272), iter 12670, avg. loss 8.15, avg. ppl 2.78 cum. examples 2240, speed 6804.29 words/sec, time elapsed 514.30 sec\n",
            "epoch 47 (168 / 272), iter 12680, avg. loss 8.88, avg. ppl 3.05 cum. examples 2560, speed 6346.45 words/sec, time elapsed 514.71 sec\n",
            "epoch 47 (178 / 272), iter 12690, avg. loss 8.78, avg. ppl 3.03 cum. examples 2880, speed 6555.15 words/sec, time elapsed 515.09 sec\n",
            "epoch 47 (188 / 272), iter 12700, avg. loss 9.20, avg. ppl 3.08 cum. examples 3200, speed 6885.42 words/sec, time elapsed 515.47 sec\n",
            "epoch 47, iter 12700, cum. loss 9.16, cum. ppl 3.11 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 12700, dev. ppl 5.318109\n",
            "epoch 47, iter 12700: save currently the best model to [model.bin]\n",
            "epoch 47 (198 / 272), iter 12710, avg. loss 9.08, avg. ppl 3.05 cum. examples 320, speed 4640.33 words/sec, time elapsed 516.03 sec\n",
            "epoch 47 (208 / 272), iter 12720, avg. loss 9.50, avg. ppl 3.21 cum. examples 640, speed 6178.49 words/sec, time elapsed 516.46 sec\n",
            "epoch 47 (218 / 272), iter 12730, avg. loss 9.30, avg. ppl 3.15 cum. examples 960, speed 6104.77 words/sec, time elapsed 516.88 sec\n",
            "epoch 47 (228 / 272), iter 12740, avg. loss 9.69, avg. ppl 3.24 cum. examples 1280, speed 5845.56 words/sec, time elapsed 517.33 sec\n",
            "epoch 47 (238 / 272), iter 12750, avg. loss 10.03, avg. ppl 3.44 cum. examples 1600, speed 6054.33 words/sec, time elapsed 517.76 sec\n",
            "epoch 47 (248 / 272), iter 12760, avg. loss 9.46, avg. ppl 3.20 cum. examples 1920, speed 6610.18 words/sec, time elapsed 518.16 sec\n",
            "epoch 47 (258 / 272), iter 12770, avg. loss 8.46, avg. ppl 2.85 cum. examples 2240, speed 6608.83 words/sec, time elapsed 518.55 sec\n",
            "epoch 47 (268 / 272), iter 12780, avg. loss 9.47, avg. ppl 3.22 cum. examples 2560, speed 6385.09 words/sec, time elapsed 518.95 sec\n",
            "epoch 48 (6 / 272), iter 12790, avg. loss 8.47, avg. ppl 2.88 cum. examples 2877, speed 6564.71 words/sec, time elapsed 519.34 sec\n",
            "epoch 48 (16 / 272), iter 12800, avg. loss 9.45, avg. ppl 3.21 cum. examples 3197, speed 6116.89 words/sec, time elapsed 519.76 sec\n",
            "epoch 48, iter 12800, cum. loss 9.29, cum. ppl 3.14 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 12800, dev. ppl 5.326283\n",
            "hit patience 1\n",
            "epoch 48 (26 / 272), iter 12810, avg. loss 8.94, avg. ppl 3.04 cum. examples 320, speed 4884.86 words/sec, time elapsed 520.29 sec\n",
            "epoch 48 (36 / 272), iter 12820, avg. loss 8.78, avg. ppl 3.01 cum. examples 640, speed 6188.00 words/sec, time elapsed 520.70 sec\n",
            "epoch 48 (46 / 272), iter 12830, avg. loss 7.98, avg. ppl 2.72 cum. examples 960, speed 6310.81 words/sec, time elapsed 521.11 sec\n",
            "epoch 48 (56 / 272), iter 12840, avg. loss 8.91, avg. ppl 3.03 cum. examples 1280, speed 6531.58 words/sec, time elapsed 521.50 sec\n",
            "epoch 48 (66 / 272), iter 12850, avg. loss 9.42, avg. ppl 3.15 cum. examples 1600, speed 6042.75 words/sec, time elapsed 521.94 sec\n",
            "epoch 48 (76 / 272), iter 12860, avg. loss 8.76, avg. ppl 2.94 cum. examples 1920, speed 6407.44 words/sec, time elapsed 522.34 sec\n",
            "epoch 48 (86 / 272), iter 12870, avg. loss 10.19, avg. ppl 3.50 cum. examples 2240, speed 6529.64 words/sec, time elapsed 522.74 sec\n",
            "epoch 48 (96 / 272), iter 12880, avg. loss 9.76, avg. ppl 3.27 cum. examples 2560, speed 6678.78 words/sec, time elapsed 523.14 sec\n",
            "epoch 48 (106 / 272), iter 12890, avg. loss 9.29, avg. ppl 3.16 cum. examples 2880, speed 6734.05 words/sec, time elapsed 523.52 sec\n",
            "epoch 48 (116 / 272), iter 12900, avg. loss 9.35, avg. ppl 3.18 cum. examples 3200, speed 6532.52 words/sec, time elapsed 523.92 sec\n",
            "epoch 48, iter 12900, cum. loss 9.14, cum. ppl 3.09 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 12900, dev. ppl 5.294435\n",
            "epoch 48, iter 12900: save currently the best model to [model.bin]\n",
            "epoch 48 (126 / 272), iter 12910, avg. loss 8.32, avg. ppl 2.83 cum. examples 320, speed 4645.08 words/sec, time elapsed 524.47 sec\n",
            "epoch 48 (136 / 272), iter 12920, avg. loss 8.44, avg. ppl 2.88 cum. examples 640, speed 6337.22 words/sec, time elapsed 524.87 sec\n",
            "epoch 48 (146 / 272), iter 12930, avg. loss 9.30, avg. ppl 3.12 cum. examples 960, speed 6679.56 words/sec, time elapsed 525.26 sec\n",
            "epoch 48 (156 / 272), iter 12940, avg. loss 9.18, avg. ppl 3.13 cum. examples 1280, speed 6499.23 words/sec, time elapsed 525.66 sec\n",
            "epoch 48 (166 / 272), iter 12950, avg. loss 8.48, avg. ppl 2.86 cum. examples 1600, speed 6231.73 words/sec, time elapsed 526.07 sec\n",
            "epoch 48 (176 / 272), iter 12960, avg. loss 8.93, avg. ppl 3.06 cum. examples 1920, speed 6514.85 words/sec, time elapsed 526.47 sec\n",
            "epoch 48 (186 / 272), iter 12970, avg. loss 9.34, avg. ppl 3.19 cum. examples 2240, speed 6410.40 words/sec, time elapsed 526.87 sec\n",
            "epoch 48 (196 / 272), iter 12980, avg. loss 9.00, avg. ppl 3.07 cum. examples 2560, speed 6517.30 words/sec, time elapsed 527.26 sec\n",
            "epoch 48 (206 / 272), iter 12990, avg. loss 9.30, avg. ppl 3.15 cum. examples 2880, speed 6455.69 words/sec, time elapsed 527.66 sec\n",
            "epoch 48 (216 / 272), iter 13000, avg. loss 9.92, avg. ppl 3.33 cum. examples 3200, speed 6161.34 words/sec, time elapsed 528.09 sec\n",
            "epoch 48, iter 13000, cum. loss 9.02, cum. ppl 3.06 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 13000, dev. ppl 5.232809\n",
            "epoch 48, iter 13000: save currently the best model to [model.bin]\n",
            "epoch 48 (226 / 272), iter 13010, avg. loss 9.24, avg. ppl 3.11 cum. examples 320, speed 4795.72 words/sec, time elapsed 528.64 sec\n",
            "epoch 48 (236 / 272), iter 13020, avg. loss 8.84, avg. ppl 2.99 cum. examples 640, speed 6476.65 words/sec, time elapsed 529.04 sec\n",
            "epoch 48 (246 / 272), iter 13030, avg. loss 9.21, avg. ppl 3.15 cum. examples 960, speed 6391.89 words/sec, time elapsed 529.44 sec\n",
            "epoch 48 (256 / 272), iter 13040, avg. loss 9.23, avg. ppl 3.13 cum. examples 1280, speed 6531.26 words/sec, time elapsed 529.83 sec\n",
            "epoch 48 (266 / 272), iter 13050, avg. loss 8.79, avg. ppl 2.95 cum. examples 1600, speed 6441.97 words/sec, time elapsed 530.24 sec\n",
            "epoch 49 (4 / 272), iter 13060, avg. loss 8.94, avg. ppl 3.05 cum. examples 1917, speed 6786.63 words/sec, time elapsed 530.61 sec\n",
            "epoch 49 (14 / 272), iter 13070, avg. loss 8.80, avg. ppl 3.01 cum. examples 2237, speed 6408.72 words/sec, time elapsed 531.01 sec\n",
            "epoch 49 (24 / 272), iter 13080, avg. loss 9.26, avg. ppl 3.09 cum. examples 2557, speed 6553.07 words/sec, time elapsed 531.41 sec\n",
            "epoch 49 (34 / 272), iter 13090, avg. loss 8.94, avg. ppl 2.98 cum. examples 2877, speed 6676.76 words/sec, time elapsed 531.81 sec\n",
            "epoch 49 (44 / 272), iter 13100, avg. loss 8.91, avg. ppl 3.03 cum. examples 3197, speed 6332.64 words/sec, time elapsed 532.21 sec\n",
            "epoch 49, iter 13100, cum. loss 9.02, cum. ppl 3.05 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 13100, dev. ppl 5.262775\n",
            "hit patience 1\n",
            "epoch 49 (54 / 272), iter 13110, avg. loss 8.34, avg. ppl 2.82 cum. examples 320, speed 4757.79 words/sec, time elapsed 532.75 sec\n",
            "epoch 49 (64 / 272), iter 13120, avg. loss 8.99, avg. ppl 3.05 cum. examples 640, speed 6303.04 words/sec, time elapsed 533.16 sec\n",
            "epoch 49 (74 / 272), iter 13130, avg. loss 9.57, avg. ppl 3.23 cum. examples 960, speed 6563.73 words/sec, time elapsed 533.56 sec\n",
            "epoch 49 (84 / 272), iter 13140, avg. loss 9.45, avg. ppl 3.12 cum. examples 1280, speed 5722.68 words/sec, time elapsed 534.03 sec\n",
            "epoch 49 (94 / 272), iter 13150, avg. loss 9.47, avg. ppl 3.19 cum. examples 1600, speed 5874.96 words/sec, time elapsed 534.47 sec\n",
            "epoch 49 (104 / 272), iter 13160, avg. loss 8.56, avg. ppl 2.92 cum. examples 1920, speed 6843.91 words/sec, time elapsed 534.85 sec\n",
            "epoch 49 (114 / 272), iter 13170, avg. loss 8.54, avg. ppl 2.94 cum. examples 2240, speed 6702.37 words/sec, time elapsed 535.22 sec\n",
            "epoch 49 (124 / 272), iter 13180, avg. loss 9.35, avg. ppl 3.16 cum. examples 2560, speed 6554.67 words/sec, time elapsed 535.62 sec\n",
            "epoch 49 (134 / 272), iter 13190, avg. loss 8.56, avg. ppl 2.89 cum. examples 2880, speed 6435.33 words/sec, time elapsed 536.02 sec\n",
            "epoch 49 (144 / 272), iter 13200, avg. loss 7.87, avg. ppl 2.71 cum. examples 3200, speed 6637.02 words/sec, time elapsed 536.40 sec\n",
            "epoch 49, iter 13200, cum. loss 8.87, cum. ppl 3.00 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 13200, dev. ppl 5.269866\n",
            "hit patience 2\n",
            "epoch 49 (154 / 272), iter 13210, avg. loss 8.74, avg. ppl 3.00 cum. examples 320, speed 4787.09 words/sec, time elapsed 536.94 sec\n",
            "epoch 49 (164 / 272), iter 13220, avg. loss 9.25, avg. ppl 3.09 cum. examples 640, speed 6631.59 words/sec, time elapsed 537.33 sec\n",
            "epoch 49 (174 / 272), iter 13230, avg. loss 8.80, avg. ppl 2.95 cum. examples 960, speed 6296.15 words/sec, time elapsed 537.74 sec\n",
            "epoch 49 (184 / 272), iter 13240, avg. loss 8.56, avg. ppl 2.92 cum. examples 1280, speed 6084.62 words/sec, time elapsed 538.16 sec\n",
            "epoch 49 (194 / 272), iter 13250, avg. loss 9.45, avg. ppl 3.13 cum. examples 1600, speed 6711.32 words/sec, time elapsed 538.56 sec\n",
            "epoch 49 (204 / 272), iter 13260, avg. loss 9.58, avg. ppl 3.22 cum. examples 1920, speed 6597.56 words/sec, time elapsed 538.96 sec\n",
            "epoch 49 (214 / 272), iter 13270, avg. loss 8.76, avg. ppl 3.02 cum. examples 2240, speed 6494.50 words/sec, time elapsed 539.35 sec\n",
            "epoch 49 (224 / 272), iter 13280, avg. loss 8.53, avg. ppl 2.90 cum. examples 2560, speed 6256.22 words/sec, time elapsed 539.76 sec\n",
            "epoch 49 (234 / 272), iter 13290, avg. loss 8.67, avg. ppl 2.91 cum. examples 2880, speed 6588.72 words/sec, time elapsed 540.15 sec\n",
            "epoch 49 (244 / 272), iter 13300, avg. loss 9.08, avg. ppl 3.06 cum. examples 3200, speed 6376.26 words/sec, time elapsed 540.56 sec\n",
            "epoch 49, iter 13300, cum. loss 8.94, cum. ppl 3.02 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 13300, dev. ppl 5.268964\n",
            "hit patience 3\n",
            "epoch 49 (254 / 272), iter 13310, avg. loss 8.79, avg. ppl 3.02 cum. examples 320, speed 4633.23 words/sec, time elapsed 541.11 sec\n",
            "epoch 49 (264 / 272), iter 13320, avg. loss 9.45, avg. ppl 3.24 cum. examples 640, speed 6517.23 words/sec, time elapsed 541.50 sec\n",
            "epoch 50 (2 / 272), iter 13330, avg. loss 8.94, avg. ppl 3.06 cum. examples 957, speed 6508.30 words/sec, time elapsed 541.89 sec\n",
            "epoch 50 (12 / 272), iter 13340, avg. loss 7.84, avg. ppl 2.69 cum. examples 1277, speed 5996.91 words/sec, time elapsed 542.31 sec\n",
            "epoch 50 (22 / 272), iter 13350, avg. loss 8.88, avg. ppl 2.99 cum. examples 1597, speed 5944.89 words/sec, time elapsed 542.75 sec\n",
            "epoch 50 (32 / 272), iter 13360, avg. loss 9.21, avg. ppl 3.08 cum. examples 1917, speed 5901.16 words/sec, time elapsed 543.19 sec\n",
            "epoch 50 (42 / 272), iter 13370, avg. loss 9.03, avg. ppl 3.02 cum. examples 2237, speed 5653.43 words/sec, time elapsed 543.66 sec\n",
            "epoch 50 (52 / 272), iter 13380, avg. loss 10.05, avg. ppl 3.37 cum. examples 2557, speed 6338.85 words/sec, time elapsed 544.08 sec\n",
            "epoch 50 (62 / 272), iter 13390, avg. loss 7.56, avg. ppl 2.57 cum. examples 2877, speed 6723.50 words/sec, time elapsed 544.46 sec\n",
            "epoch 50 (72 / 272), iter 13400, avg. loss 9.17, avg. ppl 3.08 cum. examples 3197, speed 6845.52 words/sec, time elapsed 544.84 sec\n",
            "epoch 50, iter 13400, cum. loss 8.89, cum. ppl 3.01 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 13400, dev. ppl 5.258184\n",
            "hit patience 4\n",
            "epoch 50 (82 / 272), iter 13410, avg. loss 9.21, avg. ppl 3.08 cum. examples 320, speed 5003.17 words/sec, time elapsed 545.36 sec\n",
            "epoch 50 (92 / 272), iter 13420, avg. loss 8.47, avg. ppl 2.87 cum. examples 640, speed 6889.32 words/sec, time elapsed 545.74 sec\n",
            "epoch 50 (102 / 272), iter 13430, avg. loss 8.38, avg. ppl 2.84 cum. examples 960, speed 6878.81 words/sec, time elapsed 546.11 sec\n",
            "epoch 50 (112 / 272), iter 13440, avg. loss 9.47, avg. ppl 3.25 cum. examples 1280, speed 6910.64 words/sec, time elapsed 546.48 sec\n",
            "epoch 50 (122 / 272), iter 13450, avg. loss 8.80, avg. ppl 2.99 cum. examples 1600, speed 6455.60 words/sec, time elapsed 546.88 sec\n",
            "epoch 50 (132 / 272), iter 13460, avg. loss 8.76, avg. ppl 3.01 cum. examples 1920, speed 6542.19 words/sec, time elapsed 547.27 sec\n",
            "epoch 50 (142 / 272), iter 13470, avg. loss 8.65, avg. ppl 2.95 cum. examples 2240, speed 6465.48 words/sec, time elapsed 547.66 sec\n",
            "epoch 50 (152 / 272), iter 13480, avg. loss 9.34, avg. ppl 3.11 cum. examples 2560, speed 6878.50 words/sec, time elapsed 548.05 sec\n",
            "epoch 50 (162 / 272), iter 13490, avg. loss 9.53, avg. ppl 3.21 cum. examples 2880, speed 6374.85 words/sec, time elapsed 548.46 sec\n",
            "epoch 50 (172 / 272), iter 13500, avg. loss 9.58, avg. ppl 3.19 cum. examples 3200, speed 6932.70 words/sec, time elapsed 548.84 sec\n",
            "epoch 50, iter 13500, cum. loss 9.02, cum. ppl 3.05 cum. examples 3200\n",
            "begin validation ...\n",
            "validation: iter 13500, dev. ppl 5.276312\n",
            "hit patience 5\n",
            "hit #2 trial\n",
            "load previously best model and decay learning rate to 0.000250\n",
            "restore parameters of the optimizers\n",
            "epoch 50 (182 / 272), iter 13510, avg. loss 8.77, avg. ppl 2.96 cum. examples 320, speed 5132.10 words/sec, time elapsed 549.35 sec\n",
            "epoch 50 (192 / 272), iter 13520, avg. loss 8.39, avg. ppl 2.86 cum. examples 640, speed 6530.77 words/sec, time elapsed 549.74 sec\n",
            "epoch 50 (202 / 272), iter 13530, avg. loss 9.08, avg. ppl 3.03 cum. examples 960, speed 6802.68 words/sec, time elapsed 550.12 sec\n",
            "epoch 50 (212 / 272), iter 13540, avg. loss 8.84, avg. ppl 3.05 cum. examples 1280, speed 6703.93 words/sec, time elapsed 550.50 sec\n",
            "epoch 50 (222 / 272), iter 13550, avg. loss 8.73, avg. ppl 2.94 cum. examples 1600, speed 6868.73 words/sec, time elapsed 550.88 sec\n",
            "epoch 50 (232 / 272), iter 13560, avg. loss 8.22, avg. ppl 2.82 cum. examples 1920, speed 7027.57 words/sec, time elapsed 551.24 sec\n",
            "epoch 50 (242 / 272), iter 13570, avg. loss 8.46, avg. ppl 2.92 cum. examples 2240, speed 6470.63 words/sec, time elapsed 551.63 sec\n",
            "epoch 50 (252 / 272), iter 13580, avg. loss 7.62, avg. ppl 2.62 cum. examples 2560, speed 6834.48 words/sec, time elapsed 552.00 sec\n",
            "epoch 50 (262 / 272), iter 13590, avg. loss 8.72, avg. ppl 2.91 cum. examples 2880, speed 7158.73 words/sec, time elapsed 552.37 sec\n",
            "epoch 50 (272 / 272), iter 13600, avg. loss 9.14, avg. ppl 3.07 cum. examples 3197, speed 5951.12 words/sec, time elapsed 552.80 sec\n",
            "epoch 50, iter 13600, cum. loss 8.60, cum. ppl 2.91 cum. examples 3197\n",
            "begin validation ...\n",
            "validation: iter 13600, dev. ppl 5.237351\n",
            "hit patience 1\n",
            "reached maximum number of epochs!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w0hcp7oNEju8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xhk9wiHzpyuF"
      },
      "source": [
        "## Evaluate the model\n",
        "\n",
        "We have trained a seq2seq model for the NMT task. Now let's evaluate the model on the test set!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg5Lru2Aq96m"
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBjWvIsKuiIk"
      },
      "source": [
        "First, write a function to compute the BLEU score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfjrIwTyuL_0"
      },
      "source": [
        "def compute_corpus_level_bleu_score(references: List[List[str]], hypotheses: List[Hypothesis]) -> float:\n",
        "    \"\"\" Given decoding results and reference sentences, compute corpus-level BLEU score.\n",
        "    @param references (List[List[str]]): a list of gold-standard reference target sentences\n",
        "    @param hypotheses (List[Hypothesis]): a list of hypotheses, one for each reference\n",
        "    @returns bleu_score: corpus-level BLEU score\n",
        "    \"\"\"\n",
        "    if references[0][0] == '<s>':\n",
        "        references = [ref[1:-1] for ref in references]\n",
        "\n",
        "    bleu_score = corpus_bleu([[ref] for ref in references],\n",
        "                             [hyp.value for hyp in hypotheses])\n",
        "    return bleu_score"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLx5pHDLwIpB"
      },
      "source": [
        "Define constants (hyper-parameters) used during evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0hgIXp2wKzZ"
      },
      "source": [
        "BEAM_SIZE = 5\n",
        "MAX_DECODING_TIME_STEP = 70\n",
        "\n",
        "MODEL_PATH = \"model.bin\""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPIwtRLzuLt8"
      },
      "source": [
        "We write functions to perform decoding on a test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqEeZlyeuzG2"
      },
      "source": [
        "def beam_search(model: NMT, test_data_src: List[List[str]],\n",
        "                beam_size: int, max_decoding_time_step: int) -> List[List[Hypothesis]]:\n",
        "    \"\"\" Run beam search to construct hypotheses for a list of src-language sentences.\n",
        "    @param model (NMT): NMT Model\n",
        "    @param test_data_src (List[List[str]]): List of sentences (words) in source language, from test set.\n",
        "    @param beam_size (int): beam_size (# of hypotheses to hold for a translation at every step)\n",
        "    @param max_decoding_time_step (int): maximum sentence length that Beam search can produce\n",
        "    @returns hypotheses (List[List[Hypothesis]]): List of Hypothesis translations for every source sentence.\n",
        "    \"\"\"\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "\n",
        "    hypotheses = []\n",
        "    with torch.no_grad():\n",
        "        for src_sent in test_data_src:\n",
        "            example_hyps = model.beam_search(src_sent, beam_size=beam_size,\n",
        "                                             max_decoding_time_step=max_decoding_time_step)\n",
        "            hypotheses.append(example_hyps)\n",
        "\n",
        "    if was_training:\n",
        "        model.train(was_training)\n",
        "\n",
        "    return hypotheses\n",
        "\n",
        "def decode(test_src: str = None, test_tgt: str = None):\n",
        "    \"\"\" Performs decoding on a test set, and save the best-scoring decoding results.\n",
        "    If the target gold-standard sentences are given, the function also computes\n",
        "    corpus-level BLEU score.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"load test source sentences from [{}]\".format(test_src))\n",
        "    test_data_src = read_corpus(test_src, source='src')\n",
        "        \n",
        "    print(\"load test target sentences from [{}]\".format(test_tgt))\n",
        "    test_data_tgt = read_corpus(test_tgt, source='tgt')\n",
        "\n",
        "    print(\"load model from {}\".format(MODEL_PATH))\n",
        "    model = NMT.load(MODEL_PATH)\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print('use device: %s' % device)\n",
        "    model = model.to(device)\n",
        "\n",
        "    hypotheses = beam_search(model, test_data_src,\n",
        "                             beam_size=BEAM_SIZE,\n",
        "                             max_decoding_time_step=MAX_DECODING_TIME_STEP)\n",
        "\n",
        "    top_hypotheses = [hyps[0] for hyps in hypotheses]\n",
        "    bleu_score = compute_corpus_level_bleu_score(test_data_tgt, top_hypotheses)\n",
        "    print('Corpus BLEU: {}'.format(bleu_score * 100))\n",
        "    \n",
        "    pred_tgt = [' '.join(hyps[0].value) for hyps in hypotheses]\n",
        "\n",
        "    return test_data_src, test_data_tgt, pred_tgt"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdjSgD28tg2E"
      },
      "source": [
        "Load the trained model and evaluate on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRjz11ntwgkK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b3c34b5-a800-4c08-9872-5580a6931170"
      },
      "source": [
        "test_data_src, test_data_tgt, pred_tgt = decode(test_src='NMT_data/data/test.fr', test_tgt='NMT_data/data/test.en')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load test source sentences from [NMT_data/data/test.fr]\n",
            "load test target sentences from [NMT_data/data/test.en]\n",
            "load model from model.bin\n",
            "use device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:317: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus BLEU: 2.298744146230417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOLmb9eh6kua"
      },
      "source": [
        "Look at some examples. What do you think of the quality of the translations?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5e1cDYe6t0B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cca0afc-ecbf-459f-be5d-0e8ef58f4f8d"
      },
      "source": [
        "# Feel free to change the range to look at more samples!\n",
        "for k in range(12, 22):\n",
        "  print('===== Sample %d ====='%k)\n",
        "  print('Input: %s'%(' '.join(test_data_src[k][1:-1])))\n",
        "  print('Gold: %s'%(' '.join(test_data_tgt[k][1:-1])))\n",
        "  print('Pred: %s'%(pred_tgt[k]))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Sample 12 =====\n",
            "Input: souri@@ t avec b@@ on@@ h@@ eur\n",
            "Gold: she s@@ mil@@ ed happ@@ il@@ y .\n",
            "Pred: she showed .\n",
            "===== Sample 13 =====\n",
            "Input: ne suis pas dev@@ in\n",
            "Gold: i m not a p@@ sy@@ ch@@ ic .\n",
            "Pred: i m not patient .\n",
            "===== Sample 14 =====\n",
            "Input: allez perdre\n",
            "Gold: you re going to lo@@ se .\n",
            "Pred: you are going to miss miss you you you re you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are you are\n",
            "===== Sample 15 =====\n",
            "Input: me tou@@ chez\n",
            "Gold: you re tou@@ ching me .\n",
            "Pred: you re one you you m the oldest\n",
            "===== Sample 16 =====\n",
            "Input: pars aujourd hui\n",
            "Gold: i m leaving today .\n",
            "Pred: i m afraid tomorrow tomorrow\n",
            "===== Sample 17 =====\n",
            "Input: ne suis pas une s@@ ain@@ te\n",
            "Gold: i m no saint .\n",
            "Pred: i m saint .\n",
            "===== Sample 18 =====\n",
            "Input: suis puiss@@ ant\n",
            "Gold: i m pow@@ erful .\n",
            "Pred: i m gr@@ erful ambitious i m i m i m i m i m i m i m i m i m i m i m ambitious suff@@ i m paran@@ i i m paran@@ i i i m paran@@ i i i m paran@@ i i i m paran@@ i i i m paran@@ i i i m paran@@ i i i m paran@@ i i i m\n",
            "===== Sample 19 =====\n",
            "Input: n etes qu un l@@ ache\n",
            "Gold: you re no@@ thing but a co@@ ward .\n",
            "Pred: you you you re not good only girl can .\n",
            "===== Sample 20 =====\n",
            "Input: suis fier de vous tous\n",
            "Gold: i m proud of you all .\n",
            "Pred: i m sorry .\n",
            "===== Sample 21 =====\n",
            "Input: etes un mer@@ ve@@ ill@@ eux ami\n",
            "Gold: you re a wonderful friend .\n",
            "Pred: you re a beau@@ ty you you re re they re they are they are they are they are they are they are they are they are they are they are they are they are they are they are they you are they are they are they are they are they are they are they are they are they are they are they you are they are they are they\n"
          ]
        }
      ]
    }
  ]
}